{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate transfer learning on Turnedtable Watertank (Dataset 2)  using an SVM Classifier: Self-supervised approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Tensorflow for GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tensorflow Version: 2.2.0\n",
      "[INFO] Tensorflow built with CUDA\n",
      "[INFO] Number GPUs Available:  1\n",
      "[INFO] List of GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(\"[INFO] Tensorflow Version:\", tf.__version__)\n",
    "\n",
    "if tf.config.list_physical_devices(\"GPU\") and tf.test.is_built_with_cuda():\n",
    "    print(\"[INFO] Tensorflow built with CUDA\")\n",
    "    print(\"[INFO] Number GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    print(\"[INFO] List of GPU devices:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "    physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    # tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "else:\n",
    "    print(\"[ERROR] GPU not detected, make sure tensorflow-gpu is installed and that GPU is recognized\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "def flatten(x):\n",
    "    return x.reshape((x.shape[0], -1))\n",
    "\n",
    "def classSampling(X, y, samplesPerClass, numberOfClasses):\n",
    "    X_ret = np.zeros((samplesPerClass * numberOfClasses, X.shape[1]), dtype = np.float32)\n",
    "    y_ret = np.zeros((samplesPerClass * numberOfClasses), dtype = np.uint8)\n",
    "    count = 0\n",
    "\n",
    "    for classIdx in range(numberOfClasses):\n",
    "        indices = np.where(y == classIdx)[0]\n",
    "\n",
    "        #if len(indices) < samplesPerClass:\n",
    "        #    raise IndexError(\"Not enough samples for class {} to produce {} samples per class. Only {} class samples available\".format(classIdx, samplesPerClass, len(indices)))\n",
    "\n",
    "        doResample = len(indices) < samplesPerClass\n",
    "\n",
    "        chosenIndices = np.random.choice(indices, samplesPerClass, replace = doResample)\n",
    "\n",
    "        for ci in chosenIndices:\n",
    "            X_ret[count] = X[ci]\n",
    "            y_ret[count] = y[ci]\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    return X_ret, y_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarTurnedTableSupervised(object):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def _normalize_images(self, images):\n",
    "        \"\"\"\n",
    "        Normalize sonar images by 1/255.\n",
    "        \"\"\"\n",
    "        return [element/255.0 for element in images]\n",
    "\n",
    "    def get_sonar_data(self):\n",
    "        \"\"\"\n",
    "        Reads from HDF5 file containing sonar data (resized to fix dims).\n",
    "        Returns list of np arrays containing image data.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"[INFO] Retrieving Sonar Turned Table Supervised Data\")\n",
    "\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            # list all groups\n",
    "            print(\"hdf5 dataset keys: %s\" % f.keys())\n",
    "\n",
    "            # get images and labels\n",
    "            x_train = f[\"x_train\"][...].astype(np.float32)\n",
    "            y_train = f[\"y_train\"][...]\n",
    "\n",
    "            x_test = f[\"x_test\"][...].astype(np.float32)\n",
    "            y_test = f[\"y_test\"][...]\n",
    "\n",
    "            _, x_val, _, y_val = train_test_split(x_test, y_test, train_size=0.5)\n",
    "\n",
    "            print(\"[INFO] Data dimensions\")\n",
    "            print(\"Train\", len(x_train))\n",
    "            print(\"Val\", len(x_val))\n",
    "            print(\"Test\", len(x_test))\n",
    "\n",
    "            # matias normalization\n",
    "            # multiply by 255 because hdf5 file comes as 1/255\n",
    "            x_train *= 255.0\n",
    "            x_val *= 255.0\n",
    "            x_test *= 255.0\n",
    "\n",
    "            x_train -= 84.51\n",
    "            x_val -= 84.51\n",
    "            x_test  -= 84.51\n",
    "\n",
    "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "    \n",
    "def load_sonar_turnedtable_supervised(file_path):\n",
    "    \"\"\"\n",
    "    Loads test data from turnedtable dataset.\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print(\"[INFO] Loading Tenorflow dataset\")\n",
    "\n",
    "    dataset_object = SonarTurnedTableSupervised(file_path)\n",
    "\n",
    "    # Read data\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = dataset_object.get_sonar_data()\n",
    "\n",
    "    # Train data\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(len(x_train))\n",
    "    train_dataset = train_dataset.prefetch(25)\n",
    "\n",
    "    # Validation data\n",
    "    # val_dataset = tf.data.Dataset.from_tensor_slices((x_val, labels_val))\n",
    "    # val_dataset = val_dataset.shuffle(buffer_size=len(x_val)).batch(batch_size)\n",
    "    # val_dataset = val_dataset.prefetch(25)\n",
    "\n",
    "    # Test data\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = test_dataset.shuffle(buffer_size=len(x_test)).batch(len(x_test)) # feed full test set\n",
    "    test_dataset = test_dataset.prefetch(25)\n",
    "\n",
    "    print()\n",
    "    print(\"[INFO] Tensorflow data dimensions\")\n",
    "    # print(train_dataset)\n",
    "    # print(val_dataset)\n",
    "    print(test_dataset)\n",
    "\n",
    "    # return train_dataset, val_dataset, test_dataset\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-177c4b286f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"flatten\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"activation_93\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"activation_91\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet20_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRETRAINED_NUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git-Repositories/dfki/master_thesis/research/models/self_supervised_learning/rotnet/architectures/resnet20.py\u001b[0m in \u001b[0;36mresnet20_model\u001b[0;34m(input_shape, num_classes, starting_num_filters, name)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# Stack 2, Residual block 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Git-Repositories/dfki/master_thesis/research/models/self_supervised_learning/rotnet/architectures/resnet20.py\u001b[0m in \u001b[0;36mresnet_layer\u001b[0;34m(inputs, num_filters, kernel_size, strides, activation, batch_normalization, conv_first)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconv_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_normalization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1565\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1567\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1569\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    120\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0;31m# constant from scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m       \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m.87962566103423978\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"untruncated_normal\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m       \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(self, shape, mean, stddev, dtype)\u001b[0m\n\u001b[1;32m   1075\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m     return op(\n\u001b[0;32m-> 1077\u001b[0;31m         shape=shape, mean=mean, stddev=stddev, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;31m# Compatibility aliases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[1;32m    193\u001b[0m         shape_tensor, dtype, seed=seed1, seed2=seed2)\n\u001b[1;32m    194\u001b[0m     \u001b[0mmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstddev_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]"
     ]
    }
   ],
   "source": [
    "from architectures.resnet20 import resnet20_model\n",
    "\n",
    "PRETRAINED_NUM_CLASSES = 11 # 11 supervised, 4 self-supervised\n",
    "input_shape = [96, 96, 1]\n",
    "\n",
    "model_name = \"resnet20\"\n",
    "pretraining_mode = \"supervised_learning\"\n",
    "layers = [\"flatten\", \"activation_93\", \"activation_91\"] # TODO: check layer names\n",
    "\n",
    "model = resnet20_model(input_shape, PRETRAINED_NUM_CLASSES)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.04997722 -0.00918527  0.01357953  0.08176917  0.06000052\n",
      "    -0.00139114 -0.0724242   0.03291108  0.03121746  0.04279524\n",
      "    -0.01553656  0.13586219  0.00316131 -0.01334774 -0.02930988\n",
      "    -0.05185268 -0.05685161  0.13629852  0.11300887 -0.02623674\n",
      "     0.0049383   0.04281893 -0.11455145  0.00488639  0.09588464\n",
      "    -0.09362297 -0.00974336  0.12212704 -0.09049764 -0.0637119\n",
      "    -0.07018055  0.01287864]]\n",
      "\n",
      "  [[-0.08207813  0.14111169 -0.09982266  0.00216188 -0.00656706\n",
      "    -0.14206333 -0.02288432  0.03056547  0.09128149  0.0546158\n",
      "    -0.03057618  0.06981447 -0.02749737 -0.08946207 -0.01168334\n",
      "     0.02585427  0.05832204  0.10934396 -0.06381647 -0.12536232\n",
      "     0.0932765  -0.10132461  0.0696253   0.00136797 -0.08722375\n",
      "     0.09293519 -0.13446206  0.07858631  0.04757109 -0.11601305\n",
      "     0.13609232  0.11480694]]\n",
      "\n",
      "  [[ 0.13478278 -0.01185457  0.00201017 -0.04251099  0.03003304\n",
      "    -0.11473129 -0.00936019 -0.00282069  0.09222922 -0.14126159\n",
      "    -0.03163882 -0.00796644 -0.00715981  0.02566034  0.11738871\n",
      "    -0.07686161 -0.07436649 -0.13075018  0.11859117  0.03934541\n",
      "     0.1207542  -0.10142929 -0.0587125   0.03356034  0.09078392\n",
      "    -0.11809976  0.11032264 -0.08948634 -0.12142947 -0.10646173\n",
      "    -0.03186112  0.01341572]]]\n",
      "\n",
      "\n",
      " [[[ 0.00780934 -0.01343755  0.04987699  0.08608052 -0.1069491\n",
      "    -0.1106666  -0.00289415  0.00278811 -0.12365291 -0.1392498\n",
      "     0.0614555  -0.09868424  0.10442825 -0.01942077  0.09387065\n",
      "     0.12408538 -0.09697957 -0.11953814 -0.02297033 -0.13725862\n",
      "    -0.08576182 -0.07029577 -0.11079392 -0.04975635 -0.07779158\n",
      "    -0.08355182 -0.05039936  0.09031241  0.04953837 -0.01334321\n",
      "    -0.11507186 -0.09522696]]\n",
      "\n",
      "  [[ 0.03064483 -0.06688795 -0.08254737 -0.01792749 -0.11531985\n",
      "     0.03239921 -0.07182643  0.06251273 -0.01978025  0.13377307\n",
      "     0.06356892 -0.02554899 -0.06765242  0.00388606  0.09900716\n",
      "     0.05564593 -0.09369156  0.01998076 -0.11568034 -0.0664871\n",
      "    -0.01758065 -0.12148809 -0.00815262  0.11384042  0.056402\n",
      "     0.03176789 -0.10347026  0.14125042  0.08414277  0.14128016\n",
      "     0.03312224 -0.06606595]]\n",
      "\n",
      "  [[-0.11812714  0.08874373 -0.03948238  0.01512772  0.05952807\n",
      "     0.06522988  0.04792616 -0.12605573 -0.13529678 -0.00870936\n",
      "    -0.00968714  0.04012211  0.09916379  0.03866102 -0.09250767\n",
      "     0.13757409 -0.10122769  0.09056363  0.09498738 -0.1334488\n",
      "     0.00639682  0.13420741  0.10185562  0.03893998 -0.09175655\n",
      "    -0.04204904 -0.01883845 -0.11027744  0.0702734   0.08550391\n",
      "    -0.11418662  0.0884587 ]]]\n",
      "\n",
      "\n",
      " [[[-0.09738612  0.10695058  0.11490567 -0.00150253 -0.03259491\n",
      "     0.05239275 -0.05490953  0.11552747 -0.1371048  -0.02352754\n",
      "     0.07053207 -0.03308868 -0.01653588 -0.04602803 -0.09295718\n",
      "     0.01625352  0.05055206  0.00090307 -0.12759164 -0.02994411\n",
      "     0.1174302   0.01217934  0.11949645 -0.03364857  0.05807772\n",
      "     0.0982834  -0.10494449 -0.11764479  0.02359529  0.06419405\n",
      "    -0.03845604 -0.13935103]]\n",
      "\n",
      "  [[-0.00552127 -0.0318353   0.08342017  0.06319712 -0.11692838\n",
      "    -0.01750498  0.14129688 -0.01620066 -0.03773633 -0.00022955\n",
      "    -0.03712487 -0.06600892 -0.09275281 -0.0614814   0.0246931\n",
      "     0.03294331  0.00522441 -0.07647529  0.01032965  0.06489894\n",
      "    -0.03558842 -0.10155393  0.07654151 -0.0036824   0.10744931\n",
      "    -0.04108996  0.0825901   0.13536866  0.10168833  0.09939137\n",
      "    -0.08850367 -0.10806623]]\n",
      "\n",
      "  [[-0.01587741 -0.08416501  0.08278833 -0.07613679 -0.0488605\n",
      "     0.11389185 -0.13373992 -0.08041341 -0.02585916  0.04402332\n",
      "     0.04277378  0.02271929 -0.03650755 -0.13361295 -0.01431727\n",
      "    -0.02827068  0.01995906  0.12696944  0.14136298  0.12372319\n",
      "     0.09699957  0.10769726 -0.00918584 -0.00025541  0.1246524\n",
      "    -0.09692895 -0.08583748 -0.10072637  0.11277856  0.12658976\n",
      "    -0.02031102  0.00188881]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights BEFORE loading pretrained model (second conv layer)\n",
    "print(model.layers[2].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pretrained checkpoint restored correctly: ../../../pretraining/results/self_supervised_learning/checkpoints/sonar1/mobilenet/batch_size_128/96x96_substract_mean_online_aug_width_32/ckpt-23\n"
     ]
    }
   ],
   "source": [
    "# path to pretrained model checkpoint\n",
    "pretrained_checkpoint_prefix = os.path.join(\"../../../pretraining/results/\" + pretraining_mode + \"/checkpoints/sonar1/\" + model_name + \"/batch_size_128/96x96_substract_mean_online_aug_width_32\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.5, epsilon=1)\n",
    "\n",
    "# define pretrained checkpoint model\n",
    "checkpoint_pretrained = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=model) # 4 ssl, 11 sl\n",
    "manager_pretrained = tf.train.CheckpointManager(checkpoint_pretrained, pretrained_checkpoint_prefix, max_to_keep=3)\n",
    "\n",
    "# restore model weights\n",
    "checkpoint_pretrained.restore(manager_pretrained.latest_checkpoint)\n",
    "\n",
    "if manager_pretrained.latest_checkpoint:\n",
    "    print(\"[INFO] Pretrained checkpoint restored correctly: {}\".format(manager_pretrained.latest_checkpoint))\n",
    "else:\n",
    "    print(\"[INFO] Could not restore pretrained checkpoint correctly, make sure path to pre-trained folder is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.14404939 -0.09309183  0.05454894 -0.06229801 -0.06013727\n",
      "    -0.07732987  0.07269716 -0.03821912 -0.11697425  0.1388517\n",
      "     0.08845436  0.14909086 -0.0434094   0.07132739  0.04855403\n",
      "    -0.1459768  -0.04156217  0.12690915  0.11585397 -0.02719531\n",
      "    -0.13449992 -0.04256891  0.1360308  -0.1615945   0.12728855\n",
      "     0.0988554  -0.02976339 -0.02112121 -0.12318154 -0.07028557\n",
      "     0.01778408 -0.00416138]]\n",
      "\n",
      "  [[ 0.00133723 -0.00801746 -0.12868382 -0.13219982  0.10902002\n",
      "    -0.06519885  0.12391113 -0.0785736   0.11305472 -0.05531718\n",
      "     0.0411387   0.0567715   0.06359521 -0.0998892  -0.1435193\n",
      "    -0.10393097 -0.01258101  0.15248203 -0.11573518  0.07517115\n",
      "    -0.0860673   0.0008493   0.0494826  -0.10693439 -0.01119721\n",
      "    -0.04008756 -0.09663434 -0.04191499  0.0678202   0.03121695\n",
      "    -0.15428929 -0.06734885]]\n",
      "\n",
      "  [[-0.12454671 -0.10658687 -0.02881929 -0.14558476 -0.07411117\n",
      "    -0.04570181  0.00137575  0.00256155  0.14861685  0.12742507\n",
      "     0.06354919  0.09335297  0.01787042  0.05528109 -0.06439457\n",
      "     0.07436287  0.07468322  0.03961996  0.06629568  0.06049006\n",
      "     0.00351476 -0.09949933  0.1295418   0.11717189 -0.01637852\n",
      "    -0.03883507 -0.04811847  0.11663222 -0.09129281 -0.11206447\n",
      "    -0.13382056 -0.00909827]]]\n",
      "\n",
      "\n",
      " [[[-0.05388344  0.05441418 -0.12837723 -0.02183775 -0.08582336\n",
      "    -0.01561176  0.13857374 -0.03205187 -0.02339637 -0.14301679\n",
      "     0.04329414  0.00593152  0.04406336  0.04236524 -0.04959351\n",
      "     0.03386176 -0.06303517 -0.04939976 -0.01487463  0.04141305\n",
      "    -0.00068988  0.07067118 -0.03909938 -0.10393843  0.10984906\n",
      "     0.07240268 -0.08214152  0.03228702  0.08999918  0.02311619\n",
      "     0.11098951  0.04094544]]\n",
      "\n",
      "  [[-0.00188321 -0.03358865 -0.00531636  0.01463966 -0.10119526\n",
      "     0.06697901 -0.05722759 -0.00147811 -0.00900864 -0.05001724\n",
      "    -0.12051512 -0.07697188 -0.04013479  0.12904492  0.11546247\n",
      "    -0.02125303  0.10877839 -0.10072231  0.10410361  0.13634746\n",
      "    -0.01978151  0.03710029  0.09034377 -0.0989427  -0.02132693\n",
      "     0.01493169 -0.11770552 -0.13386303 -0.08312008  0.04546061\n",
      "     0.10975662  0.14623252]]\n",
      "\n",
      "  [[ 0.02148721 -0.08122881 -0.03538341  0.04298209  0.07048514\n",
      "     0.13274135 -0.00510898  0.08306567 -0.02088917 -0.10985592\n",
      "     0.12903148  0.11409313  0.00087258  0.05705377  0.08125357\n",
      "    -0.05354698 -0.03461336 -0.04832822 -0.07317195  0.02706087\n",
      "    -0.04583281 -0.01353603 -0.04665786 -0.06627695  0.12961845\n",
      "    -0.09460057  0.12100387 -0.00790856  0.03239175  0.12942268\n",
      "    -0.07974358 -0.00360656]]]\n",
      "\n",
      "\n",
      " [[[ 0.03433191  0.14386977  0.03480404  0.03780293  0.13212499\n",
      "    -0.13338873  0.08321498 -0.06039484  0.01272877  0.0248135\n",
      "    -0.15482837  0.03080554 -0.10773932  0.1149974  -0.09046186\n",
      "     0.02402977  0.09670835  0.02322695 -0.10135086  0.10529795\n",
      "     0.11937867  0.01897962  0.11404452  0.02379823 -0.12067164\n",
      "     0.13605723  0.05997743  0.08858859 -0.06952348 -0.0404102\n",
      "    -0.12788133 -0.12751523]]\n",
      "\n",
      "  [[ 0.01689137  0.0480641  -0.02705329  0.14779943 -0.03926948\n",
      "    -0.0659373  -0.03430628  0.10868759 -0.09147737 -0.08856399\n",
      "     0.01006336 -0.05943159 -0.02819593  0.00893965  0.04827042\n",
      "    -0.08797839  0.0616488  -0.02781573 -0.01492007  0.12183929\n",
      "     0.10579551 -0.02869827 -0.00059727 -0.03790615 -0.07633289\n",
      "    -0.10916154  0.10303617 -0.093502   -0.10267456  0.01132873\n",
      "    -0.07866152  0.02703843]]\n",
      "\n",
      "  [[ 0.02754069  0.00541649  0.02748204  0.08778019 -0.08588883\n",
      "     0.16256045  0.14574225 -0.08057392  0.03499466  0.10470296\n",
      "    -0.13488604  0.02848252 -0.00037263 -0.13752995  0.13740954\n",
      "    -0.04477771  0.1851264  -0.010793    0.1238165  -0.00473857\n",
      "    -0.13011743  0.15801784 -0.08793713 -0.12674129  0.0888084\n",
      "    -0.05116467 -0.02537933 -0.05779462 -0.09087966  0.04028242\n",
      "    -0.13272785  0.1614328 ]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights AFTER loading pretrained model (second conv layer)\n",
    "print(model.layers[2].get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models up to intermediate layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate layers from model: ['conv_pw_11_relu', 'flatten', 'conv_pw_12_relu']\n"
     ]
    }
   ],
   "source": [
    "print(\"Intermediate layers from model:\", layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63297838/how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction\n",
    "model_flatten = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                               outputs=model.get_layer(layers[0]).output)\n",
    "\n",
    "model_activation_93 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                     outputs=model.get_layer(layers[1]).output)\n",
    "\n",
    "model_activation_91 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                     outputs=model.get_layer(layers[2]).output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate vector embeddings for train and test data (up to n-th layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Loading Tenorflow dataset\n",
      "[INFO] Retrieving Sonar Turned Table Supervised Data\n",
      "hdf5 dataset keys: <KeysViewHDF5 ['class_names', 'x_test', 'x_train', 'y_test', 'y_train']>\n",
      "[INFO] Data dimensions\n",
      "Train 1505\n",
      "Val 323\n",
      "Test 645\n",
      "\n",
      "[INFO] Tensorflow data dimensions\n",
      "<PrefetchDataset shapes: ((None, 96, 96, 1), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# define tensorflow dataset\n",
    "data_dir = \"../../../../../../datasets/sonar_turntable_dataset_2/marine-debris-turntable-classification-object_classes-platform-96x96.hdf5\"\n",
    "train_dataset, test_dataset = load_sonar_turnedtable_supervised(data_dir)\n",
    "\n",
    "# load tensorflow tensors individually\n",
    "x_train, y_train = next(iter(train_dataset))\n",
    "x_test, y_test = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a forward pass to generate embeddings (both train and test data) (for each n-th layer)\n",
    "\n",
    "# NOTE: when doing this all tensors are loaded into memory, this saturates NVIDIA memory (nvidia-smi)\n",
    "x_train_flatten = model_flatten([x_train], training=False)\n",
    "x_train_activation_93 = model_activation_93([x_train], training=False)\n",
    "x_train_activation_91 = model_activation_91([x_train], training=False)\n",
    "\n",
    "x_test_flatten = model_flatten([x_test], training=False)\n",
    "x_test_activation_93 = model_activation_93([x_test], training=False)\n",
    "x_test_activation_91 = model_activation_91([x_test], training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1505, 6, 6, 512), dtype=float32, numpy=\n",
       "array([[[[1.21386254e+00, 4.89381775e-02, 8.45410645e-01, ...,\n",
       "          0.00000000e+00, 4.96995270e-01, 9.05933157e-02],\n",
       "         [1.40980411e+00, 1.15261090e+00, 8.35694194e-01, ...,\n",
       "          0.00000000e+00, 5.93474329e-01, 4.82767463e-01],\n",
       "         [1.82574883e-01, 6.56372130e-01, 5.60133994e-01, ...,\n",
       "          0.00000000e+00, 6.67990267e-01, 9.42384839e-01],\n",
       "         [1.29431516e-01, 1.25769377e+00, 2.52908558e-01, ...,\n",
       "          0.00000000e+00, 5.47911167e-01, 1.50075305e+00],\n",
       "         [0.00000000e+00, 7.05164850e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.08221430e-01, 7.03265250e-01],\n",
       "         [1.43316180e-01, 8.97599578e-01, 6.38682246e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.05568409e-01]],\n",
       "\n",
       "        [[1.58779538e+00, 2.70380199e-01, 6.62188411e-01, ...,\n",
       "          0.00000000e+00, 9.18517351e-01, 0.00000000e+00],\n",
       "         [1.36984611e+00, 1.52387643e+00, 6.65007174e-01, ...,\n",
       "          5.64474225e-01, 1.26944888e+00, 0.00000000e+00],\n",
       "         [1.15218312e-01, 1.10056651e+00, 0.00000000e+00, ...,\n",
       "          9.88080502e-01, 8.42722595e-01, 0.00000000e+00],\n",
       "         [2.41711080e-01, 6.82391763e-01, 1.18062049e-01, ...,\n",
       "          8.92391920e-01, 9.17503238e-01, 3.38331610e-01],\n",
       "         [8.01368356e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.33009458e+00, 6.31139040e-01, 9.87581849e-01],\n",
       "         [3.50163549e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.07743216e+00, 4.88872319e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.67930317e+00, 0.00000000e+00, 6.10883594e-01, ...,\n",
       "          0.00000000e+00, 6.40770674e-01, 0.00000000e+00],\n",
       "         [1.31692612e+00, 1.33257222e+00, 0.00000000e+00, ...,\n",
       "          2.02301934e-01, 7.47570693e-01, 0.00000000e+00],\n",
       "         [3.54028255e-01, 1.43480206e+00, 0.00000000e+00, ...,\n",
       "          1.42425289e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [4.69609290e-01, 7.73074746e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.37829918e-01, 0.00000000e+00],\n",
       "         [7.43504584e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.55491638e-01, 7.40871966e-01, 0.00000000e+00],\n",
       "         [4.51024294e-01, 0.00000000e+00, 5.22799492e-01, ...,\n",
       "          1.58414018e+00, 0.00000000e+00, 3.75580698e-01]],\n",
       "\n",
       "        [[7.55223513e-01, 2.43446156e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.44895494e+00, 0.00000000e+00],\n",
       "         [2.37992689e-01, 7.69590557e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 7.24948108e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 6.02175832e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.17057258e-01, 3.09611231e-01],\n",
       "         [2.29788959e-01, 5.17907739e-01, 0.00000000e+00, ...,\n",
       "          2.76066422e-01, 5.44403076e-01, 0.00000000e+00],\n",
       "         [3.90599757e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.11351252e-01, 3.87470573e-01, 0.00000000e+00],\n",
       "         [5.69515169e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.46275985e-01, 0.00000000e+00, 2.04475895e-01]],\n",
       "\n",
       "        [[6.03065133e-01, 1.81254387e-01, 1.62985653e-01, ...,\n",
       "          4.45793033e-01, 1.15529406e+00, 0.00000000e+00],\n",
       "         [7.56154954e-01, 3.09719771e-01, 0.00000000e+00, ...,\n",
       "          1.91156042e+00, 1.20842910e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.65345109e-01, 0.00000000e+00, ...,\n",
       "          1.81911242e+00, 0.00000000e+00, 3.70041668e-01],\n",
       "         [0.00000000e+00, 2.00629160e-01, 0.00000000e+00, ...,\n",
       "          1.40022433e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.48094797e-01, 0.00000000e+00, 3.92494977e-01],\n",
       "         [1.10064581e-01, 0.00000000e+00, 3.84586662e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.39752233e-01]],\n",
       "\n",
       "        [[8.80364239e-01, 1.38908774e-01, 9.69308019e-02, ...,\n",
       "          1.00734603e+00, 1.31476969e-01, 1.56573400e-01],\n",
       "         [6.56927526e-01, 0.00000000e+00, 5.46266437e-01, ...,\n",
       "          1.70416558e+00, 8.26609254e-01, 3.44359756e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.23115039e+00, 8.10497880e-01, 1.03638220e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.85691655e+00, 4.63376671e-01, 4.76679295e-01],\n",
       "         [3.30108911e-01, 0.00000000e+00, 3.68238956e-01, ...,\n",
       "          1.32343161e+00, 7.18894958e-01, 0.00000000e+00],\n",
       "         [4.51950848e-01, 0.00000000e+00, 1.56692922e-01, ...,\n",
       "          8.26672494e-01, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 1.52691096e-01, 5.29016376e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.43502966e-01, 4.82692480e-01, ...,\n",
       "          0.00000000e+00, 8.17698956e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.00359893e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.86733508e-01, 0.00000000e+00, ...,\n",
       "          1.28555104e-01, 2.33236456e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.96128833e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.41390359e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.07653040e-01, 3.29929680e-01, 1.17597485e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 1.70783386e-01, ...,\n",
       "          0.00000000e+00, 4.06205714e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.19671243e-01, 4.21145827e-01, ...,\n",
       "          0.00000000e+00, 1.83619052e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.11542404e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 6.32457376e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.08643031e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.02846766e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.94382715e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[2.85702109e-01, 0.00000000e+00, 1.24083459e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.92233336e-01, 9.89120781e-01, ...,\n",
       "          0.00000000e+00, 2.70563632e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 8.75124216e-01, ...,\n",
       "          1.38954234e+00, 1.76084387e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.49925661e-01, ...,\n",
       "          9.02132750e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.55398309e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.70396245e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[7.95933366e-01, 0.00000000e+00, 6.79903626e-01, ...,\n",
       "          0.00000000e+00, 1.64485350e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.54022312e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.83697939e+00, 4.69868422e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.08654076e-01, ...,\n",
       "          5.78733504e-01, 3.30802470e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.32641780e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.08220828e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.18128037e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.36451232e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.90511560e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.36809742e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.56128395e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.27201509e+00, 0.00000000e+00, 2.52235115e-01],\n",
       "         [0.00000000e+00, 1.98683381e-01, 0.00000000e+00, ...,\n",
       "          1.79942012e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.23751953e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [5.72776973e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.75177157e-01, 2.88074195e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.84128478e-01, ...,\n",
       "          1.88957775e+00, 0.00000000e+00, 3.07772666e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 9.18155491e-01, ...,\n",
       "          1.23943233e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.46942747e-01, 0.00000000e+00, 1.76285785e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.33068621e+00, 0.00000000e+00, 6.05253614e-02]]],\n",
       "\n",
       "\n",
       "       [[[4.97658908e-01, 2.26412073e-01, 1.28878057e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.04931021e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.94786954e-01, 6.15833402e-01, ...,\n",
       "          2.00244635e-01, 1.10513580e+00, 5.58649361e-01],\n",
       "         [1.03040911e-01, 1.11017883e+00, 1.30273789e-01, ...,\n",
       "          0.00000000e+00, 1.09344733e+00, 5.84765911e-01],\n",
       "         [1.42691910e-01, 1.03211796e+00, 2.64871195e-02, ...,\n",
       "          0.00000000e+00, 3.89539629e-01, 4.24094677e-01],\n",
       "         [2.33292338e-02, 9.52406645e-01, 4.16681141e-01, ...,\n",
       "          0.00000000e+00, 5.58226347e-01, 8.26527923e-02]],\n",
       "\n",
       "        [[9.22215819e-01, 4.14413184e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.82159829e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.50354218e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.28124762e-01, 0.00000000e+00, ...,\n",
       "          1.10234261e+00, 1.60742247e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.12121868e+00, 7.57788479e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.03214610e-01, 1.14583671e+00, 0.00000000e+00],\n",
       "         [6.59933865e-01, 1.97398141e-01, 0.00000000e+00, ...,\n",
       "          8.70444536e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.05376267e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.39320302e+00, 1.40793100e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.36519694e-01, ...,\n",
       "          1.47311008e+00, 5.35422921e-01, 0.00000000e+00],\n",
       "         [4.51415032e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.23708463e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.65599966e-01, 0.00000000e+00],\n",
       "         [3.99715692e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[5.43277085e-01, 5.69180727e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.39797926e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.28812009e-01, 0.00000000e+00, 2.07650233e-02],\n",
       "         [0.00000000e+00, 2.22789854e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.73306441e-01, 0.00000000e+00, ...,\n",
       "          5.03833853e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.39736611e-01, ...,\n",
       "          3.98845226e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[2.76941031e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.58346689e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.25047827e-01, ...,\n",
       "          0.00000000e+00, 4.95000660e-01, 2.49710783e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.41210335e-02, 0.00000000e+00, ...,\n",
       "          2.22059980e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.73117429e-01, 0.00000000e+00, ...,\n",
       "          1.69370547e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.40151966e-01, 1.69803277e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[3.01103026e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.59076020e-01, 0.00000000e+00, 7.77833819e-01],\n",
       "         [2.64523566e-01, 0.00000000e+00, 7.33150840e-01, ...,\n",
       "          9.28520977e-01, 0.00000000e+00, 1.98531970e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.54606104e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.46149707e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.36316240e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.97520751e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.34823036e-01, 0.00000000e+00, 2.77273625e-01]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[5.54868579e-01, 0.00000000e+00, 2.09653452e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.95802283e-01, 2.33481854e-01, 4.39013660e-01, ...,\n",
       "          0.00000000e+00, 6.85738504e-01, 0.00000000e+00],\n",
       "         [6.18452132e-01, 2.78394729e-01, 8.34464669e-01, ...,\n",
       "          5.90230152e-02, 9.04665351e-01, 0.00000000e+00],\n",
       "         [8.51163507e-01, 8.32234383e-01, 8.65169168e-01, ...,\n",
       "          2.30508029e-01, 4.21075702e-01, 1.07643473e+00],\n",
       "         [3.37417990e-01, 8.76152217e-01, 8.20224956e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.51392376e+00],\n",
       "         [0.00000000e+00, 1.17680086e-02, 5.58582425e-01, ...,\n",
       "          5.43553233e-01, 2.61656735e-02, 1.06153272e-01]],\n",
       "\n",
       "        [[7.40259111e-01, 6.23618126e-01, 1.59319758e-01, ...,\n",
       "          0.00000000e+00, 8.03648084e-02, 0.00000000e+00],\n",
       "         [1.08002603e+00, 1.34148788e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [7.14338124e-01, 6.62054271e-02, 0.00000000e+00, ...,\n",
       "          6.33005321e-01, 1.70548058e+00, 1.08340038e-02],\n",
       "         [3.38811427e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.49380326e-01, 1.82285869e+00, 8.91632855e-01],\n",
       "         [5.66983461e-01, 2.70252258e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 9.21631515e-01, 5.82605481e-01],\n",
       "         [0.00000000e+00, 1.27941728e-01, 1.28289675e-02, ...,\n",
       "          6.45930767e-01, 5.37137985e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.65202153e+00, 1.92711979e-01, 3.46427023e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [6.58399940e-01, 0.00000000e+00, 3.79514545e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.82154924e-01, 4.51045722e-01, 0.00000000e+00, ...,\n",
       "          8.88791382e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.85798681e+00, 1.71447486e-01, 1.48875400e-01],\n",
       "         [0.00000000e+00, 2.08903059e-01, 0.00000000e+00, ...,\n",
       "          1.14160225e-01, 4.17020977e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.79270977e-01, ...,\n",
       "          7.10267484e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.40898919e+00, 6.93294346e-01, 3.30813453e-02, ...,\n",
       "          0.00000000e+00, 4.08204645e-02, 0.00000000e+00],\n",
       "         [3.68216962e-01, 1.01068199e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.85913122e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.31343973e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.75643480e-01, 0.00000000e+00, ...,\n",
       "          5.39589226e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 6.87130272e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.52528536e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.01818192e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.86673868e-01]],\n",
       "\n",
       "        [[1.16354299e+00, 2.07711473e-01, 1.53946295e-01, ...,\n",
       "          0.00000000e+00, 5.13336420e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.01600027e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.42235357e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.52194881e-01, 0.00000000e+00, ...,\n",
       "          1.03011453e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.84673083e-01, 0.00000000e+00, ...,\n",
       "          1.25499861e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.49452367e-01, 0.00000000e+00, ...,\n",
       "          5.65113485e-01, 0.00000000e+00, 2.97164977e-01],\n",
       "         [0.00000000e+00, 4.77514923e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.52172071e-01]],\n",
       "\n",
       "        [[7.69353747e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.34844124e-01, 0.00000000e+00, 1.95097715e-01],\n",
       "         [1.21529236e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          4.65871066e-01, 1.59877092e-01, 5.56281447e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.98413515e-01, 1.84804350e-01, 6.31211221e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.20745170e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.88785389e-01, ...,\n",
       "          7.97446847e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.52627841e-01, 4.34158117e-01, 4.62248385e-01, ...,\n",
       "          7.30552912e-01, 0.00000000e+00, 2.51083910e-01]]],\n",
       "\n",
       "\n",
       "       [[[6.53113246e-01, 4.54290479e-01, 3.25090051e-01, ...,\n",
       "          0.00000000e+00, 2.46574238e-01, 0.00000000e+00],\n",
       "         [7.92538345e-01, 0.00000000e+00, 6.71231508e-01, ...,\n",
       "          6.18359685e-01, 3.42639357e-01, 0.00000000e+00],\n",
       "         [3.01716439e-02, 1.43768096e+00, 3.01402528e-02, ...,\n",
       "          1.29568911e+00, 7.55373776e-01, 7.48455942e-01],\n",
       "         [7.97515333e-01, 9.62288976e-01, 7.14009881e-01, ...,\n",
       "          8.15240979e-01, 1.16498959e+00, 1.00717831e+00],\n",
       "         [5.90333879e-01, 6.40912652e-01, 4.67910796e-01, ...,\n",
       "          5.10940254e-01, 4.57203656e-01, 7.22755194e-01],\n",
       "         [1.75583541e-01, 1.72066256e-01, 1.05659497e+00, ...,\n",
       "          2.87493795e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[8.43252718e-01, 0.00000000e+00, 4.57172245e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.48493516e-01],\n",
       "         [6.10471547e-01, 1.45302888e-03, 0.00000000e+00, ...,\n",
       "          1.18889856e+00, 2.53336817e-01, 1.25075087e-01],\n",
       "         [2.51874954e-01, 6.40163124e-01, 0.00000000e+00, ...,\n",
       "          2.05259895e+00, 1.80451882e+00, 7.60612369e-01],\n",
       "         [9.21549618e-01, 7.70189703e-01, 9.86776352e-02, ...,\n",
       "          1.42471516e+00, 1.01065588e+00, 1.63200998e+00],\n",
       "         [6.41722500e-01, 7.38803446e-01, 0.00000000e+00, ...,\n",
       "          6.47588670e-01, 9.90402699e-01, 1.14861214e+00],\n",
       "         [7.94853568e-02, 4.89017427e-01, 0.00000000e+00, ...,\n",
       "          9.27468598e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.07835996e+00, 0.00000000e+00, 4.65320289e-01, ...,\n",
       "          0.00000000e+00, 9.68485832e-01, 0.00000000e+00],\n",
       "         [1.16809785e+00, 0.00000000e+00, 4.48173463e-01, ...,\n",
       "          5.73757648e-01, 1.28421974e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 9.54543471e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.18168509e-02, 3.44119132e-01],\n",
       "         [0.00000000e+00, 9.16096866e-01, 3.64798844e-01, ...,\n",
       "          1.20460756e-01, 2.30051920e-01, 1.27440298e+00],\n",
       "         [0.00000000e+00, 1.08253360e+00, 4.85471904e-01, ...,\n",
       "          4.86900285e-02, 5.25438488e-01, 2.10460052e-01],\n",
       "         [0.00000000e+00, 1.08314276e+00, 0.00000000e+00, ...,\n",
       "          6.67749107e-01, 0.00000000e+00, 5.29617257e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 5.30756533e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.34827936e+00, 0.00000000e+00],\n",
       "         [5.59777737e-01, 8.74446690e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.42847204e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.23623180e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.22674847e+00, 9.22094941e-01],\n",
       "         [7.68942475e-01, 1.47062910e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.03019905e+00, 1.85458049e-01],\n",
       "         [6.60330653e-01, 8.58195662e-01, 0.00000000e+00, ...,\n",
       "          5.26714146e-01, 9.46454048e-01, 0.00000000e+00],\n",
       "         [1.78587094e-01, 8.49398971e-01, 6.91891834e-02, ...,\n",
       "          8.68261158e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.42874813e+00, 0.00000000e+00, 5.66674769e-01, ...,\n",
       "          3.36644113e-01, 2.25867510e+00, 0.00000000e+00],\n",
       "         [5.28068662e-01, 2.41930306e-01, 0.00000000e+00, ...,\n",
       "          7.88549066e-01, 3.45656347e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.11576211e+00, 0.00000000e+00, ...,\n",
       "          1.08674037e+00, 2.33060884e+00, 7.20527470e-01],\n",
       "         [0.00000000e+00, 8.46525192e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.38700271e-01, 8.37134182e-01],\n",
       "         [0.00000000e+00, 6.48640394e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 9.23870444e-01, 4.07819837e-01, ...,\n",
       "          1.36592615e+00, 0.00000000e+00, 5.43898284e-01]],\n",
       "\n",
       "        [[1.12075758e+00, 0.00000000e+00, 2.57105172e-01, ...,\n",
       "          9.42003310e-01, 9.91547167e-01, 1.26096472e-01],\n",
       "         [6.32403135e-01, 0.00000000e+00, 3.94560039e-01, ...,\n",
       "          1.62719321e+00, 1.51517367e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.91845524e+00, 9.20094311e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.76704347e-01, 3.09583932e-01, 0.00000000e+00],\n",
       "         [3.68879378e-01, 0.00000000e+00, 1.88309938e-01, ...,\n",
       "          1.85832703e+00, 2.28459612e-01, 0.00000000e+00],\n",
       "         [4.04950887e-01, 3.59160870e-01, 9.94559675e-02, ...,\n",
       "          1.02736771e+00, 0.00000000e+00, 2.99938768e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.57726073e-01, 4.78269279e-01, 2.89182156e-01, ...,\n",
       "          0.00000000e+00, 5.77444971e-01, 0.00000000e+00],\n",
       "         [3.77552390e-01, 8.46817791e-01, 2.21524775e-01, ...,\n",
       "          4.97461766e-01, 5.34188867e-01, 8.56971443e-02],\n",
       "         [0.00000000e+00, 1.26131773e+00, 0.00000000e+00, ...,\n",
       "          2.83341169e-01, 4.16179597e-01, 1.06382358e+00],\n",
       "         [1.00784743e+00, 1.13370395e+00, 0.00000000e+00, ...,\n",
       "          2.17416748e-01, 1.47419524e+00, 0.00000000e+00],\n",
       "         [3.92637312e-01, 1.50990188e+00, 0.00000000e+00, ...,\n",
       "          3.70646417e-02, 8.23083282e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.04876149e+00, 5.16032338e-01, ...,\n",
       "          3.89874637e-01, 0.00000000e+00, 1.63580582e-01]],\n",
       "\n",
       "        [[1.35706222e+00, 2.50392646e-01, 1.28529206e-01, ...,\n",
       "          9.73118424e-01, 1.06202078e+00, 2.96067968e-02],\n",
       "         [1.07852590e+00, 8.77265871e-01, 6.59916818e-01, ...,\n",
       "          1.70621288e+00, 1.20290744e+00, 1.39084756e-01],\n",
       "         [5.90643585e-01, 9.34118390e-01, 0.00000000e+00, ...,\n",
       "          1.90188920e+00, 1.07160127e+00, 1.56916189e+00],\n",
       "         [4.97220159e-01, 1.17705953e+00, 0.00000000e+00, ...,\n",
       "          6.03450716e-01, 9.71510947e-01, 1.98160660e+00],\n",
       "         [2.33068734e-01, 1.40483224e+00, 0.00000000e+00, ...,\n",
       "          5.74225426e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.26884186e+00, 0.00000000e+00, ...,\n",
       "          7.76317716e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.14034641e+00, 1.46218777e-01, 5.61741710e-01, ...,\n",
       "          6.49898112e-01, 1.47306681e+00, 0.00000000e+00],\n",
       "         [9.33997154e-01, 1.09830832e+00, 1.10959172e+00, ...,\n",
       "          0.00000000e+00, 7.34269261e-01, 0.00000000e+00],\n",
       "         [1.25174806e-01, 9.12549317e-01, 0.00000000e+00, ...,\n",
       "          3.28876674e-02, 0.00000000e+00, 1.44126713e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.07391715e-01, 0.00000000e+00, 1.48584914e+00],\n",
       "         [0.00000000e+00, 6.99180126e-01, 0.00000000e+00, ...,\n",
       "          4.26554710e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.17238986e-01, 6.01000041e-02, ...,\n",
       "          4.56224084e-01, 0.00000000e+00, 2.51361698e-01]],\n",
       "\n",
       "        [[5.80825135e-02, 7.60677636e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.37212437e-01, 0.00000000e+00],\n",
       "         [6.84985280e-01, 8.07671130e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.14525783e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.33564508e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 7.64890969e-01, 6.04996324e-01],\n",
       "         [0.00000000e+00, 1.19725275e+00, 0.00000000e+00, ...,\n",
       "          2.99072742e-01, 2.19196707e-01, 4.63523775e-01],\n",
       "         [0.00000000e+00, 6.35608971e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.00149262e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.64133471e-01, 0.00000000e+00, ...,\n",
       "          7.66643405e-01, 0.00000000e+00, 7.93660730e-02]],\n",
       "\n",
       "        [[2.26246268e-01, 1.88237891e-01, 2.33566716e-01, ...,\n",
       "          0.00000000e+00, 1.25859392e+00, 0.00000000e+00],\n",
       "         [1.34010124e+00, 9.20340538e-01, 7.31295884e-01, ...,\n",
       "          1.96400952e+00, 1.70905030e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.25383019e+00, 0.00000000e+00, ...,\n",
       "          1.84583437e+00, 1.14905369e+00, 9.88898337e-01],\n",
       "         [0.00000000e+00, 1.61289775e+00, 0.00000000e+00, ...,\n",
       "          9.40056622e-01, 5.16195774e-01, 1.09151697e+00],\n",
       "         [0.00000000e+00, 2.25601435e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.70864153e+00],\n",
       "         [0.00000000e+00, 8.68908763e-01, 0.00000000e+00, ...,\n",
       "          8.78184676e-01, 0.00000000e+00, 6.23790801e-01]],\n",
       "\n",
       "        [[1.79624856e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.18204939e-01, 2.99267292e-01, 4.24002588e-01],\n",
       "         [1.10217623e-01, 0.00000000e+00, 7.92395353e-01, ...,\n",
       "          2.14755702e+00, 7.17249572e-01, 1.70226265e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.84304762e+00, 9.26787376e-01, 5.17188847e-01],\n",
       "         [0.00000000e+00, 3.53877187e-01, 0.00000000e+00, ...,\n",
       "          2.15315700e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.93930912e-01, 5.94902158e-01, ...,\n",
       "          1.32630420e+00, 5.10512948e-01, 0.00000000e+00],\n",
       "         [2.11916253e-01, 2.19456255e-01, 4.88787889e-01, ...,\n",
       "          1.36721027e+00, 0.00000000e+00, 0.00000000e+00]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning setup: classification with subsamples per object class (few shot learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning params\n",
    "# SAMPLES_PER_CLASS = [1, 5, 10, 20, 30, 40, 50] # NOTE: taking more samples per class since it is 88 for 50\n",
    "# SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 70, 90, 110, 130, 150, len(x_test)]\n",
    "SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 80, 110, 140, 170, 200]\n",
    "TRIALS = 10\n",
    "\n",
    "NUM_CLASSES_WATERTANK = 11\n",
    "NUM_CLASSES_TURNEDTABLE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten train & test data for SVM\n",
    "x_train_flatten = flatten(x_train_flatten.numpy())\n",
    "x_train_activation_93 = flatten(x_train_activation_93.numpy())\n",
    "x_train_activation_91 = flatten(x_train_activation_91.numpy())\n",
    "\n",
    "x_test_flatten = flatten(x_test_flatten.numpy())\n",
    "x_test_activation_93 = flatten(x_test_activation_93.numpy())\n",
    "x_test_activation_91 = flatten(x_test_activation_91.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505,)\n",
      "(645,)\n"
     ]
    }
   ],
   "source": [
    "# these two are not modified (only x_test, x_train)\n",
    "print(y_train.numpy().shape)\n",
    "print(y_test.numpy().shape)\n",
    "\n",
    "y_train = y_train.numpy() # convert from tf tensor --> numpy\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run svm tl evaluation with spc for each n-th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_with_spc(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Takes embeddings from pretrained model and evaluates transfer learning \n",
    "    with few samples per class.\n",
    "    \"\"\"\n",
    "    # NOTE: svm takes original labels (not one-hot encoding)\n",
    "    for spc in SAMPLES_PER_CLASS:\n",
    "        accuracies = []\n",
    "\n",
    "        for i in range(TRIALS):\n",
    "            x_sample, y_sample = classSampling(x_train, y_train, spc, NUM_CLASSES_TURNEDTABLE)\n",
    "\n",
    "            svm = SVC(C=1.0, decision_function_shape = 'ovo', kernel=\"linear\")\n",
    "            svm.fit(x_sample, y_sample)\n",
    "\n",
    "            train_acc = svm.score(x_sample, y_sample)\n",
    "            test_acc = svm.score(x_test, y_test)\n",
    "\n",
    "            print(\"SPC {} Train Accuracy: {:.3f}\".format(spc, train_acc))\n",
    "            print(\"SPC {} Test Accuracy: {:.3f}\".format(spc, test_acc))\n",
    "            print()\n",
    "\n",
    "            accuracies.append(test_acc)\n",
    "\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "\n",
    "        mean_acc = round(100 * mean_acc, 3)\n",
    "        std_acc = round(100 * std_acc, 3)\n",
    "\n",
    "        print(\"After {} trials - Test Accuracy is {} +- {}\".format(TRIALS, mean_acc, std_acc ))\n",
    "        print(\"------------------------------------------------------------------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.594\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.586\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.580\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.552\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.605\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.600\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.572\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.597\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.577\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.560\n",
      "\n",
      "After 10 trials - Test Accuracy is 58.217 +- 1.657\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.679\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.653\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.678\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.653\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.651\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.690\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.650\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.674\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.690\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.698\n",
      "\n",
      "After 10 trials - Test Accuracy is 67.147 +- 1.751\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.667\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.727\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.710\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.736\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.674\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.729\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.726\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "After 10 trials - Test Accuracy is 71.318 +- 2.233\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.736\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.749\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.726\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.749\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.761\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.730\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.757\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.757\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.752\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.750\n",
      "\n",
      "After 10 trials - Test Accuracy is 74.667 +- 1.131\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.752\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.743\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.752\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.791\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.798\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.757\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.772\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.774\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.778\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.803\n",
      "\n",
      "After 10 trials - Test Accuracy is 77.194 +- 1.991\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.819\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.814\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_flatten, y_train, x_test_flatten, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.620\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.681\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.713\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.691\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.688\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.690\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.662\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.699\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.712\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.729\n",
      "\n",
      "After 10 trials - Test Accuracy is 68.853 +- 2.884\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.812\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.805\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.775\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.778\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.775\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.977 +- 1.215\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.854\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.843\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.839\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.814\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.867\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.823\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.837\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.828\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.833\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.845\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.829 +- 1.446\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.874\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.848\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.865\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.870\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.881\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.876\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.850\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.879\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.881\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.867\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.899 +- 1.133\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.870\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.881\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.879\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.912\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.859\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.904\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.874\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.876\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.186 +- 1.464\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.907\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.926\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.904\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.916\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.909\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.891\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.893\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.913\n",
      "\n",
      "After 10 trials - Test Accuracy is 91.039 +- 1.133\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.932\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.921\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.909\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.919\n",
      "\n",
      "After 10 trials - Test Accuracy is 92.589 +- 0.73\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.946\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.941\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.950\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.930\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.944\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.926\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.935\n",
      "\n",
      "After 10 trials - Test Accuracy is 93.907 +- 0.704\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.938\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.955\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.944\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.941\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.949\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.938\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.952\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.961\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.791 +- 0.718\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.941\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.957\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.949\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.947\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.943\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.936\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.943\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.667 +- 0.56\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_activation_93, y_train, x_test_activation_93, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.648\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.684\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.628\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.670\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.647\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.625\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.662\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.679\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.640\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.569\n",
      "\n",
      "After 10 trials - Test Accuracy is 64.512 +- 3.174\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.722\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.738\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.744\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.707\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.718\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.741\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.729\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.732\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.724\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.712\n",
      "\n",
      "After 10 trials - Test Accuracy is 72.667 +- 1.179\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.811\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.780\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.766\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.795\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.769\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.794\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.771\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.784\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.780\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.778\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.279 +- 1.316\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.803\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.797\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.812\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.802\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.840\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.811\n",
      "\n",
      "After 10 trials - Test Accuracy is 80.961 +- 1.115\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.809\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.847\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.845\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.840\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.843\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.853\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.839\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.736 +- 1.132\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.871\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.865\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.881\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.842\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.864\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.864\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.854\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.854\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.859\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.878\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.31 +- 1.101\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.867\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.879\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.893\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.876\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.887\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.870\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.874\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.901\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.264 +- 1.052\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.876\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.884\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.890\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.891\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.898\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.890\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.898\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.868 +- 0.608\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.910\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.913\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.893\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.895\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.899\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.901\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.357 +- 0.619\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.899\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.893\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.905\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.918\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.895\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.902\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.904\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.905\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.901\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.895\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.171 +- 0.691\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_activation_91, y_train, x_test_activation_91, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rotnet]",
   "language": "python",
   "name": "conda-env-rotnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
