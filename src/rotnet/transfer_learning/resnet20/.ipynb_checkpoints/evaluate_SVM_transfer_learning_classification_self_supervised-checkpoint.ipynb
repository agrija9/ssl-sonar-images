{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate transfer learning on Turnedtable Watertank (Dataset 2)  using an SVM Classifier: Self-supervised approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Tensorflow for GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tensorflow Version: 2.2.0\n",
      "[INFO] Tensorflow built with CUDA\n",
      "[INFO] Number GPUs Available:  1\n",
      "[INFO] List of GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(\"[INFO] Tensorflow Version:\", tf.__version__)\n",
    "\n",
    "if tf.config.list_physical_devices(\"GPU\") and tf.test.is_built_with_cuda():\n",
    "    print(\"[INFO] Tensorflow built with CUDA\")\n",
    "    print(\"[INFO] Number GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    print(\"[INFO] List of GPU devices:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "    physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    # tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "else:\n",
    "    print(\"[ERROR] GPU not detected, make sure tensorflow-gpu is installed and that GPU is recognized\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "def flatten(x):\n",
    "    return x.reshape((x.shape[0], -1))\n",
    "\n",
    "def classSampling(X, y, samplesPerClass, numberOfClasses):\n",
    "    X_ret = np.zeros((samplesPerClass * numberOfClasses, X.shape[1]), dtype = np.float32)\n",
    "    y_ret = np.zeros((samplesPerClass * numberOfClasses), dtype = np.uint8)\n",
    "    count = 0\n",
    "\n",
    "    for classIdx in range(numberOfClasses):\n",
    "        indices = np.where(y == classIdx)[0]\n",
    "\n",
    "        #if len(indices) < samplesPerClass:\n",
    "        #    raise IndexError(\"Not enough samples for class {} to produce {} samples per class. Only {} class samples available\".format(classIdx, samplesPerClass, len(indices)))\n",
    "\n",
    "        doResample = len(indices) < samplesPerClass\n",
    "\n",
    "        chosenIndices = np.random.choice(indices, samplesPerClass, replace = doResample)\n",
    "\n",
    "        for ci in chosenIndices:\n",
    "            X_ret[count] = X[ci]\n",
    "            y_ret[count] = y[ci]\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    return X_ret, y_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarTurnedTableSupervised(object):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def _normalize_images(self, images):\n",
    "        \"\"\"\n",
    "        Normalize sonar images by 1/255.\n",
    "        \"\"\"\n",
    "        return [element/255.0 for element in images]\n",
    "\n",
    "    def get_sonar_data(self):\n",
    "        \"\"\"\n",
    "        Reads from HDF5 file containing sonar data (resized to fix dims).\n",
    "        Returns list of np arrays containing image data.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"[INFO] Retrieving Sonar Turned Table Supervised Data\")\n",
    "\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            # list all groups\n",
    "            print(\"hdf5 dataset keys: %s\" % f.keys())\n",
    "\n",
    "            # get images and labels\n",
    "            x_train = f[\"x_train\"][...].astype(np.float32)\n",
    "            y_train = f[\"y_train\"][...]\n",
    "\n",
    "            x_test = f[\"x_test\"][...].astype(np.float32)\n",
    "            y_test = f[\"y_test\"][...]\n",
    "\n",
    "            _, x_val, _, y_val = train_test_split(x_test, y_test, train_size=0.5)\n",
    "\n",
    "            print(\"[INFO] Data dimensions\")\n",
    "            print(\"Train\", len(x_train))\n",
    "            print(\"Val\", len(x_val))\n",
    "            print(\"Test\", len(x_test))\n",
    "\n",
    "            # matias normalization\n",
    "            # multiply by 255 because hdf5 file comes as 1/255\n",
    "            x_train *= 255.0\n",
    "            x_val *= 255.0\n",
    "            x_test *= 255.0\n",
    "\n",
    "            x_train -= 84.51\n",
    "            x_val -= 84.51\n",
    "            x_test  -= 84.51\n",
    "\n",
    "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "    \n",
    "def load_sonar_turnedtable_supervised(file_path):\n",
    "    \"\"\"\n",
    "    Loads test data from turnedtable dataset.\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print(\"[INFO] Loading Tenorflow dataset\")\n",
    "\n",
    "    dataset_object = SonarTurnedTableSupervised(file_path)\n",
    "\n",
    "    # Read data\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = dataset_object.get_sonar_data()\n",
    "\n",
    "    # Train data\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(len(x_train))\n",
    "    train_dataset = train_dataset.prefetch(25)\n",
    "\n",
    "    # Validation data\n",
    "    # val_dataset = tf.data.Dataset.from_tensor_slices((x_val, labels_val))\n",
    "    # val_dataset = val_dataset.shuffle(buffer_size=len(x_val)).batch(batch_size)\n",
    "    # val_dataset = val_dataset.prefetch(25)\n",
    "\n",
    "    # Test data\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = test_dataset.shuffle(buffer_size=len(x_test)).batch(len(x_test)) # feed full test set\n",
    "    test_dataset = test_dataset.prefetch(25)\n",
    "\n",
    "    print()\n",
    "    print(\"[INFO] Tensorflow data dimensions\")\n",
    "    # print(train_dataset)\n",
    "    # print(val_dataset)\n",
    "    print(test_dataset)\n",
    "\n",
    "    # return train_dataset, val_dataset, test_dataset\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 96, 96, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 96, 96, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 96, 96, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 96, 32)   9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 96, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 96, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 96, 96, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 96, 96, 32)   0           activation[0][0]                 \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 96, 32)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 96, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 96, 96, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 96, 96, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 96, 96, 32)   9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 96, 96, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 96, 96, 32)   0           activation_2[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 96, 96, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 96, 96, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 96, 96, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 96, 96, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 96, 96, 32)   9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 96, 96, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 96, 96, 32)   0           activation_4[0][0]               \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 96, 96, 32)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 48, 48, 64)   18496       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 48, 48, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 48, 48, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 48, 48, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 48, 48, 64)   2112        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 48, 48, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 48, 64)   0           conv2d_9[0][0]                   \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 48, 48, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 48, 48, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 48, 48, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 48, 48, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 48, 48, 64)   36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 48, 48, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 48, 48, 64)   0           activation_8[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 48, 48, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 48, 48, 64)   36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 48, 48, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 48, 48, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 48, 48, 64)   36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 48, 48, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 48, 48, 64)   0           activation_10[0][0]              \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 48, 48, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 24, 24, 128)  73856       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 24, 24, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 24, 24, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 24, 24, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 24, 24, 128)  8320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 24, 24, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 24, 24, 128)  0           conv2d_16[0][0]                  \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 24, 24, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 24, 24, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 24, 24, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 24, 24, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 24, 24, 128)  147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 24, 24, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 24, 24, 128)  0           activation_14[0][0]              \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 24, 24, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 24, 24, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 24, 24, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 24, 24, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 24, 24, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 24, 24, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 24, 24, 128)  0           activation_16[0][0]              \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 24, 24, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 3, 3, 128)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1152)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            4612        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,091,268\n",
      "Trainable params: 1,088,516\n",
      "Non-trainable params: 2,752\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from architectures.resnet20 import resnet20_model\n",
    "\n",
    "NUM_CLASSES_TURNEDTABLE = 12\n",
    "PRETRAINED_NUM_CLASSES = 4 # 11 supervised, 4 self-supervised\n",
    "input_shape = [96, 96, 1]\n",
    "\n",
    "model_name = \"resnet20\"\n",
    "pretraining_mode = \"self_supervised_learning\"\n",
    "# layers = [\"flatten\", \"activation_93\", \"activation_91\"] # TODO: check layer names\n",
    "layers = [\"flatten\", \"activation_18\", \"activation_17\"]\n",
    "\n",
    "model = resnet20_model(input_shape, PRETRAINED_NUM_CLASSES)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-1.40673593e-01  1.69926479e-01  2.65265834e-02  3.41628343e-02\n",
      "    -8.52224112e-01  1.98701397e-01  1.60149157e-01 -7.29749858e-01\n",
      "     5.91268659e-01  1.80942982e-01 -4.04706925e-01  2.29352623e-01\n",
      "    -1.41822442e-01  9.22616363e-01 -4.78315577e-02 -2.61976779e-01\n",
      "    -2.97128677e-01  1.19378746e-01  1.62915483e-01 -8.10958743e-01\n",
      "     6.61827326e-01 -2.82247514e-01 -3.42580646e-01  1.99071109e-01\n",
      "     1.02937984e+00  1.75896123e-01  1.53842598e-01 -1.04033031e-01\n",
      "     1.68776602e-01 -7.70219937e-02 -2.53956348e-01 -1.04093075e+00]]\n",
      "\n",
      "  [[-2.86563158e-01 -1.04924656e-01 -3.72057229e-01 -1.00908071e-01\n",
      "    -5.49394369e-01  5.42090893e-01 -8.82983088e-01 -5.11450052e-01\n",
      "     3.91836882e-01 -4.45679545e-01  5.41264594e-01  2.30427712e-01\n",
      "    -2.67545015e-01 -7.30590641e-01  5.73210061e-01 -8.95664990e-01\n",
      "     4.23214197e-01 -6.77166462e-01 -1.09755456e-01  8.97730827e-01\n",
      "    -3.02762836e-01 -7.15198159e-01 -4.37221766e-01  7.14848280e-01\n",
      "    -7.23701358e-01  5.12587428e-01  5.93150795e-01 -1.09591797e-01\n",
      "    -1.06198713e-01 -5.88773429e-01 -9.34794247e-01 -1.61076728e-02]]\n",
      "\n",
      "  [[-2.34723985e-01 -4.34629805e-02  4.28622633e-01  4.35415357e-02\n",
      "     6.30534068e-02  7.39401102e-01 -8.11905086e-01  1.25391170e-01\n",
      "    -1.71565473e-01  7.13735640e-01 -1.49183542e-01  4.27111566e-01\n",
      "     3.57654780e-01 -1.69052511e-01 -1.02869964e+00  4.06304210e-01\n",
      "    -5.96937776e-01  1.49251550e-01  6.34133995e-01  2.19367728e-01\n",
      "    -6.33659124e-01 -5.66938877e-01  2.89791495e-01 -8.59650970e-02\n",
      "     3.15787762e-01 -6.21273220e-01  2.23614499e-01  8.83582294e-01\n",
      "     7.36073375e-01 -4.12566215e-01  2.29252711e-01 -4.94097769e-01]]]\n",
      "\n",
      "\n",
      " [[[-2.82896340e-01  2.20270038e-01  1.47243351e-01 -2.98374981e-01\n",
      "     4.89006221e-01  3.22797447e-01  8.71477649e-02 -5.63049614e-01\n",
      "    -3.21671396e-01  5.47918499e-01 -5.32391630e-02  6.56793475e-01\n",
      "     4.30029094e-01  1.19030751e-01 -3.82153660e-01  6.48686647e-01\n",
      "    -9.64782387e-02 -5.39528310e-01  1.38149753e-01  4.75896806e-01\n",
      "     3.28719229e-01 -1.76986337e-01 -1.59375034e-02  2.22857311e-01\n",
      "    -4.97265130e-01 -3.54841232e-01  2.69478083e-01  9.48846564e-02\n",
      "    -7.34761283e-02 -4.95806485e-01 -3.77677202e-01 -8.32379758e-01]]\n",
      "\n",
      "  [[-7.95727074e-01 -7.67622113e-01  6.50785983e-01 -4.88455296e-01\n",
      "     4.47598368e-01  4.31203127e-01  6.07289433e-01  2.46769860e-02\n",
      "    -2.17193831e-03  1.37114376e-02 -8.64355385e-01 -2.43833140e-01\n",
      "     6.69839025e-01 -5.10955572e-01 -5.73093772e-01 -2.67842352e-01\n",
      "     7.63560534e-01 -6.14182651e-01  7.59290636e-01  6.36706233e-01\n",
      "    -9.43784118e-01  7.86614716e-02 -3.09210092e-01 -3.86263460e-01\n",
      "     6.92206264e-01 -1.17224477e-01  3.73884067e-02 -6.06034994e-01\n",
      "     2.54386008e-01 -1.65703550e-01  7.68998086e-01  4.66649860e-01]]\n",
      "\n",
      "  [[ 4.00806934e-01  3.06885004e-01  4.94838655e-01  6.40885651e-01\n",
      "    -1.16551727e-01  4.36564863e-01  8.07913721e-01 -8.86710212e-02\n",
      "    -3.29351336e-01  8.60109329e-01  8.65474284e-01 -6.63608536e-02\n",
      "     8.16218257e-01 -2.49781132e-01 -6.55349158e-03 -3.02828908e-01\n",
      "     1.04705326e-01  3.77421498e-01 -5.61741233e-01  4.80067253e-01\n",
      "     6.39038563e-01 -5.62650323e-01  3.28038454e-01  6.78055882e-01\n",
      "    -6.15675628e-01 -7.14058280e-01  5.56672812e-01  9.11804557e-01\n",
      "     5.56619704e-01  2.55873203e-01 -7.22211227e-02  5.84857047e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.41816217e-01  6.22093022e-01  4.22555596e-01  9.39887762e-01\n",
      "    -7.37352490e-01 -3.23892653e-01 -3.15397441e-01 -2.65377194e-01\n",
      "     3.58517864e-05 -1.17604703e-01  6.55600309e-01  6.12691939e-01\n",
      "    -3.24819982e-02 -3.39280784e-01  6.89449385e-02 -9.64942813e-01\n",
      "    -5.81828132e-02  9.17149484e-01  5.01750827e-01  2.54540741e-01\n",
      "    -5.78605771e-01 -5.15033938e-02 -6.10321105e-01  2.03060225e-01\n",
      "     1.98160395e-01 -1.40684396e-01  6.58975691e-02 -1.36401832e-01\n",
      "    -4.79646437e-02 -1.57543346e-02 -4.72245425e-01  3.05009067e-01]]\n",
      "\n",
      "  [[ 1.58400953e-01  5.25051430e-02 -4.19591784e-01 -5.89119010e-02\n",
      "    -3.74236822e-01 -2.84234464e-01 -5.64941049e-01 -1.44927651e-01\n",
      "     6.26421809e-01  3.26700419e-01 -5.41976869e-01  6.38682187e-01\n",
      "     3.48889083e-02 -8.72239053e-01  9.94179964e-01 -4.97665733e-01\n",
      "     2.49382779e-01 -4.66971934e-01  2.39206087e-02 -3.08197528e-01\n",
      "     7.14735210e-01 -2.10534468e-01 -5.03604233e-01  4.54295188e-01\n",
      "     1.65689185e-01 -1.50458574e-01  4.87502426e-01  2.78018475e-01\n",
      "     3.01461309e-01 -3.08143497e-01 -6.49979889e-01 -4.15515304e-01]]\n",
      "\n",
      "  [[ 2.86285818e-01 -2.10338041e-01  2.25566283e-01  2.67606806e-02\n",
      "    -7.23202288e-01  7.23178685e-01  5.51326692e-01 -1.48461908e-01\n",
      "     4.44524139e-01 -6.31107390e-01 -5.96887231e-01 -2.06618965e-01\n",
      "    -6.25679553e-01  1.70471296e-01 -3.79958540e-01 -6.19101226e-01\n",
      "     1.21486120e-01  5.93476117e-01  2.64885202e-02  4.35013294e-01\n",
      "    -5.66394150e-01 -4.90300320e-02 -1.96571350e-01 -7.03159392e-01\n",
      "     2.64268875e-01  8.50156367e-01  4.67126280e-01  5.84971249e-01\n",
      "     1.99445590e-01 -2.75504645e-02  3.79447877e-01  1.98314235e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights BEFORE loading pretrained model (second conv layer)\n",
    "print(model.layers[1].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pretrained checkpoint restored correctly: ../../../pretraining/results/self_supervised_learning/checkpoints/sonar1/resnet20/batch_size_128/96x96_substract_mean_online_aug_width_32/ckpt-21\n"
     ]
    }
   ],
   "source": [
    "# path to pretrained model checkpoint\n",
    "pretrained_checkpoint_prefix = os.path.join(\"../../../pretraining/results/\" + pretraining_mode + \"/checkpoints/sonar1/\" + model_name + \"/batch_size_128/96x96_substract_mean_online_aug_width_32\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.5, epsilon=1)\n",
    "\n",
    "# define pretrained checkpoint model\n",
    "checkpoint_pretrained = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=model) # 4 ssl, 11 sl\n",
    "manager_pretrained = tf.train.CheckpointManager(checkpoint_pretrained, pretrained_checkpoint_prefix, max_to_keep=3)\n",
    "\n",
    "# restore model weights\n",
    "checkpoint_pretrained.restore(manager_pretrained.latest_checkpoint)\n",
    "\n",
    "if manager_pretrained.latest_checkpoint:\n",
    "    print(\"[INFO] Pretrained checkpoint restored correctly: {}\".format(manager_pretrained.latest_checkpoint))\n",
    "else:\n",
    "    print(\"[INFO] Could not restore pretrained checkpoint correctly, make sure path to pre-trained folder is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.15665546  0.8736606   0.4524331  -0.17387402 -0.06019677\n",
      "    -0.8110342   0.00777892 -0.17976741  0.5137232  -0.00923039\n",
      "     0.46582806 -0.2888845  -0.8801327   0.48167223 -0.2529096\n",
      "    -0.6543446   0.3862048   0.6425645   0.01238315  0.22614734\n",
      "     0.45380807 -0.5377274   0.1584441   0.09060708  0.16537999\n",
      "    -0.6425707   0.4733188   0.32461873 -0.36615193  1.0190421\n",
      "    -0.8967734   0.00528878]]\n",
      "\n",
      "  [[-0.3395558  -1.046582    0.2632137  -0.09394844  0.4540797\n",
      "     0.57875085  0.33806995  0.54879385 -0.0290968  -0.5666749\n",
      "    -0.42463067 -0.12701213 -0.1178494   0.87143755 -0.22825968\n",
      "     0.24024971  0.38119063 -0.27140114  0.6005567  -0.6968887\n",
      "    -0.29758188  0.8830861   0.259353   -0.3039734   0.31943595\n",
      "     0.01892374  0.0588457  -0.23642947 -0.47847977 -0.69204164\n",
      "     0.5831095  -0.06247765]]\n",
      "\n",
      "  [[-0.5469783   0.3660456  -0.1595695  -0.18146332 -0.5641104\n",
      "    -0.2058276   0.47436017 -0.34118295  0.25013068 -0.5287826\n",
      "    -0.52772903 -0.10278388  0.29210457 -0.27043337  0.12815121\n",
      "    -0.5542803   0.31866345  0.877338   -0.44607258  0.52777165\n",
      "    -0.33089188  0.71873236  0.6171545  -0.06787722 -0.33630013\n",
      "     0.02934843  0.51673216 -0.5886091   0.5319002   0.32697544\n",
      "     0.2204763   0.25806513]]]\n",
      "\n",
      "\n",
      " [[[-0.1810513  -0.01105253 -0.1332305  -0.57006294 -0.88800836\n",
      "    -0.15192835  0.15618873 -0.47229573 -0.5665641  -0.3446266\n",
      "    -0.67063606  0.81229293  0.1826906  -0.27501556  0.25217494\n",
      "    -0.11162234  0.34709242 -0.33680484 -0.5709904  -1.0759933\n",
      "     0.48337168 -0.32771856  0.12710397  0.1426535   0.5110552\n",
      "     0.3803201  -0.94404864  0.17111059  0.06336274 -0.03541694\n",
      "    -0.2013546  -0.17478903]]\n",
      "\n",
      "  [[ 0.5949022   0.36054376 -0.62070787  0.14888233 -0.36900458\n",
      "     0.17316994  0.44670847  0.19353369 -0.0150384  -0.13344617\n",
      "    -0.529598   -0.25401226 -0.42572582  0.05394522 -0.25329974\n",
      "    -0.13894302 -0.29050124 -0.75864047  0.40136993  0.314377\n",
      "    -0.1800855   0.40869293  0.22766872  0.14301482 -0.99196225\n",
      "     0.7214736  -0.4681049  -0.7851007  -0.6948498  -0.4115982\n",
      "     0.18993117 -0.525015  ]]\n",
      "\n",
      "  [[ 0.13639687  0.26834393 -0.5409246   0.29833448 -0.6610716\n",
      "    -0.40513527 -1.002718    0.10378059  0.64426917  0.36587152\n",
      "    -0.604003    0.8549913  -0.00914775  0.5769913  -0.95972955\n",
      "     0.04625061 -0.64864653 -0.339183    0.11719902  0.67767483\n",
      "     0.2779942  -0.96074265 -0.3977301   0.2365364  -0.41325876\n",
      "    -1.0284404   0.30452785 -0.47251165  0.10489486 -0.23200712\n",
      "     0.01103744  0.40792224]]]\n",
      "\n",
      "\n",
      " [[[-0.01187482  0.5616028   0.522962   -0.77021956 -0.5950572\n",
      "     0.8472449   0.36929968  0.37470812 -0.51060504  0.3675646\n",
      "    -0.29482618  0.4984031   0.40576988  0.66458106 -0.91131246\n",
      "     0.06176573 -0.02688981  0.85909253 -0.12785268  0.23045862\n",
      "     0.23764984  0.35097983  0.05811747  0.487645   -0.07846242\n",
      "     0.27801678  0.5649571   0.9564974   0.59024644 -0.25161615\n",
      "    -0.28971997 -0.3263172 ]]\n",
      "\n",
      "  [[ 0.14566794  0.7397408   0.8838379   0.77660614  0.21296793\n",
      "    -0.22581783 -0.51518416 -0.36511132  0.39884987  0.29005802\n",
      "     0.3813989   0.15960267 -0.39646813 -0.45028958 -0.32525566\n",
      "    -0.6467414  -0.10401994  0.5708129   0.17279838 -0.13615134\n",
      "     0.42715967  0.06586713 -0.13695799  0.00433036 -0.04496729\n",
      "    -0.9178204   0.23650345 -0.10692862  0.31637815  1.0532244\n",
      "     0.48739922 -0.6941706 ]]\n",
      "\n",
      "  [[-0.3701603  -0.30137128  0.5516773   0.23431258  0.3035633\n",
      "    -0.753402    0.61430776  0.8888841  -0.516605    0.5528533\n",
      "     0.764834    0.26668212  0.5110653   0.80168     0.36020356\n",
      "    -0.25511885  0.9446311   0.58408123 -0.19741818 -0.07840554\n",
      "     0.22847125  0.3187075   0.04556654 -0.3741764   0.36805546\n",
      "    -0.09012689 -0.7136122   0.5559298  -0.05789012  0.3470588\n",
      "     0.82072407  0.52400625]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights AFTER loading pretrained model (second conv layer)\n",
    "print(model.layers[1].get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models up to intermediate layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate layers from model: ['flatten', 'activation_18', 'activation_17']\n"
     ]
    }
   ],
   "source": [
    "print(\"Intermediate layers from model:\", layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63297838/how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction\n",
    "model_flatten = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                               outputs=model.get_layer(layers[0]).output)\n",
    "\n",
    "model_activation_93 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                     outputs=model.get_layer(layers[1]).output)\n",
    "\n",
    "model_activation_91 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                     outputs=model.get_layer(layers[2]).output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate vector embeddings for train and test data (up to n-th layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Loading Tenorflow dataset\n",
      "[INFO] Retrieving Sonar Turned Table Supervised Data\n",
      "hdf5 dataset keys: <KeysViewHDF5 ['class_names', 'x_test', 'x_train', 'y_test', 'y_train']>\n",
      "[INFO] Data dimensions\n",
      "Train 1505\n",
      "Val 323\n",
      "Test 645\n",
      "\n",
      "[INFO] Tensorflow data dimensions\n",
      "<PrefetchDataset shapes: ((None, 96, 96, 1), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# define tensorflow dataset\n",
    "data_dir = \"../../../../../../datasets/sonar_turntable_dataset_2/marine-debris-turntable-classification-object_classes-platform-96x96.hdf5\"\n",
    "train_dataset, test_dataset = load_sonar_turnedtable_supervised(data_dir)\n",
    "\n",
    "# load tensorflow tensors individually\n",
    "x_train, y_train = next(iter(train_dataset))\n",
    "x_test, y_test = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1505,32,96,96] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m    927\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: Expecting int64_t value for attr strides, got numpy.int32",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-56b2993fe1d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# NOTE: when doing this all tensors are loaded into memory, this saturates NVIDIA memory (nvidia-smi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train_flatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx_train_activation_93\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_activation_93\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_train_activation_91\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_activation_91\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    717\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m   1104\u001b[0m           call_from_convolution=False)\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2012\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[1;32m   1021\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1022\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1023\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1505,32,96,96] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "# perform a forward pass to generate embeddings (both train and test data) (for each n-th layer)\n",
    "\n",
    "# NOTE: when doing this all tensors are loaded into memory, this saturates NVIDIA memory (nvidia-smi)\n",
    "x_train_flatten = model_flatten([x_train], training=False)\n",
    "x_train_activation_93 = model_activation_93([x_train], training=False)\n",
    "x_train_activation_91 = model_activation_91([x_train], training=False)\n",
    "\n",
    "x_test_flatten = model_flatten([x_test], training=False)\n",
    "x_test_activation_93 = model_activation_93([x_test], training=False)\n",
    "x_test_activation_91 = model_activation_91([x_test], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1505, 6, 6, 512), dtype=float32, numpy=\n",
       "array([[[[1.21386254e+00, 4.89381775e-02, 8.45410645e-01, ...,\n",
       "          0.00000000e+00, 4.96995270e-01, 9.05933157e-02],\n",
       "         [1.40980411e+00, 1.15261090e+00, 8.35694194e-01, ...,\n",
       "          0.00000000e+00, 5.93474329e-01, 4.82767463e-01],\n",
       "         [1.82574883e-01, 6.56372130e-01, 5.60133994e-01, ...,\n",
       "          0.00000000e+00, 6.67990267e-01, 9.42384839e-01],\n",
       "         [1.29431516e-01, 1.25769377e+00, 2.52908558e-01, ...,\n",
       "          0.00000000e+00, 5.47911167e-01, 1.50075305e+00],\n",
       "         [0.00000000e+00, 7.05164850e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.08221430e-01, 7.03265250e-01],\n",
       "         [1.43316180e-01, 8.97599578e-01, 6.38682246e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.05568409e-01]],\n",
       "\n",
       "        [[1.58779538e+00, 2.70380199e-01, 6.62188411e-01, ...,\n",
       "          0.00000000e+00, 9.18517351e-01, 0.00000000e+00],\n",
       "         [1.36984611e+00, 1.52387643e+00, 6.65007174e-01, ...,\n",
       "          5.64474225e-01, 1.26944888e+00, 0.00000000e+00],\n",
       "         [1.15218312e-01, 1.10056651e+00, 0.00000000e+00, ...,\n",
       "          9.88080502e-01, 8.42722595e-01, 0.00000000e+00],\n",
       "         [2.41711080e-01, 6.82391763e-01, 1.18062049e-01, ...,\n",
       "          8.92391920e-01, 9.17503238e-01, 3.38331610e-01],\n",
       "         [8.01368356e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.33009458e+00, 6.31139040e-01, 9.87581849e-01],\n",
       "         [3.50163549e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.07743216e+00, 4.88872319e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.67930317e+00, 0.00000000e+00, 6.10883594e-01, ...,\n",
       "          0.00000000e+00, 6.40770674e-01, 0.00000000e+00],\n",
       "         [1.31692612e+00, 1.33257222e+00, 0.00000000e+00, ...,\n",
       "          2.02301934e-01, 7.47570693e-01, 0.00000000e+00],\n",
       "         [3.54028255e-01, 1.43480206e+00, 0.00000000e+00, ...,\n",
       "          1.42425289e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [4.69609290e-01, 7.73074746e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.37829918e-01, 0.00000000e+00],\n",
       "         [7.43504584e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.55491638e-01, 7.40871966e-01, 0.00000000e+00],\n",
       "         [4.51024294e-01, 0.00000000e+00, 5.22799492e-01, ...,\n",
       "          1.58414018e+00, 0.00000000e+00, 3.75580698e-01]],\n",
       "\n",
       "        [[7.55223513e-01, 2.43446156e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.44895494e+00, 0.00000000e+00],\n",
       "         [2.37992689e-01, 7.69590557e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 7.24948108e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 6.02175832e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.17057258e-01, 3.09611231e-01],\n",
       "         [2.29788959e-01, 5.17907739e-01, 0.00000000e+00, ...,\n",
       "          2.76066422e-01, 5.44403076e-01, 0.00000000e+00],\n",
       "         [3.90599757e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.11351252e-01, 3.87470573e-01, 0.00000000e+00],\n",
       "         [5.69515169e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.46275985e-01, 0.00000000e+00, 2.04475895e-01]],\n",
       "\n",
       "        [[6.03065133e-01, 1.81254387e-01, 1.62985653e-01, ...,\n",
       "          4.45793033e-01, 1.15529406e+00, 0.00000000e+00],\n",
       "         [7.56154954e-01, 3.09719771e-01, 0.00000000e+00, ...,\n",
       "          1.91156042e+00, 1.20842910e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.65345109e-01, 0.00000000e+00, ...,\n",
       "          1.81911242e+00, 0.00000000e+00, 3.70041668e-01],\n",
       "         [0.00000000e+00, 2.00629160e-01, 0.00000000e+00, ...,\n",
       "          1.40022433e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.48094797e-01, 0.00000000e+00, 3.92494977e-01],\n",
       "         [1.10064581e-01, 0.00000000e+00, 3.84586662e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.39752233e-01]],\n",
       "\n",
       "        [[8.80364239e-01, 1.38908774e-01, 9.69308019e-02, ...,\n",
       "          1.00734603e+00, 1.31476969e-01, 1.56573400e-01],\n",
       "         [6.56927526e-01, 0.00000000e+00, 5.46266437e-01, ...,\n",
       "          1.70416558e+00, 8.26609254e-01, 3.44359756e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.23115039e+00, 8.10497880e-01, 1.03638220e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.85691655e+00, 4.63376671e-01, 4.76679295e-01],\n",
       "         [3.30108911e-01, 0.00000000e+00, 3.68238956e-01, ...,\n",
       "          1.32343161e+00, 7.18894958e-01, 0.00000000e+00],\n",
       "         [4.51950848e-01, 0.00000000e+00, 1.56692922e-01, ...,\n",
       "          8.26672494e-01, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 1.52691096e-01, 5.29016376e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.43502966e-01, 4.82692480e-01, ...,\n",
       "          0.00000000e+00, 8.17698956e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.00359893e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.86733508e-01, 0.00000000e+00, ...,\n",
       "          1.28555104e-01, 2.33236456e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.96128833e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.41390359e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.07653040e-01, 3.29929680e-01, 1.17597485e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 1.70783386e-01, ...,\n",
       "          0.00000000e+00, 4.06205714e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.19671243e-01, 4.21145827e-01, ...,\n",
       "          0.00000000e+00, 1.83619052e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.11542404e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 6.32457376e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.08643031e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.02846766e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.94382715e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[2.85702109e-01, 0.00000000e+00, 1.24083459e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.92233336e-01, 9.89120781e-01, ...,\n",
       "          0.00000000e+00, 2.70563632e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 8.75124216e-01, ...,\n",
       "          1.38954234e+00, 1.76084387e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.49925661e-01, ...,\n",
       "          9.02132750e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.55398309e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.70396245e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[7.95933366e-01, 0.00000000e+00, 6.79903626e-01, ...,\n",
       "          0.00000000e+00, 1.64485350e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.54022312e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.83697939e+00, 4.69868422e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.08654076e-01, ...,\n",
       "          5.78733504e-01, 3.30802470e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.32641780e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.08220828e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.18128037e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.36451232e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.90511560e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.36809742e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.56128395e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.27201509e+00, 0.00000000e+00, 2.52235115e-01],\n",
       "         [0.00000000e+00, 1.98683381e-01, 0.00000000e+00, ...,\n",
       "          1.79942012e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.23751953e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [5.72776973e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.75177157e-01, 2.88074195e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.84128478e-01, ...,\n",
       "          1.88957775e+00, 0.00000000e+00, 3.07772666e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 9.18155491e-01, ...,\n",
       "          1.23943233e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.46942747e-01, 0.00000000e+00, 1.76285785e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.33068621e+00, 0.00000000e+00, 6.05253614e-02]]],\n",
       "\n",
       "\n",
       "       [[[4.97658908e-01, 2.26412073e-01, 1.28878057e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.04931021e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.94786954e-01, 6.15833402e-01, ...,\n",
       "          2.00244635e-01, 1.10513580e+00, 5.58649361e-01],\n",
       "         [1.03040911e-01, 1.11017883e+00, 1.30273789e-01, ...,\n",
       "          0.00000000e+00, 1.09344733e+00, 5.84765911e-01],\n",
       "         [1.42691910e-01, 1.03211796e+00, 2.64871195e-02, ...,\n",
       "          0.00000000e+00, 3.89539629e-01, 4.24094677e-01],\n",
       "         [2.33292338e-02, 9.52406645e-01, 4.16681141e-01, ...,\n",
       "          0.00000000e+00, 5.58226347e-01, 8.26527923e-02]],\n",
       "\n",
       "        [[9.22215819e-01, 4.14413184e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.82159829e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.50354218e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.28124762e-01, 0.00000000e+00, ...,\n",
       "          1.10234261e+00, 1.60742247e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.12121868e+00, 7.57788479e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.03214610e-01, 1.14583671e+00, 0.00000000e+00],\n",
       "         [6.59933865e-01, 1.97398141e-01, 0.00000000e+00, ...,\n",
       "          8.70444536e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.05376267e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.39320302e+00, 1.40793100e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.36519694e-01, ...,\n",
       "          1.47311008e+00, 5.35422921e-01, 0.00000000e+00],\n",
       "         [4.51415032e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.23708463e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.65599966e-01, 0.00000000e+00],\n",
       "         [3.99715692e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[5.43277085e-01, 5.69180727e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.39797926e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.28812009e-01, 0.00000000e+00, 2.07650233e-02],\n",
       "         [0.00000000e+00, 2.22789854e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.73306441e-01, 0.00000000e+00, ...,\n",
       "          5.03833853e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.39736611e-01, ...,\n",
       "          3.98845226e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[2.76941031e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.58346689e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.25047827e-01, ...,\n",
       "          0.00000000e+00, 4.95000660e-01, 2.49710783e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.41210335e-02, 0.00000000e+00, ...,\n",
       "          2.22059980e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.73117429e-01, 0.00000000e+00, ...,\n",
       "          1.69370547e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.40151966e-01, 1.69803277e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[3.01103026e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.59076020e-01, 0.00000000e+00, 7.77833819e-01],\n",
       "         [2.64523566e-01, 0.00000000e+00, 7.33150840e-01, ...,\n",
       "          9.28520977e-01, 0.00000000e+00, 1.98531970e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.54606104e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.46149707e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.36316240e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.97520751e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.34823036e-01, 0.00000000e+00, 2.77273625e-01]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[5.54868579e-01, 0.00000000e+00, 2.09653452e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.95802283e-01, 2.33481854e-01, 4.39013660e-01, ...,\n",
       "          0.00000000e+00, 6.85738504e-01, 0.00000000e+00],\n",
       "         [6.18452132e-01, 2.78394729e-01, 8.34464669e-01, ...,\n",
       "          5.90230152e-02, 9.04665351e-01, 0.00000000e+00],\n",
       "         [8.51163507e-01, 8.32234383e-01, 8.65169168e-01, ...,\n",
       "          2.30508029e-01, 4.21075702e-01, 1.07643473e+00],\n",
       "         [3.37417990e-01, 8.76152217e-01, 8.20224956e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.51392376e+00],\n",
       "         [0.00000000e+00, 1.17680086e-02, 5.58582425e-01, ...,\n",
       "          5.43553233e-01, 2.61656735e-02, 1.06153272e-01]],\n",
       "\n",
       "        [[7.40259111e-01, 6.23618126e-01, 1.59319758e-01, ...,\n",
       "          0.00000000e+00, 8.03648084e-02, 0.00000000e+00],\n",
       "         [1.08002603e+00, 1.34148788e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [7.14338124e-01, 6.62054271e-02, 0.00000000e+00, ...,\n",
       "          6.33005321e-01, 1.70548058e+00, 1.08340038e-02],\n",
       "         [3.38811427e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.49380326e-01, 1.82285869e+00, 8.91632855e-01],\n",
       "         [5.66983461e-01, 2.70252258e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 9.21631515e-01, 5.82605481e-01],\n",
       "         [0.00000000e+00, 1.27941728e-01, 1.28289675e-02, ...,\n",
       "          6.45930767e-01, 5.37137985e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.65202153e+00, 1.92711979e-01, 3.46427023e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [6.58399940e-01, 0.00000000e+00, 3.79514545e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.82154924e-01, 4.51045722e-01, 0.00000000e+00, ...,\n",
       "          8.88791382e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.85798681e+00, 1.71447486e-01, 1.48875400e-01],\n",
       "         [0.00000000e+00, 2.08903059e-01, 0.00000000e+00, ...,\n",
       "          1.14160225e-01, 4.17020977e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.79270977e-01, ...,\n",
       "          7.10267484e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.40898919e+00, 6.93294346e-01, 3.30813453e-02, ...,\n",
       "          0.00000000e+00, 4.08204645e-02, 0.00000000e+00],\n",
       "         [3.68216962e-01, 1.01068199e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.85913122e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.31343973e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.75643480e-01, 0.00000000e+00, ...,\n",
       "          5.39589226e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 6.87130272e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.52528536e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.01818192e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.86673868e-01]],\n",
       "\n",
       "        [[1.16354299e+00, 2.07711473e-01, 1.53946295e-01, ...,\n",
       "          0.00000000e+00, 5.13336420e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.01600027e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.42235357e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.52194881e-01, 0.00000000e+00, ...,\n",
       "          1.03011453e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.84673083e-01, 0.00000000e+00, ...,\n",
       "          1.25499861e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.49452367e-01, 0.00000000e+00, ...,\n",
       "          5.65113485e-01, 0.00000000e+00, 2.97164977e-01],\n",
       "         [0.00000000e+00, 4.77514923e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.52172071e-01]],\n",
       "\n",
       "        [[7.69353747e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.34844124e-01, 0.00000000e+00, 1.95097715e-01],\n",
       "         [1.21529236e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          4.65871066e-01, 1.59877092e-01, 5.56281447e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.98413515e-01, 1.84804350e-01, 6.31211221e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.20745170e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.88785389e-01, ...,\n",
       "          7.97446847e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.52627841e-01, 4.34158117e-01, 4.62248385e-01, ...,\n",
       "          7.30552912e-01, 0.00000000e+00, 2.51083910e-01]]],\n",
       "\n",
       "\n",
       "       [[[6.53113246e-01, 4.54290479e-01, 3.25090051e-01, ...,\n",
       "          0.00000000e+00, 2.46574238e-01, 0.00000000e+00],\n",
       "         [7.92538345e-01, 0.00000000e+00, 6.71231508e-01, ...,\n",
       "          6.18359685e-01, 3.42639357e-01, 0.00000000e+00],\n",
       "         [3.01716439e-02, 1.43768096e+00, 3.01402528e-02, ...,\n",
       "          1.29568911e+00, 7.55373776e-01, 7.48455942e-01],\n",
       "         [7.97515333e-01, 9.62288976e-01, 7.14009881e-01, ...,\n",
       "          8.15240979e-01, 1.16498959e+00, 1.00717831e+00],\n",
       "         [5.90333879e-01, 6.40912652e-01, 4.67910796e-01, ...,\n",
       "          5.10940254e-01, 4.57203656e-01, 7.22755194e-01],\n",
       "         [1.75583541e-01, 1.72066256e-01, 1.05659497e+00, ...,\n",
       "          2.87493795e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[8.43252718e-01, 0.00000000e+00, 4.57172245e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.48493516e-01],\n",
       "         [6.10471547e-01, 1.45302888e-03, 0.00000000e+00, ...,\n",
       "          1.18889856e+00, 2.53336817e-01, 1.25075087e-01],\n",
       "         [2.51874954e-01, 6.40163124e-01, 0.00000000e+00, ...,\n",
       "          2.05259895e+00, 1.80451882e+00, 7.60612369e-01],\n",
       "         [9.21549618e-01, 7.70189703e-01, 9.86776352e-02, ...,\n",
       "          1.42471516e+00, 1.01065588e+00, 1.63200998e+00],\n",
       "         [6.41722500e-01, 7.38803446e-01, 0.00000000e+00, ...,\n",
       "          6.47588670e-01, 9.90402699e-01, 1.14861214e+00],\n",
       "         [7.94853568e-02, 4.89017427e-01, 0.00000000e+00, ...,\n",
       "          9.27468598e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.07835996e+00, 0.00000000e+00, 4.65320289e-01, ...,\n",
       "          0.00000000e+00, 9.68485832e-01, 0.00000000e+00],\n",
       "         [1.16809785e+00, 0.00000000e+00, 4.48173463e-01, ...,\n",
       "          5.73757648e-01, 1.28421974e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 9.54543471e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.18168509e-02, 3.44119132e-01],\n",
       "         [0.00000000e+00, 9.16096866e-01, 3.64798844e-01, ...,\n",
       "          1.20460756e-01, 2.30051920e-01, 1.27440298e+00],\n",
       "         [0.00000000e+00, 1.08253360e+00, 4.85471904e-01, ...,\n",
       "          4.86900285e-02, 5.25438488e-01, 2.10460052e-01],\n",
       "         [0.00000000e+00, 1.08314276e+00, 0.00000000e+00, ...,\n",
       "          6.67749107e-01, 0.00000000e+00, 5.29617257e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 5.30756533e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.34827936e+00, 0.00000000e+00],\n",
       "         [5.59777737e-01, 8.74446690e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.42847204e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.23623180e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.22674847e+00, 9.22094941e-01],\n",
       "         [7.68942475e-01, 1.47062910e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.03019905e+00, 1.85458049e-01],\n",
       "         [6.60330653e-01, 8.58195662e-01, 0.00000000e+00, ...,\n",
       "          5.26714146e-01, 9.46454048e-01, 0.00000000e+00],\n",
       "         [1.78587094e-01, 8.49398971e-01, 6.91891834e-02, ...,\n",
       "          8.68261158e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.42874813e+00, 0.00000000e+00, 5.66674769e-01, ...,\n",
       "          3.36644113e-01, 2.25867510e+00, 0.00000000e+00],\n",
       "         [5.28068662e-01, 2.41930306e-01, 0.00000000e+00, ...,\n",
       "          7.88549066e-01, 3.45656347e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.11576211e+00, 0.00000000e+00, ...,\n",
       "          1.08674037e+00, 2.33060884e+00, 7.20527470e-01],\n",
       "         [0.00000000e+00, 8.46525192e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.38700271e-01, 8.37134182e-01],\n",
       "         [0.00000000e+00, 6.48640394e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 9.23870444e-01, 4.07819837e-01, ...,\n",
       "          1.36592615e+00, 0.00000000e+00, 5.43898284e-01]],\n",
       "\n",
       "        [[1.12075758e+00, 0.00000000e+00, 2.57105172e-01, ...,\n",
       "          9.42003310e-01, 9.91547167e-01, 1.26096472e-01],\n",
       "         [6.32403135e-01, 0.00000000e+00, 3.94560039e-01, ...,\n",
       "          1.62719321e+00, 1.51517367e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.91845524e+00, 9.20094311e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.76704347e-01, 3.09583932e-01, 0.00000000e+00],\n",
       "         [3.68879378e-01, 0.00000000e+00, 1.88309938e-01, ...,\n",
       "          1.85832703e+00, 2.28459612e-01, 0.00000000e+00],\n",
       "         [4.04950887e-01, 3.59160870e-01, 9.94559675e-02, ...,\n",
       "          1.02736771e+00, 0.00000000e+00, 2.99938768e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.57726073e-01, 4.78269279e-01, 2.89182156e-01, ...,\n",
       "          0.00000000e+00, 5.77444971e-01, 0.00000000e+00],\n",
       "         [3.77552390e-01, 8.46817791e-01, 2.21524775e-01, ...,\n",
       "          4.97461766e-01, 5.34188867e-01, 8.56971443e-02],\n",
       "         [0.00000000e+00, 1.26131773e+00, 0.00000000e+00, ...,\n",
       "          2.83341169e-01, 4.16179597e-01, 1.06382358e+00],\n",
       "         [1.00784743e+00, 1.13370395e+00, 0.00000000e+00, ...,\n",
       "          2.17416748e-01, 1.47419524e+00, 0.00000000e+00],\n",
       "         [3.92637312e-01, 1.50990188e+00, 0.00000000e+00, ...,\n",
       "          3.70646417e-02, 8.23083282e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.04876149e+00, 5.16032338e-01, ...,\n",
       "          3.89874637e-01, 0.00000000e+00, 1.63580582e-01]],\n",
       "\n",
       "        [[1.35706222e+00, 2.50392646e-01, 1.28529206e-01, ...,\n",
       "          9.73118424e-01, 1.06202078e+00, 2.96067968e-02],\n",
       "         [1.07852590e+00, 8.77265871e-01, 6.59916818e-01, ...,\n",
       "          1.70621288e+00, 1.20290744e+00, 1.39084756e-01],\n",
       "         [5.90643585e-01, 9.34118390e-01, 0.00000000e+00, ...,\n",
       "          1.90188920e+00, 1.07160127e+00, 1.56916189e+00],\n",
       "         [4.97220159e-01, 1.17705953e+00, 0.00000000e+00, ...,\n",
       "          6.03450716e-01, 9.71510947e-01, 1.98160660e+00],\n",
       "         [2.33068734e-01, 1.40483224e+00, 0.00000000e+00, ...,\n",
       "          5.74225426e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.26884186e+00, 0.00000000e+00, ...,\n",
       "          7.76317716e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.14034641e+00, 1.46218777e-01, 5.61741710e-01, ...,\n",
       "          6.49898112e-01, 1.47306681e+00, 0.00000000e+00],\n",
       "         [9.33997154e-01, 1.09830832e+00, 1.10959172e+00, ...,\n",
       "          0.00000000e+00, 7.34269261e-01, 0.00000000e+00],\n",
       "         [1.25174806e-01, 9.12549317e-01, 0.00000000e+00, ...,\n",
       "          3.28876674e-02, 0.00000000e+00, 1.44126713e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.07391715e-01, 0.00000000e+00, 1.48584914e+00],\n",
       "         [0.00000000e+00, 6.99180126e-01, 0.00000000e+00, ...,\n",
       "          4.26554710e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.17238986e-01, 6.01000041e-02, ...,\n",
       "          4.56224084e-01, 0.00000000e+00, 2.51361698e-01]],\n",
       "\n",
       "        [[5.80825135e-02, 7.60677636e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.37212437e-01, 0.00000000e+00],\n",
       "         [6.84985280e-01, 8.07671130e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.14525783e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.33564508e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 7.64890969e-01, 6.04996324e-01],\n",
       "         [0.00000000e+00, 1.19725275e+00, 0.00000000e+00, ...,\n",
       "          2.99072742e-01, 2.19196707e-01, 4.63523775e-01],\n",
       "         [0.00000000e+00, 6.35608971e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.00149262e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.64133471e-01, 0.00000000e+00, ...,\n",
       "          7.66643405e-01, 0.00000000e+00, 7.93660730e-02]],\n",
       "\n",
       "        [[2.26246268e-01, 1.88237891e-01, 2.33566716e-01, ...,\n",
       "          0.00000000e+00, 1.25859392e+00, 0.00000000e+00],\n",
       "         [1.34010124e+00, 9.20340538e-01, 7.31295884e-01, ...,\n",
       "          1.96400952e+00, 1.70905030e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.25383019e+00, 0.00000000e+00, ...,\n",
       "          1.84583437e+00, 1.14905369e+00, 9.88898337e-01],\n",
       "         [0.00000000e+00, 1.61289775e+00, 0.00000000e+00, ...,\n",
       "          9.40056622e-01, 5.16195774e-01, 1.09151697e+00],\n",
       "         [0.00000000e+00, 2.25601435e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.70864153e+00],\n",
       "         [0.00000000e+00, 8.68908763e-01, 0.00000000e+00, ...,\n",
       "          8.78184676e-01, 0.00000000e+00, 6.23790801e-01]],\n",
       "\n",
       "        [[1.79624856e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.18204939e-01, 2.99267292e-01, 4.24002588e-01],\n",
       "         [1.10217623e-01, 0.00000000e+00, 7.92395353e-01, ...,\n",
       "          2.14755702e+00, 7.17249572e-01, 1.70226265e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.84304762e+00, 9.26787376e-01, 5.17188847e-01],\n",
       "         [0.00000000e+00, 3.53877187e-01, 0.00000000e+00, ...,\n",
       "          2.15315700e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.93930912e-01, 5.94902158e-01, ...,\n",
       "          1.32630420e+00, 5.10512948e-01, 0.00000000e+00],\n",
       "         [2.11916253e-01, 2.19456255e-01, 4.88787889e-01, ...,\n",
       "          1.36721027e+00, 0.00000000e+00, 0.00000000e+00]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning setup: classification with subsamples per object class (few shot learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning params\n",
    "# SAMPLES_PER_CLASS = [1, 5, 10, 20, 30, 40, 50] # NOTE: taking more samples per class since it is 88 for 50\n",
    "# SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 70, 90, 110, 130, 150, len(x_test)]\n",
    "SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 80, 110, 140, 170, 200]\n",
    "TRIALS = 10\n",
    "\n",
    "NUM_CLASSES_WATERTANK = 11\n",
    "NUM_CLASSES_TURNEDTABLE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten train & test data for SVM\n",
    "x_train_flatten = flatten(x_train_flatten.numpy())\n",
    "x_train_activation_93 = flatten(x_train_activation_93.numpy())\n",
    "x_train_activation_91 = flatten(x_train_activation_91.numpy())\n",
    "\n",
    "x_test_flatten = flatten(x_test_flatten.numpy())\n",
    "x_test_activation_93 = flatten(x_test_activation_93.numpy())\n",
    "x_test_activation_91 = flatten(x_test_activation_91.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505,)\n",
      "(645,)\n"
     ]
    }
   ],
   "source": [
    "# these two are not modified (only x_test, x_train)\n",
    "print(y_train.numpy().shape)\n",
    "print(y_test.numpy().shape)\n",
    "\n",
    "y_train = y_train.numpy() # convert from tf tensor --> numpy\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run svm tl evaluation with spc for each n-th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_with_spc(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Takes embeddings from pretrained model and evaluates transfer learning \n",
    "    with few samples per class.\n",
    "    \"\"\"\n",
    "    # NOTE: svm takes original labels (not one-hot encoding)\n",
    "    for spc in SAMPLES_PER_CLASS:\n",
    "        accuracies = []\n",
    "\n",
    "        for i in range(TRIALS):\n",
    "            x_sample, y_sample = classSampling(x_train, y_train, spc, NUM_CLASSES_TURNEDTABLE)\n",
    "\n",
    "            svm = SVC(C=1.0, decision_function_shape = 'ovo', kernel=\"linear\")\n",
    "            svm.fit(x_sample, y_sample)\n",
    "\n",
    "            train_acc = svm.score(x_sample, y_sample)\n",
    "            test_acc = svm.score(x_test, y_test)\n",
    "\n",
    "            print(\"SPC {} Train Accuracy: {:.3f}\".format(spc, train_acc))\n",
    "            print(\"SPC {} Test Accuracy: {:.3f}\".format(spc, test_acc))\n",
    "            print()\n",
    "\n",
    "            accuracies.append(test_acc)\n",
    "\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "\n",
    "        mean_acc = round(100 * mean_acc, 3)\n",
    "        std_acc = round(100 * std_acc, 3)\n",
    "\n",
    "        print(\"After {} trials - Test Accuracy is {} +- {}\".format(TRIALS, mean_acc, std_acc ))\n",
    "        print(\"------------------------------------------------------------------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.594\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.586\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.580\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.552\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.605\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.600\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.572\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.597\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.577\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.560\n",
      "\n",
      "After 10 trials - Test Accuracy is 58.217 +- 1.657\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.679\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.653\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.678\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.653\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.651\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.690\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.650\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.674\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.690\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.698\n",
      "\n",
      "After 10 trials - Test Accuracy is 67.147 +- 1.751\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.667\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.727\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.710\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.736\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.674\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.729\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.726\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "After 10 trials - Test Accuracy is 71.318 +- 2.233\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.736\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.749\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.726\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.749\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.761\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.730\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.757\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.757\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.752\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.750\n",
      "\n",
      "After 10 trials - Test Accuracy is 74.667 +- 1.131\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.752\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.743\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.752\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.791\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.798\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.757\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.772\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.774\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.778\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.803\n",
      "\n",
      "After 10 trials - Test Accuracy is 77.194 +- 1.991\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.819\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.814\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_flatten, y_train, x_test_flatten, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.620\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.681\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.713\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.691\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.688\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.690\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.662\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.699\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.712\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.729\n",
      "\n",
      "After 10 trials - Test Accuracy is 68.853 +- 2.884\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.812\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.805\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.775\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.778\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.775\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.977 +- 1.215\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.854\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.843\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.839\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.814\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.867\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.823\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.837\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.828\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.833\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.845\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.829 +- 1.446\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.874\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.848\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.865\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.870\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.881\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.876\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.850\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.879\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.881\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.867\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.899 +- 1.133\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.870\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.881\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.879\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.912\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.859\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.904\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.874\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.876\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.186 +- 1.464\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.907\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.926\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.904\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.916\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.909\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.891\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.893\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.913\n",
      "\n",
      "After 10 trials - Test Accuracy is 91.039 +- 1.133\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.932\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.921\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.909\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.919\n",
      "\n",
      "After 10 trials - Test Accuracy is 92.589 +- 0.73\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.946\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.941\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.950\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.930\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.944\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.926\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.935\n",
      "\n",
      "After 10 trials - Test Accuracy is 93.907 +- 0.704\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.938\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.955\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.944\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.941\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.949\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.938\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.952\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.961\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.791 +- 0.718\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.941\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.957\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.949\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.947\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.943\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.936\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.943\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.667 +- 0.56\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_activation_93, y_train, x_test_activation_93, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.648\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.684\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.628\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.670\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.647\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.625\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.662\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.679\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.640\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.569\n",
      "\n",
      "After 10 trials - Test Accuracy is 64.512 +- 3.174\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.722\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.738\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.744\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.707\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.718\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.741\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.729\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.732\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.724\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.712\n",
      "\n",
      "After 10 trials - Test Accuracy is 72.667 +- 1.179\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.811\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.780\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.766\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.795\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.769\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.794\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.771\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.784\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.780\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.778\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.279 +- 1.316\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.803\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.797\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.812\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.802\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.840\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.811\n",
      "\n",
      "After 10 trials - Test Accuracy is 80.961 +- 1.115\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.809\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.847\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.845\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.840\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.843\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.853\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.839\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.736 +- 1.132\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.871\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.865\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.881\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.842\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.864\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.864\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.854\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.854\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.859\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.878\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.31 +- 1.101\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.867\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.879\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.893\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.876\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.887\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.870\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.874\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.901\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.264 +- 1.052\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.876\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.884\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.890\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.891\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.898\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.890\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.898\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.868 +- 0.608\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.910\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.913\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.893\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.895\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.899\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.901\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.357 +- 0.619\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.899\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.893\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.905\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.918\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.895\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.902\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.904\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.905\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.901\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.895\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.171 +- 0.691\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_activation_91, y_train, x_test_activation_91, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rotnet] *",
   "language": "python",
   "name": "conda-env-rotnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
