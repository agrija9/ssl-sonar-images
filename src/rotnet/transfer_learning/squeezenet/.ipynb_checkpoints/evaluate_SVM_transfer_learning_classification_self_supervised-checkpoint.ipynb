{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate transfer learning on Turnedtable Watertank (Dataset 2)  using an SVM Classifier: Self-supervised approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Tensorflow for GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tensorflow Version: 2.2.0\n",
      "[INFO] Tensorflow built with CUDA\n",
      "[INFO] Number GPUs Available:  1\n",
      "[INFO] List of GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(\"[INFO] Tensorflow Version:\", tf.__version__)\n",
    "\n",
    "if tf.config.list_physical_devices(\"GPU\") and tf.test.is_built_with_cuda():\n",
    "    print(\"[INFO] Tensorflow built with CUDA\")\n",
    "    print(\"[INFO] Number GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    print(\"[INFO] List of GPU devices:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "    physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    # tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "else:\n",
    "    print(\"[ERROR] GPU not detected, make sure tensorflow-gpu is installed and that GPU is recognized\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "def flatten(x):\n",
    "    return x.reshape((x.shape[0], -1))\n",
    "\n",
    "def classSampling(X, y, samplesPerClass, numberOfClasses):\n",
    "    X_ret = np.zeros((samplesPerClass * numberOfClasses, X.shape[1]), dtype = np.float32)\n",
    "    y_ret = np.zeros((samplesPerClass * numberOfClasses), dtype = np.uint8)\n",
    "    count = 0\n",
    "\n",
    "    for classIdx in range(numberOfClasses):\n",
    "        indices = np.where(y == classIdx)[0]\n",
    "\n",
    "        #if len(indices) < samplesPerClass:\n",
    "        #    raise IndexError(\"Not enough samples for class {} to produce {} samples per class. Only {} class samples available\".format(classIdx, samplesPerClass, len(indices)))\n",
    "\n",
    "        doResample = len(indices) < samplesPerClass\n",
    "\n",
    "        chosenIndices = np.random.choice(indices, samplesPerClass, replace = doResample)\n",
    "\n",
    "        for ci in chosenIndices:\n",
    "            X_ret[count] = X[ci]\n",
    "            y_ret[count] = y[ci]\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    return X_ret, y_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarTurnedTableSupervised(object):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def _normalize_images(self, images):\n",
    "        \"\"\"\n",
    "        Normalize sonar images by 1/255.\n",
    "        \"\"\"\n",
    "        return [element/255.0 for element in images]\n",
    "\n",
    "    def get_sonar_data(self):\n",
    "        \"\"\"\n",
    "        Reads from HDF5 file containing sonar data (resized to fix dims).\n",
    "        Returns list of np arrays containing image data.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"[INFO] Retrieving Sonar Turned Table Supervised Data\")\n",
    "\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            # list all groups\n",
    "            print(\"hdf5 dataset keys: %s\" % f.keys())\n",
    "\n",
    "            # get images and labels\n",
    "            x_train = f[\"x_train\"][...].astype(np.float32)\n",
    "            y_train = f[\"y_train\"][...]\n",
    "\n",
    "            x_test = f[\"x_test\"][...].astype(np.float32)\n",
    "            y_test = f[\"y_test\"][...]\n",
    "\n",
    "            _, x_val, _, y_val = train_test_split(x_test, y_test, train_size=0.5)\n",
    "\n",
    "            print(\"[INFO] Data dimensions\")\n",
    "            print(\"Train\", len(x_train))\n",
    "            print(\"Val\", len(x_val))\n",
    "            print(\"Test\", len(x_test))\n",
    "\n",
    "            # matias normalization\n",
    "            # multiply by 255 because hdf5 file comes as 1/255\n",
    "            x_train *= 255.0\n",
    "            x_val *= 255.0\n",
    "            x_test *= 255.0\n",
    "\n",
    "            x_train -= 84.51\n",
    "            x_val -= 84.51\n",
    "            x_test  -= 84.51\n",
    "\n",
    "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "    \n",
    "def load_sonar_turnedtable_supervised(file_path):\n",
    "    \"\"\"\n",
    "    Loads test data from turnedtable dataset.\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print(\"[INFO] Loading Tenorflow dataset\")\n",
    "\n",
    "    dataset_object = SonarTurnedTableSupervised(file_path)\n",
    "\n",
    "    # Read data\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = dataset_object.get_sonar_data()\n",
    "\n",
    "    # Train data\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(len(x_train))\n",
    "    train_dataset = train_dataset.prefetch(25)\n",
    "\n",
    "    # Validation data\n",
    "    # val_dataset = tf.data.Dataset.from_tensor_slices((x_val, labels_val))\n",
    "    # val_dataset = val_dataset.shuffle(buffer_size=len(x_val)).batch(batch_size)\n",
    "    # val_dataset = val_dataset.prefetch(25)\n",
    "\n",
    "    # Test data\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = test_dataset.shuffle(buffer_size=len(x_test)).batch(len(x_test)) # feed full test set\n",
    "    test_dataset = test_dataset.prefetch(25)\n",
    "\n",
    "    print()\n",
    "    print(\"[INFO] Tensorflow data dimensions\")\n",
    "    # print(train_dataset)\n",
    "    # print(val_dataset)\n",
    "    print(test_dataset)\n",
    "\n",
    "    # return train_dataset, val_dataset, test_dataset\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 48, 48, 8)    400         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 48, 48, 8)    32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 24, 24, 8)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 24, 32)   288         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 24, 24, 64)   2112        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 24, 24, 64)   18496       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 24, 24, 128)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24, 24, 128)  512         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 24, 24, 32)   4128        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 24, 24, 64)   2112        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 24, 24, 64)   18496       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 24, 24, 128)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 24, 128)  512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 24, 24, 64)   8256        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 24, 24, 128)  8320        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 24, 24, 128)  73856       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 24, 256)  0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 24, 256)  1024        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 256)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 12, 12, 64)   16448       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 12, 12, 128)  8320        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 12, 12, 128)  73856       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 12, 12, 256)  0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 12, 256)  1024        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 12, 12, 96)   24672       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 12, 12, 192)  18624       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 12, 12, 192)  166080      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 12, 12, 384)  0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 12, 12, 384)  1536        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 12, 12, 96)   36960       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 12, 12, 192)  18624       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 12, 12, 192)  166080      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 12, 12, 384)  0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 12, 12, 384)  1536        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 12, 12, 128)  49280       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 12, 12, 256)  33024       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 12, 12, 256)  295168      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 12, 12, 512)  0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 12, 12, 512)  2048        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 6, 6, 128)    65664       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 6, 6, 256)    33024       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 6, 6, 256)    295168      conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 6, 6, 512)    0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 6, 512)    2048        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 6, 6, 4)      51204       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 6, 4)      16          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 4)            0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 4)            0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 1,498,948\n",
      "Trainable params: 1,493,804\n",
      "Non-trainable params: 5,144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from architectures.squeezenet import squeezenet\n",
    "\n",
    "PRETRAINED_NUM_CLASSES = 4 # 11 supervised, 4 self-supervised\n",
    "input_shape = [96, 96, 1]\n",
    "\n",
    "model_name = \"squeezenet\"\n",
    "pretraining_mode = \"self_supervised_learning\"\n",
    "# layers = [\"batch_norm_48\", \"batch_norm_49\", \"batch_norm_50\"] # TODO: check layer names\n",
    "layers = [\"batch_normalization_8\", \"batch_normalization_9\", \"global_average_pooling2d\"]\n",
    "model = squeezenet(input_shape, PRETRAINED_NUM_CLASSES)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-7.64901042e-02  1.90203041e-02 -3.74044776e-02  2.44408697e-02\n",
      "    -1.12369493e-01 -1.10302255e-01 -5.44078574e-02 -2.49821544e-02]]\n",
      "\n",
      "  [[-6.16396330e-02  2.23979354e-04  1.57767534e-03  6.03458434e-02\n",
      "     1.54968798e-02  9.31169391e-02 -6.05186820e-03 -5.54286689e-03]]\n",
      "\n",
      "  [[-7.02164248e-02 -2.67192721e-03 -1.04847327e-01  5.87085485e-02\n",
      "    -4.23309356e-02  3.54649425e-02 -7.82359987e-02  7.91964829e-02]]\n",
      "\n",
      "  [[-5.69837876e-02  9.04656202e-02  9.09406096e-02 -9.93871167e-02\n",
      "    -1.24929547e-02 -8.87132213e-02 -2.03947201e-02  7.67280906e-03]]\n",
      "\n",
      "  [[-2.93047875e-02  6.53758198e-02 -1.07388750e-01  8.72641951e-02\n",
      "     1.01561844e-02 -8.67780298e-02  5.42785376e-02  9.30715352e-02]]\n",
      "\n",
      "  [[-1.53890327e-02  4.75405008e-02 -3.63478437e-02 -1.36444196e-02\n",
      "     1.01812616e-01 -7.34028369e-02  1.69945061e-02 -2.73213163e-02]]\n",
      "\n",
      "  [[ 1.09131977e-01 -6.00091778e-02  5.22561371e-03 -3.41588557e-02\n",
      "     8.77260268e-02 -8.24422091e-02 -8.93129110e-02 -9.94019359e-02]]]\n",
      "\n",
      "\n",
      " [[[-8.48209709e-02 -2.85244435e-02 -9.71134752e-03 -9.38696414e-02\n",
      "     6.38484508e-02 -8.32192451e-02 -2.84204111e-02  3.12029868e-02]]\n",
      "\n",
      "  [[ 4.51275110e-02 -5.82937934e-02 -3.84557918e-02 -7.56656006e-02\n",
      "     7.06029832e-02  5.28084934e-02  6.02339059e-02 -7.56116211e-02]]\n",
      "\n",
      "  [[-4.49004397e-02 -6.69799745e-04  6.62650019e-02  1.43983066e-02\n",
      "     6.67075068e-02 -9.78808850e-02  2.73015350e-02 -8.12605247e-02]]\n",
      "\n",
      "  [[-6.92017376e-02 -7.13673308e-02 -1.03681430e-01 -4.86224070e-02\n",
      "    -2.04115734e-02 -3.59450802e-02 -1.06619388e-01 -3.98752093e-03]]\n",
      "\n",
      "  [[ 6.80787712e-02 -9.99170244e-02 -1.06798343e-01 -1.44770965e-02\n",
      "    -1.04099415e-01 -1.43236369e-02 -1.44179463e-02  2.82236040e-02]]\n",
      "\n",
      "  [[-4.01467085e-02  9.61453021e-02  1.39569640e-02 -1.10320359e-01\n",
      "    -2.01945230e-02  1.08347848e-01  5.01103401e-02 -6.26346618e-02]]\n",
      "\n",
      "  [[ 7.16589689e-02 -3.13471034e-02 -1.29532069e-03 -5.69629036e-02\n",
      "     1.02299675e-01 -7.52186477e-02  1.01780444e-02  1.01579860e-01]]]\n",
      "\n",
      "\n",
      " [[[ 1.98647231e-02  1.09114915e-01  5.97952604e-02 -9.87487733e-02\n",
      "    -6.78907335e-03  1.13220602e-01  8.54475796e-02  4.81995642e-02]]\n",
      "\n",
      "  [[ 9.70285237e-02  7.08000660e-02  2.16641873e-02 -4.36408818e-02\n",
      "     2.18268335e-02 -2.34433338e-02 -5.62391281e-02  1.07190073e-01]]\n",
      "\n",
      "  [[ 9.64190662e-02  5.70446402e-02 -9.95504111e-03  4.80166376e-02\n",
      "     2.40438879e-02  9.43330675e-02 -5.75128421e-02 -8.16055536e-02]]\n",
      "\n",
      "  [[ 7.03437924e-02  7.38556385e-02  9.10045207e-03  2.54922956e-02\n",
      "    -4.73447219e-02  4.67600673e-03  5.63276261e-02 -9.17644724e-02]]\n",
      "\n",
      "  [[-9.48120281e-02 -6.77463710e-02  6.41399175e-02 -1.02173090e-01\n",
      "     4.86662090e-02  1.12188175e-01  9.83775705e-02 -2.68360078e-02]]\n",
      "\n",
      "  [[-1.05882436e-02 -4.14611846e-02  8.19623917e-02 -1.14434138e-02\n",
      "    -2.59632543e-02  5.98524362e-02  7.70198554e-02  1.20929629e-02]]\n",
      "\n",
      "  [[-1.23586506e-03  6.03668392e-03 -1.15241125e-01 -3.44283879e-02\n",
      "     5.24058044e-02  8.49561840e-02  1.04859784e-01 -6.97364658e-03]]]\n",
      "\n",
      "\n",
      " [[[ 9.13110375e-02  1.13127947e-01  2.55418867e-02  9.61285383e-02\n",
      "     6.02995157e-02 -6.28543049e-02 -8.89976025e-02 -6.19875640e-03]]\n",
      "\n",
      "  [[-5.50539047e-02  6.20776713e-02  3.31847072e-02  9.17043537e-02\n",
      "    -4.87330407e-02 -9.08213332e-02 -1.54383928e-02  1.61956847e-02]]\n",
      "\n",
      "  [[ 6.33893162e-02 -1.01641178e-01  6.04561418e-02 -3.05754393e-02\n",
      "     4.22154218e-02  1.05673820e-02  1.59864724e-02  8.57242048e-02]]\n",
      "\n",
      "  [[-1.11022472e-01 -1.12985589e-01  7.69016147e-03  7.58687556e-02\n",
      "    -1.53830200e-02  6.89919889e-02 -1.02517977e-02  6.52329773e-02]]\n",
      "\n",
      "  [[-2.70629376e-02  8.88002664e-02 -5.04145771e-02 -2.81434506e-02\n",
      "     3.81212085e-02  7.58436620e-02 -3.05370316e-02  4.67056036e-03]]\n",
      "\n",
      "  [[-3.06782797e-02  4.20563668e-02  1.08454689e-01 -6.47891313e-03\n",
      "     3.60952169e-02  2.35648006e-02 -9.45838541e-03  8.86673331e-02]]\n",
      "\n",
      "  [[ 8.52119923e-03 -8.74923989e-02 -4.97270152e-02  1.05873868e-01\n",
      "     8.18005949e-03  4.43448275e-02 -1.41175836e-03 -7.19446316e-02]]]\n",
      "\n",
      "\n",
      " [[[-3.23837623e-02 -1.14889473e-01 -1.02197088e-01  5.30256033e-02\n",
      "     2.30784714e-03  3.88687849e-03  2.64058411e-02  7.39269704e-02]]\n",
      "\n",
      "  [[-9.28285569e-02 -1.05057485e-01 -5.44447340e-02  4.55340892e-02\n",
      "    -1.09572530e-01 -9.21234936e-02 -2.30704620e-02  1.06699809e-01]]\n",
      "\n",
      "  [[-4.00334969e-02  6.05333298e-02 -7.03476593e-02  9.52212960e-02\n",
      "    -5.75764142e-02 -9.38697159e-03  4.77428436e-02 -3.12146768e-02]]\n",
      "\n",
      "  [[ 7.02703446e-02  3.63692641e-02  3.26281637e-02 -8.07344913e-04\n",
      "     1.10806093e-01 -1.67805701e-02 -1.15601756e-01 -8.84860158e-02]]\n",
      "\n",
      "  [[ 3.14438790e-02 -2.95962393e-03 -5.18873557e-02 -3.14783305e-03\n",
      "    -2.80081555e-02  2.12548226e-02  4.17507440e-03 -8.09961632e-02]]\n",
      "\n",
      "  [[ 1.16142958e-01 -8.75927359e-02 -6.54418021e-03 -2.97067761e-02\n",
      "     6.96880072e-02  3.59226614e-02  5.30605316e-02  9.06287134e-03]]\n",
      "\n",
      "  [[-3.38953361e-02 -9.41132009e-02 -1.70043558e-02 -5.59418164e-02\n",
      "    -4.69286889e-02 -6.77359700e-02  1.08185127e-01 -4.16906774e-02]]]\n",
      "\n",
      "\n",
      " [[[ 4.63010818e-02 -7.63406232e-02  3.40831131e-02  5.90524375e-02\n",
      "     1.10388577e-01  7.40096420e-02 -1.70319155e-02  1.07896775e-01]]\n",
      "\n",
      "  [[-1.08535923e-01  1.16086155e-01  1.09231919e-01  3.54487598e-02\n",
      "    -3.26418951e-02  7.04728067e-04 -8.07471871e-02  1.07110128e-01]]\n",
      "\n",
      "  [[ 7.77952373e-04  6.73468560e-02  1.21365190e-02  7.46098906e-02\n",
      "     1.62040144e-02 -1.01360798e-01  8.54626596e-02  1.50446147e-02]]\n",
      "\n",
      "  [[-3.32119688e-02  1.33854747e-02  1.22139156e-02  4.43835109e-02\n",
      "     4.08614129e-02 -8.54553133e-02  8.25887471e-02  1.08466446e-02]]\n",
      "\n",
      "  [[-7.69107193e-02 -5.79121038e-02  4.05124575e-02 -5.27435839e-02\n",
      "    -2.89570838e-02 -3.18146646e-02  9.02104080e-02  2.41696984e-02]]\n",
      "\n",
      "  [[-2.44900584e-03 -1.36922523e-02  8.64641070e-02 -6.17100224e-02\n",
      "     5.23602515e-02  6.56191260e-02 -6.32665902e-02 -2.19501778e-02]]\n",
      "\n",
      "  [[ 3.62999290e-02 -2.55982801e-02 -9.20246094e-02  8.20141435e-02\n",
      "    -1.01919465e-01 -6.01524264e-02  1.13922104e-01  6.85214847e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.14432447e-01  4.09660935e-02 -5.15199006e-02  8.70295316e-02\n",
      "     6.62439167e-02  2.88839191e-02 -1.00780606e-01  3.79950404e-02]]\n",
      "\n",
      "  [[ 7.15078562e-02 -6.19482659e-02  1.73936337e-02  1.09549701e-01\n",
      "     1.03469878e-01 -3.83278430e-02 -1.85377300e-02 -8.75249356e-02]]\n",
      "\n",
      "  [[ 6.39293492e-02 -8.07723254e-02  9.33835506e-02 -8.98918509e-02\n",
      "     1.37823820e-02 -2.38976628e-02 -9.61024240e-02  9.59864855e-02]]\n",
      "\n",
      "  [[-1.03978664e-01 -9.40359384e-02  2.28007585e-02  8.63362998e-02\n",
      "     3.03545147e-02 -2.48545110e-02  5.82844466e-02  8.25633854e-03]]\n",
      "\n",
      "  [[ 7.76911229e-02 -6.07481375e-02  1.18982792e-02  4.55252677e-02\n",
      "    -6.45443797e-05  2.56284475e-02  9.42767709e-02  7.47047812e-02]]\n",
      "\n",
      "  [[-1.04039453e-01 -9.02007595e-02  1.83905661e-03  3.25494260e-02\n",
      "    -9.83690470e-03  1.07250586e-01 -7.33911544e-02  9.48794037e-02]]\n",
      "\n",
      "  [[-2.00410113e-02 -8.14218521e-02 -1.12750292e-01  4.59596068e-02\n",
      "    -5.71463630e-02 -7.99386948e-03  4.21599597e-02 -8.17166567e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights BEFORE loading pretrained model (second conv layer)\n",
    "print(model.layers[1].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pretrained checkpoint restored correctly: ../../../pretraining/results/self_supervised_learning/checkpoints/sonar1/squeezenet/batch_size_128/96x96_substract_mean_online_aug_width_32/ckpt-21\n"
     ]
    }
   ],
   "source": [
    "# path to pretrained model checkpoint\n",
    "pretrained_checkpoint_prefix = os.path.join(\"../../../pretraining/results/\" + pretraining_mode + \"/checkpoints/sonar1/\" + model_name + \"/batch_size_128/96x96_substract_mean_online_aug_width_32\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.5, epsilon=1)\n",
    "\n",
    "# define pretrained checkpoint model\n",
    "checkpoint_pretrained = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=model) # 4 ssl, 11 sl\n",
    "manager_pretrained = tf.train.CheckpointManager(checkpoint_pretrained, pretrained_checkpoint_prefix, max_to_keep=3)\n",
    "\n",
    "# restore model weights\n",
    "checkpoint_pretrained.restore(manager_pretrained.latest_checkpoint)\n",
    "\n",
    "if manager_pretrained.latest_checkpoint:\n",
    "    print(\"[INFO] Pretrained checkpoint restored correctly: {}\".format(manager_pretrained.latest_checkpoint))\n",
    "else:\n",
    "    print(\"[INFO] Could not restore pretrained checkpoint correctly, make sure path to pre-trained folder is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.06216595 -0.03900114 -0.02578199 -0.02512501 -0.00926176\n",
      "    -0.0772492   0.08437654  0.09840393]]\n",
      "\n",
      "  [[ 0.08783991 -0.10164145 -0.02722576 -0.08092385 -0.0152075\n",
      "    -0.09763503  0.01076004  0.02054841]]\n",
      "\n",
      "  [[-0.03476039 -0.01866436 -0.11986611  0.05831946 -0.11343325\n",
      "    -0.02424521 -0.06752407  0.00966931]]\n",
      "\n",
      "  [[-0.09956822 -0.04149697 -0.0852205   0.10161399 -0.02028412\n",
      "    -0.09849622 -0.01819678 -0.09657682]]\n",
      "\n",
      "  [[ 0.05221378  0.01381214  0.00276488  0.03069827  0.05144576\n",
      "    -0.00697406  0.05501994 -0.01501517]]\n",
      "\n",
      "  [[ 0.04223234  0.10458919 -0.04650391  0.00161301  0.02099225\n",
      "     0.10271543  0.11928242 -0.08690233]]\n",
      "\n",
      "  [[ 0.08221544 -0.0049354  -0.05628303  0.06656159  0.09399419\n",
      "     0.07261222 -0.02798264 -0.08347652]]]\n",
      "\n",
      "\n",
      " [[[ 0.00047691  0.07692079  0.01617629  0.07047198  0.08686607\n",
      "    -0.0433566   0.00916725  0.04945499]]\n",
      "\n",
      "  [[-0.02974954  0.01272425  0.0555886   0.09433492 -0.01387227\n",
      "     0.04432397  0.13563244  0.00651278]]\n",
      "\n",
      "  [[-0.09382562  0.05086119  0.03260311 -0.06769482 -0.09122989\n",
      "    -0.00130989  0.03932575 -0.01622847]]\n",
      "\n",
      "  [[ 0.07789835 -0.09162525  0.09772023  0.05353693 -0.0166718\n",
      "     0.0170392  -0.15307812 -0.02999679]]\n",
      "\n",
      "  [[ 0.08987559 -0.08390643  0.0488353   0.14044255  0.09991998\n",
      "    -0.01662789  0.06937123 -0.02093223]]\n",
      "\n",
      "  [[-0.0005806   0.03744551 -0.01508343  0.08454919  0.05786892\n",
      "    -0.10487786 -0.01957865  0.01616156]]\n",
      "\n",
      "  [[ 0.08663671 -0.02764871 -0.02431356  0.03264019  0.00920067\n",
      "     0.06694484  0.07593752 -0.02590648]]]\n",
      "\n",
      "\n",
      " [[[-0.00336525 -0.08971535 -0.10556893 -0.06839999  0.0140167\n",
      "     0.10113636 -0.00219026  0.1164541 ]]\n",
      "\n",
      "  [[-0.01466064  0.0647555  -0.07935384  0.0654368   0.01604722\n",
      "     0.05485763  0.11000086  0.11848119]]\n",
      "\n",
      "  [[-0.05346181  0.00886537 -0.02811771  0.02792971  0.08023463\n",
      "    -0.01804017 -0.01251898 -0.12987669]]\n",
      "\n",
      "  [[ 0.00918676  0.08656278 -0.1182083   0.05295856 -0.00965512\n",
      "     0.0240304  -0.13954116 -0.09486616]]\n",
      "\n",
      "  [[-0.01377564  0.03808655  0.0763118  -0.07706346 -0.05352079\n",
      "    -0.005884    0.06034947  0.02062404]]\n",
      "\n",
      "  [[ 0.01307618 -0.12962614  0.04754759  0.08086514 -0.05897726\n",
      "    -0.08971314  0.05431144 -0.06359162]]\n",
      "\n",
      "  [[-0.04123626 -0.08088776  0.05449654  0.11571553 -0.03982627\n",
      "     0.02824811 -0.03310224 -0.11374069]]]\n",
      "\n",
      "\n",
      " [[[-0.08862807 -0.0813889  -0.0853465   0.00373474 -0.08279965\n",
      "     0.1056815  -0.0318942   0.07721613]]\n",
      "\n",
      "  [[-0.08801147 -0.10723839 -0.12054691 -0.02722923 -0.09284468\n",
      "    -0.09159534  0.18115692 -0.0555298 ]]\n",
      "\n",
      "  [[-0.07685504  0.03694799 -0.10908262 -0.05746757  0.04206384\n",
      "    -0.07382233 -0.0724059  -0.07061235]]\n",
      "\n",
      "  [[ 0.07600513  0.00217225 -0.0749086  -0.07775234 -0.0281934\n",
      "     0.07098035 -0.11148663 -0.02164344]]\n",
      "\n",
      "  [[-0.05756436  0.08229234  0.0228521  -0.03734843 -0.08112086\n",
      "     0.0964132  -0.01314992 -0.06044219]]\n",
      "\n",
      "  [[ 0.01670164 -0.00191012 -0.10740699 -0.07857814  0.02310259\n",
      "     0.08709194  0.02608144 -0.07831217]]\n",
      "\n",
      "  [[ 0.16404758  0.1112401  -0.02839459 -0.0756636   0.00616734\n",
      "     0.00107148 -0.02774877  0.07036071]]]\n",
      "\n",
      "\n",
      " [[[ 0.07144514 -0.08117114 -0.07637449 -0.05001972  0.0954613\n",
      "     0.12362161  0.09254483  0.04905485]]\n",
      "\n",
      "  [[-0.11578733 -0.04948206  0.11225109 -0.00058107 -0.01294626\n",
      "     0.0440176   0.04005275 -0.06385448]]\n",
      "\n",
      "  [[-0.07193763 -0.03941956  0.08577305 -0.02636348 -0.07950499\n",
      "     0.08762645 -0.10394501 -0.06988747]]\n",
      "\n",
      "  [[ 0.06891607 -0.09341794  0.1322555  -0.0706004   0.02633542\n",
      "     0.03649662 -0.04073945 -0.0718092 ]]\n",
      "\n",
      "  [[-0.07357071  0.00975771  0.06811254 -0.06113302  0.10725952\n",
      "    -0.00797262 -0.09944481 -0.1178754 ]]\n",
      "\n",
      "  [[-0.05476837 -0.04261877  0.10902675 -0.09325965  0.09603374\n",
      "     0.08867337  0.02008155 -0.00998765]]\n",
      "\n",
      "  [[ 0.14943181 -0.08793277 -0.07577278 -0.08915956  0.11990649\n",
      "     0.06402555  0.06693425  0.07189989]]]\n",
      "\n",
      "\n",
      " [[[-0.11962008  0.11493124 -0.07038314 -0.04220145  0.09965012\n",
      "     0.13942829  0.04978712 -0.07884744]]\n",
      "\n",
      "  [[ 0.02368857  0.04521363 -0.01461681 -0.02206239  0.11576346\n",
      "    -0.07493913  0.00664408  0.01105502]]\n",
      "\n",
      "  [[ 0.09046371  0.03049804  0.11417156  0.02470006  0.0928742\n",
      "     0.07449861  0.012953   -0.01136455]]\n",
      "\n",
      "  [[-0.04092547 -0.03107867  0.13740948 -0.03996482  0.1029862\n",
      "     0.07174299 -0.04961502  0.03130847]]\n",
      "\n",
      "  [[-0.10717218 -0.06281631  0.10546879  0.05829464 -0.08847052\n",
      "     0.08099836  0.05058083 -0.0546883 ]]\n",
      "\n",
      "  [[ 0.00762324 -0.02629613  0.0723132   0.02778878  0.04680789\n",
      "     0.04900672 -0.02911246  0.07900856]]\n",
      "\n",
      "  [[ 0.10065763 -0.06226122 -0.02330411  0.13557148  0.07101759\n",
      "    -0.09515402 -0.09738076  0.07174305]]]\n",
      "\n",
      "\n",
      " [[[-0.01969322  0.15528162  0.05891782  0.03701206 -0.04085656\n",
      "     0.03012499  0.05514098 -0.07091851]]\n",
      "\n",
      "  [[ 0.05022334  0.14437577  0.10704787 -0.10088713 -0.01948345\n",
      "     0.09284694 -0.02303923  0.10167807]]\n",
      "\n",
      "  [[ 0.04418651  0.17424922 -0.07800157 -0.00646284 -0.06335219\n",
      "     0.04584314 -0.07513222 -0.01943853]]\n",
      "\n",
      "  [[ 0.01343621 -0.03256495  0.10781389  0.01093308 -0.07847645\n",
      "    -0.01996314 -0.02016174  0.01191623]]\n",
      "\n",
      "  [[-0.07032696  0.02547353  0.09255808  0.02148153 -0.07345828\n",
      "    -0.0363452  -0.074207   -0.05668457]]\n",
      "\n",
      "  [[ 0.08266357  0.05332749  0.06735127 -0.06113046  0.02805828\n",
      "    -0.10892268 -0.0930634  -0.02951322]]\n",
      "\n",
      "  [[ 0.11284932 -0.0493842   0.0233286  -0.08522145  0.04532268\n",
      "     0.11418355  0.06239653  0.09182546]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights AFTER loading pretrained model (second conv layer)\n",
    "print(model.layers[1].get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models up to intermediate layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate layers from model: ['batch_norm_48', 'batch_norm_49', 'batch_norm_50']\n"
     ]
    }
   ],
   "source": [
    "print(\"Intermediate layers from model:\", layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: batch_norm_48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b530385eaf74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://stackoverflow.com/questions/63297838/how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model_batch_norm_48 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n\u001b[0;32m----> 3\u001b[0;31m                                      outputs=model.get_layer(layers[0]).output)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model_batch_norm_49 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
      "\u001b[0;32m~/anaconda3/envs/rotnet/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    561\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such layer: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: batch_norm_48"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/63297838/how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction\n",
    "model_batch_norm_48 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                     outputs=model.get_layer(layers[0]).output)\n",
    "\n",
    "model_batch_norm_49 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                     outputs=model.get_layer(layers[1]).output)\n",
    "\n",
    "model_batch_norm_50 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                     outputs=model.get_layer(layers[2]).output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate vector embeddings for train and test data (up to n-th layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Loading Tenorflow dataset\n",
      "[INFO] Retrieving Sonar Turned Table Supervised Data\n",
      "hdf5 dataset keys: <KeysViewHDF5 ['class_names', 'x_test', 'x_train', 'y_test', 'y_train']>\n",
      "[INFO] Data dimensions\n",
      "Train 1505\n",
      "Val 323\n",
      "Test 645\n",
      "\n",
      "[INFO] Tensorflow data dimensions\n",
      "<PrefetchDataset shapes: ((None, 96, 96, 1), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# define tensorflow dataset\n",
    "data_dir = \"../../../../../../datasets/sonar_turntable_dataset_2/marine-debris-turntable-classification-object_classes-platform-96x96.hdf5\"\n",
    "train_dataset, test_dataset = load_sonar_turnedtable_supervised(data_dir)\n",
    "\n",
    "# load tensorflow tensors individually\n",
    "x_train, y_train = next(iter(train_dataset))\n",
    "x_test, y_test = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a forward pass to generate embeddings (both train and test data) (for each n-th layer)\n",
    "\n",
    "# NOTE: when doing this all tensors are loaded into memory, this saturates NVIDIA memory (nvidia-smi)\n",
    "x_train_batch_norm_48 = model_batch_norm_48([x_train], training=False)\n",
    "x_train_batch_norm_49 = model_batch_norm_49([x_train], training=False)\n",
    "x_train_batch_norm_50 = model_batch_norm_50([x_train], training=False)\n",
    "\n",
    "x_test_batch_norm_48 = model_batch_norm_48([x_test], training=False)\n",
    "x_test_batch_norm_49 = model_batch_norm_49([x_test], training=False)\n",
    "x_test_batch_norm_50 = model_batch_norm_50([x_test], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1505, 6, 6, 512), dtype=float32, numpy=\n",
       "array([[[[1.21386254e+00, 4.89381775e-02, 8.45410645e-01, ...,\n",
       "          0.00000000e+00, 4.96995270e-01, 9.05933157e-02],\n",
       "         [1.40980411e+00, 1.15261090e+00, 8.35694194e-01, ...,\n",
       "          0.00000000e+00, 5.93474329e-01, 4.82767463e-01],\n",
       "         [1.82574883e-01, 6.56372130e-01, 5.60133994e-01, ...,\n",
       "          0.00000000e+00, 6.67990267e-01, 9.42384839e-01],\n",
       "         [1.29431516e-01, 1.25769377e+00, 2.52908558e-01, ...,\n",
       "          0.00000000e+00, 5.47911167e-01, 1.50075305e+00],\n",
       "         [0.00000000e+00, 7.05164850e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.08221430e-01, 7.03265250e-01],\n",
       "         [1.43316180e-01, 8.97599578e-01, 6.38682246e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.05568409e-01]],\n",
       "\n",
       "        [[1.58779538e+00, 2.70380199e-01, 6.62188411e-01, ...,\n",
       "          0.00000000e+00, 9.18517351e-01, 0.00000000e+00],\n",
       "         [1.36984611e+00, 1.52387643e+00, 6.65007174e-01, ...,\n",
       "          5.64474225e-01, 1.26944888e+00, 0.00000000e+00],\n",
       "         [1.15218312e-01, 1.10056651e+00, 0.00000000e+00, ...,\n",
       "          9.88080502e-01, 8.42722595e-01, 0.00000000e+00],\n",
       "         [2.41711080e-01, 6.82391763e-01, 1.18062049e-01, ...,\n",
       "          8.92391920e-01, 9.17503238e-01, 3.38331610e-01],\n",
       "         [8.01368356e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.33009458e+00, 6.31139040e-01, 9.87581849e-01],\n",
       "         [3.50163549e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.07743216e+00, 4.88872319e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.67930317e+00, 0.00000000e+00, 6.10883594e-01, ...,\n",
       "          0.00000000e+00, 6.40770674e-01, 0.00000000e+00],\n",
       "         [1.31692612e+00, 1.33257222e+00, 0.00000000e+00, ...,\n",
       "          2.02301934e-01, 7.47570693e-01, 0.00000000e+00],\n",
       "         [3.54028255e-01, 1.43480206e+00, 0.00000000e+00, ...,\n",
       "          1.42425289e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [4.69609290e-01, 7.73074746e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.37829918e-01, 0.00000000e+00],\n",
       "         [7.43504584e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.55491638e-01, 7.40871966e-01, 0.00000000e+00],\n",
       "         [4.51024294e-01, 0.00000000e+00, 5.22799492e-01, ...,\n",
       "          1.58414018e+00, 0.00000000e+00, 3.75580698e-01]],\n",
       "\n",
       "        [[7.55223513e-01, 2.43446156e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.44895494e+00, 0.00000000e+00],\n",
       "         [2.37992689e-01, 7.69590557e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 7.24948108e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 6.02175832e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.17057258e-01, 3.09611231e-01],\n",
       "         [2.29788959e-01, 5.17907739e-01, 0.00000000e+00, ...,\n",
       "          2.76066422e-01, 5.44403076e-01, 0.00000000e+00],\n",
       "         [3.90599757e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.11351252e-01, 3.87470573e-01, 0.00000000e+00],\n",
       "         [5.69515169e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.46275985e-01, 0.00000000e+00, 2.04475895e-01]],\n",
       "\n",
       "        [[6.03065133e-01, 1.81254387e-01, 1.62985653e-01, ...,\n",
       "          4.45793033e-01, 1.15529406e+00, 0.00000000e+00],\n",
       "         [7.56154954e-01, 3.09719771e-01, 0.00000000e+00, ...,\n",
       "          1.91156042e+00, 1.20842910e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.65345109e-01, 0.00000000e+00, ...,\n",
       "          1.81911242e+00, 0.00000000e+00, 3.70041668e-01],\n",
       "         [0.00000000e+00, 2.00629160e-01, 0.00000000e+00, ...,\n",
       "          1.40022433e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.48094797e-01, 0.00000000e+00, 3.92494977e-01],\n",
       "         [1.10064581e-01, 0.00000000e+00, 3.84586662e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 7.39752233e-01]],\n",
       "\n",
       "        [[8.80364239e-01, 1.38908774e-01, 9.69308019e-02, ...,\n",
       "          1.00734603e+00, 1.31476969e-01, 1.56573400e-01],\n",
       "         [6.56927526e-01, 0.00000000e+00, 5.46266437e-01, ...,\n",
       "          1.70416558e+00, 8.26609254e-01, 3.44359756e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.23115039e+00, 8.10497880e-01, 1.03638220e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.85691655e+00, 4.63376671e-01, 4.76679295e-01],\n",
       "         [3.30108911e-01, 0.00000000e+00, 3.68238956e-01, ...,\n",
       "          1.32343161e+00, 7.18894958e-01, 0.00000000e+00],\n",
       "         [4.51950848e-01, 0.00000000e+00, 1.56692922e-01, ...,\n",
       "          8.26672494e-01, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 1.52691096e-01, 5.29016376e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.43502966e-01, 4.82692480e-01, ...,\n",
       "          0.00000000e+00, 8.17698956e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.00359893e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.86733508e-01, 0.00000000e+00, ...,\n",
       "          1.28555104e-01, 2.33236456e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.96128833e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.41390359e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.07653040e-01, 3.29929680e-01, 1.17597485e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 1.70783386e-01, ...,\n",
       "          0.00000000e+00, 4.06205714e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.19671243e-01, 4.21145827e-01, ...,\n",
       "          0.00000000e+00, 1.83619052e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.11542404e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 6.32457376e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.08643031e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.02846766e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.94382715e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[2.85702109e-01, 0.00000000e+00, 1.24083459e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.92233336e-01, 9.89120781e-01, ...,\n",
       "          0.00000000e+00, 2.70563632e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 8.75124216e-01, ...,\n",
       "          1.38954234e+00, 1.76084387e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.49925661e-01, ...,\n",
       "          9.02132750e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.55398309e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.70396245e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[7.95933366e-01, 0.00000000e+00, 6.79903626e-01, ...,\n",
       "          0.00000000e+00, 1.64485350e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.54022312e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.83697939e+00, 4.69868422e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.08654076e-01, ...,\n",
       "          5.78733504e-01, 3.30802470e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.32641780e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.08220828e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.18128037e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.36451232e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.90511560e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.36809742e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.56128395e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.27201509e+00, 0.00000000e+00, 2.52235115e-01],\n",
       "         [0.00000000e+00, 1.98683381e-01, 0.00000000e+00, ...,\n",
       "          1.79942012e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.23751953e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [5.72776973e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.75177157e-01, 2.88074195e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.84128478e-01, ...,\n",
       "          1.88957775e+00, 0.00000000e+00, 3.07772666e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 9.18155491e-01, ...,\n",
       "          1.23943233e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.46942747e-01, 0.00000000e+00, 1.76285785e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.33068621e+00, 0.00000000e+00, 6.05253614e-02]]],\n",
       "\n",
       "\n",
       "       [[[4.97658908e-01, 2.26412073e-01, 1.28878057e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.04931021e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.94786954e-01, 6.15833402e-01, ...,\n",
       "          2.00244635e-01, 1.10513580e+00, 5.58649361e-01],\n",
       "         [1.03040911e-01, 1.11017883e+00, 1.30273789e-01, ...,\n",
       "          0.00000000e+00, 1.09344733e+00, 5.84765911e-01],\n",
       "         [1.42691910e-01, 1.03211796e+00, 2.64871195e-02, ...,\n",
       "          0.00000000e+00, 3.89539629e-01, 4.24094677e-01],\n",
       "         [2.33292338e-02, 9.52406645e-01, 4.16681141e-01, ...,\n",
       "          0.00000000e+00, 5.58226347e-01, 8.26527923e-02]],\n",
       "\n",
       "        [[9.22215819e-01, 4.14413184e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.82159829e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.50354218e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.28124762e-01, 0.00000000e+00, ...,\n",
       "          1.10234261e+00, 1.60742247e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.12121868e+00, 7.57788479e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          3.03214610e-01, 1.14583671e+00, 0.00000000e+00],\n",
       "         [6.59933865e-01, 1.97398141e-01, 0.00000000e+00, ...,\n",
       "          8.70444536e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.05376267e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.39320302e+00, 1.40793100e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.36519694e-01, ...,\n",
       "          1.47311008e+00, 5.35422921e-01, 0.00000000e+00],\n",
       "         [4.51415032e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.23708463e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.65599966e-01, 0.00000000e+00],\n",
       "         [3.99715692e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[5.43277085e-01, 5.69180727e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.39797926e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.28812009e-01, 0.00000000e+00, 2.07650233e-02],\n",
       "         [0.00000000e+00, 2.22789854e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.73306441e-01, 0.00000000e+00, ...,\n",
       "          5.03833853e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.39736611e-01, ...,\n",
       "          3.98845226e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[2.76941031e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.58346689e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.25047827e-01, ...,\n",
       "          0.00000000e+00, 4.95000660e-01, 2.49710783e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.41210335e-02, 0.00000000e+00, ...,\n",
       "          2.22059980e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.73117429e-01, 0.00000000e+00, ...,\n",
       "          1.69370547e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.40151966e-01, 1.69803277e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[3.01103026e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.59076020e-01, 0.00000000e+00, 7.77833819e-01],\n",
       "         [2.64523566e-01, 0.00000000e+00, 7.33150840e-01, ...,\n",
       "          9.28520977e-01, 0.00000000e+00, 1.98531970e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.54606104e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.46149707e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.36316240e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [3.97520751e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          9.34823036e-01, 0.00000000e+00, 2.77273625e-01]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[5.54868579e-01, 0.00000000e+00, 2.09653452e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.95802283e-01, 2.33481854e-01, 4.39013660e-01, ...,\n",
       "          0.00000000e+00, 6.85738504e-01, 0.00000000e+00],\n",
       "         [6.18452132e-01, 2.78394729e-01, 8.34464669e-01, ...,\n",
       "          5.90230152e-02, 9.04665351e-01, 0.00000000e+00],\n",
       "         [8.51163507e-01, 8.32234383e-01, 8.65169168e-01, ...,\n",
       "          2.30508029e-01, 4.21075702e-01, 1.07643473e+00],\n",
       "         [3.37417990e-01, 8.76152217e-01, 8.20224956e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.51392376e+00],\n",
       "         [0.00000000e+00, 1.17680086e-02, 5.58582425e-01, ...,\n",
       "          5.43553233e-01, 2.61656735e-02, 1.06153272e-01]],\n",
       "\n",
       "        [[7.40259111e-01, 6.23618126e-01, 1.59319758e-01, ...,\n",
       "          0.00000000e+00, 8.03648084e-02, 0.00000000e+00],\n",
       "         [1.08002603e+00, 1.34148788e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [7.14338124e-01, 6.62054271e-02, 0.00000000e+00, ...,\n",
       "          6.33005321e-01, 1.70548058e+00, 1.08340038e-02],\n",
       "         [3.38811427e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.49380326e-01, 1.82285869e+00, 8.91632855e-01],\n",
       "         [5.66983461e-01, 2.70252258e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 9.21631515e-01, 5.82605481e-01],\n",
       "         [0.00000000e+00, 1.27941728e-01, 1.28289675e-02, ...,\n",
       "          6.45930767e-01, 5.37137985e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.65202153e+00, 1.92711979e-01, 3.46427023e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [6.58399940e-01, 0.00000000e+00, 3.79514545e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.82154924e-01, 4.51045722e-01, 0.00000000e+00, ...,\n",
       "          8.88791382e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.85798681e+00, 1.71447486e-01, 1.48875400e-01],\n",
       "         [0.00000000e+00, 2.08903059e-01, 0.00000000e+00, ...,\n",
       "          1.14160225e-01, 4.17020977e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.79270977e-01, ...,\n",
       "          7.10267484e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.40898919e+00, 6.93294346e-01, 3.30813453e-02, ...,\n",
       "          0.00000000e+00, 4.08204645e-02, 0.00000000e+00],\n",
       "         [3.68216962e-01, 1.01068199e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.85913122e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.31343973e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.75643480e-01, 0.00000000e+00, ...,\n",
       "          5.39589226e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 6.87130272e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.52528536e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.01818192e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.86673868e-01]],\n",
       "\n",
       "        [[1.16354299e+00, 2.07711473e-01, 1.53946295e-01, ...,\n",
       "          0.00000000e+00, 5.13336420e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.01600027e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.42235357e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.52194881e-01, 0.00000000e+00, ...,\n",
       "          1.03011453e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.84673083e-01, 0.00000000e+00, ...,\n",
       "          1.25499861e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.49452367e-01, 0.00000000e+00, ...,\n",
       "          5.65113485e-01, 0.00000000e+00, 2.97164977e-01],\n",
       "         [0.00000000e+00, 4.77514923e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.52172071e-01]],\n",
       "\n",
       "        [[7.69353747e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.34844124e-01, 0.00000000e+00, 1.95097715e-01],\n",
       "         [1.21529236e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          4.65871066e-01, 1.59877092e-01, 5.56281447e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.98413515e-01, 1.84804350e-01, 6.31211221e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.20745170e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.88785389e-01, ...,\n",
       "          7.97446847e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.52627841e-01, 4.34158117e-01, 4.62248385e-01, ...,\n",
       "          7.30552912e-01, 0.00000000e+00, 2.51083910e-01]]],\n",
       "\n",
       "\n",
       "       [[[6.53113246e-01, 4.54290479e-01, 3.25090051e-01, ...,\n",
       "          0.00000000e+00, 2.46574238e-01, 0.00000000e+00],\n",
       "         [7.92538345e-01, 0.00000000e+00, 6.71231508e-01, ...,\n",
       "          6.18359685e-01, 3.42639357e-01, 0.00000000e+00],\n",
       "         [3.01716439e-02, 1.43768096e+00, 3.01402528e-02, ...,\n",
       "          1.29568911e+00, 7.55373776e-01, 7.48455942e-01],\n",
       "         [7.97515333e-01, 9.62288976e-01, 7.14009881e-01, ...,\n",
       "          8.15240979e-01, 1.16498959e+00, 1.00717831e+00],\n",
       "         [5.90333879e-01, 6.40912652e-01, 4.67910796e-01, ...,\n",
       "          5.10940254e-01, 4.57203656e-01, 7.22755194e-01],\n",
       "         [1.75583541e-01, 1.72066256e-01, 1.05659497e+00, ...,\n",
       "          2.87493795e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[8.43252718e-01, 0.00000000e+00, 4.57172245e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.48493516e-01],\n",
       "         [6.10471547e-01, 1.45302888e-03, 0.00000000e+00, ...,\n",
       "          1.18889856e+00, 2.53336817e-01, 1.25075087e-01],\n",
       "         [2.51874954e-01, 6.40163124e-01, 0.00000000e+00, ...,\n",
       "          2.05259895e+00, 1.80451882e+00, 7.60612369e-01],\n",
       "         [9.21549618e-01, 7.70189703e-01, 9.86776352e-02, ...,\n",
       "          1.42471516e+00, 1.01065588e+00, 1.63200998e+00],\n",
       "         [6.41722500e-01, 7.38803446e-01, 0.00000000e+00, ...,\n",
       "          6.47588670e-01, 9.90402699e-01, 1.14861214e+00],\n",
       "         [7.94853568e-02, 4.89017427e-01, 0.00000000e+00, ...,\n",
       "          9.27468598e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.07835996e+00, 0.00000000e+00, 4.65320289e-01, ...,\n",
       "          0.00000000e+00, 9.68485832e-01, 0.00000000e+00],\n",
       "         [1.16809785e+00, 0.00000000e+00, 4.48173463e-01, ...,\n",
       "          5.73757648e-01, 1.28421974e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 9.54543471e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.18168509e-02, 3.44119132e-01],\n",
       "         [0.00000000e+00, 9.16096866e-01, 3.64798844e-01, ...,\n",
       "          1.20460756e-01, 2.30051920e-01, 1.27440298e+00],\n",
       "         [0.00000000e+00, 1.08253360e+00, 4.85471904e-01, ...,\n",
       "          4.86900285e-02, 5.25438488e-01, 2.10460052e-01],\n",
       "         [0.00000000e+00, 1.08314276e+00, 0.00000000e+00, ...,\n",
       "          6.67749107e-01, 0.00000000e+00, 5.29617257e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 5.30756533e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.34827936e+00, 0.00000000e+00],\n",
       "         [5.59777737e-01, 8.74446690e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.42847204e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.23623180e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.22674847e+00, 9.22094941e-01],\n",
       "         [7.68942475e-01, 1.47062910e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.03019905e+00, 1.85458049e-01],\n",
       "         [6.60330653e-01, 8.58195662e-01, 0.00000000e+00, ...,\n",
       "          5.26714146e-01, 9.46454048e-01, 0.00000000e+00],\n",
       "         [1.78587094e-01, 8.49398971e-01, 6.91891834e-02, ...,\n",
       "          8.68261158e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.42874813e+00, 0.00000000e+00, 5.66674769e-01, ...,\n",
       "          3.36644113e-01, 2.25867510e+00, 0.00000000e+00],\n",
       "         [5.28068662e-01, 2.41930306e-01, 0.00000000e+00, ...,\n",
       "          7.88549066e-01, 3.45656347e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.11576211e+00, 0.00000000e+00, ...,\n",
       "          1.08674037e+00, 2.33060884e+00, 7.20527470e-01],\n",
       "         [0.00000000e+00, 8.46525192e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.38700271e-01, 8.37134182e-01],\n",
       "         [0.00000000e+00, 6.48640394e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 9.23870444e-01, 4.07819837e-01, ...,\n",
       "          1.36592615e+00, 0.00000000e+00, 5.43898284e-01]],\n",
       "\n",
       "        [[1.12075758e+00, 0.00000000e+00, 2.57105172e-01, ...,\n",
       "          9.42003310e-01, 9.91547167e-01, 1.26096472e-01],\n",
       "         [6.32403135e-01, 0.00000000e+00, 3.94560039e-01, ...,\n",
       "          1.62719321e+00, 1.51517367e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.91845524e+00, 9.20094311e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.76704347e-01, 3.09583932e-01, 0.00000000e+00],\n",
       "         [3.68879378e-01, 0.00000000e+00, 1.88309938e-01, ...,\n",
       "          1.85832703e+00, 2.28459612e-01, 0.00000000e+00],\n",
       "         [4.04950887e-01, 3.59160870e-01, 9.94559675e-02, ...,\n",
       "          1.02736771e+00, 0.00000000e+00, 2.99938768e-01]]],\n",
       "\n",
       "\n",
       "       [[[7.57726073e-01, 4.78269279e-01, 2.89182156e-01, ...,\n",
       "          0.00000000e+00, 5.77444971e-01, 0.00000000e+00],\n",
       "         [3.77552390e-01, 8.46817791e-01, 2.21524775e-01, ...,\n",
       "          4.97461766e-01, 5.34188867e-01, 8.56971443e-02],\n",
       "         [0.00000000e+00, 1.26131773e+00, 0.00000000e+00, ...,\n",
       "          2.83341169e-01, 4.16179597e-01, 1.06382358e+00],\n",
       "         [1.00784743e+00, 1.13370395e+00, 0.00000000e+00, ...,\n",
       "          2.17416748e-01, 1.47419524e+00, 0.00000000e+00],\n",
       "         [3.92637312e-01, 1.50990188e+00, 0.00000000e+00, ...,\n",
       "          3.70646417e-02, 8.23083282e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.04876149e+00, 5.16032338e-01, ...,\n",
       "          3.89874637e-01, 0.00000000e+00, 1.63580582e-01]],\n",
       "\n",
       "        [[1.35706222e+00, 2.50392646e-01, 1.28529206e-01, ...,\n",
       "          9.73118424e-01, 1.06202078e+00, 2.96067968e-02],\n",
       "         [1.07852590e+00, 8.77265871e-01, 6.59916818e-01, ...,\n",
       "          1.70621288e+00, 1.20290744e+00, 1.39084756e-01],\n",
       "         [5.90643585e-01, 9.34118390e-01, 0.00000000e+00, ...,\n",
       "          1.90188920e+00, 1.07160127e+00, 1.56916189e+00],\n",
       "         [4.97220159e-01, 1.17705953e+00, 0.00000000e+00, ...,\n",
       "          6.03450716e-01, 9.71510947e-01, 1.98160660e+00],\n",
       "         [2.33068734e-01, 1.40483224e+00, 0.00000000e+00, ...,\n",
       "          5.74225426e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.26884186e+00, 0.00000000e+00, ...,\n",
       "          7.76317716e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[1.14034641e+00, 1.46218777e-01, 5.61741710e-01, ...,\n",
       "          6.49898112e-01, 1.47306681e+00, 0.00000000e+00],\n",
       "         [9.33997154e-01, 1.09830832e+00, 1.10959172e+00, ...,\n",
       "          0.00000000e+00, 7.34269261e-01, 0.00000000e+00],\n",
       "         [1.25174806e-01, 9.12549317e-01, 0.00000000e+00, ...,\n",
       "          3.28876674e-02, 0.00000000e+00, 1.44126713e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.07391715e-01, 0.00000000e+00, 1.48584914e+00],\n",
       "         [0.00000000e+00, 6.99180126e-01, 0.00000000e+00, ...,\n",
       "          4.26554710e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.17238986e-01, 6.01000041e-02, ...,\n",
       "          4.56224084e-01, 0.00000000e+00, 2.51361698e-01]],\n",
       "\n",
       "        [[5.80825135e-02, 7.60677636e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.37212437e-01, 0.00000000e+00],\n",
       "         [6.84985280e-01, 8.07671130e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.14525783e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.33564508e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 7.64890969e-01, 6.04996324e-01],\n",
       "         [0.00000000e+00, 1.19725275e+00, 0.00000000e+00, ...,\n",
       "          2.99072742e-01, 2.19196707e-01, 4.63523775e-01],\n",
       "         [0.00000000e+00, 6.35608971e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.00149262e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.64133471e-01, 0.00000000e+00, ...,\n",
       "          7.66643405e-01, 0.00000000e+00, 7.93660730e-02]],\n",
       "\n",
       "        [[2.26246268e-01, 1.88237891e-01, 2.33566716e-01, ...,\n",
       "          0.00000000e+00, 1.25859392e+00, 0.00000000e+00],\n",
       "         [1.34010124e+00, 9.20340538e-01, 7.31295884e-01, ...,\n",
       "          1.96400952e+00, 1.70905030e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.25383019e+00, 0.00000000e+00, ...,\n",
       "          1.84583437e+00, 1.14905369e+00, 9.88898337e-01],\n",
       "         [0.00000000e+00, 1.61289775e+00, 0.00000000e+00, ...,\n",
       "          9.40056622e-01, 5.16195774e-01, 1.09151697e+00],\n",
       "         [0.00000000e+00, 2.25601435e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.70864153e+00],\n",
       "         [0.00000000e+00, 8.68908763e-01, 0.00000000e+00, ...,\n",
       "          8.78184676e-01, 0.00000000e+00, 6.23790801e-01]],\n",
       "\n",
       "        [[1.79624856e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.18204939e-01, 2.99267292e-01, 4.24002588e-01],\n",
       "         [1.10217623e-01, 0.00000000e+00, 7.92395353e-01, ...,\n",
       "          2.14755702e+00, 7.17249572e-01, 1.70226265e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          2.84304762e+00, 9.26787376e-01, 5.17188847e-01],\n",
       "         [0.00000000e+00, 3.53877187e-01, 0.00000000e+00, ...,\n",
       "          2.15315700e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.93930912e-01, 5.94902158e-01, ...,\n",
       "          1.32630420e+00, 5.10512948e-01, 0.00000000e+00],\n",
       "         [2.11916253e-01, 2.19456255e-01, 4.88787889e-01, ...,\n",
       "          1.36721027e+00, 0.00000000e+00, 0.00000000e+00]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_batch_norm_48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning setup: classification with subsamples per object class (few shot learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning params\n",
    "# SAMPLES_PER_CLASS = [1, 5, 10, 20, 30, 40, 50] # NOTE: taking more samples per class since it is 88 for 50\n",
    "# SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 70, 90, 110, 130, 150, len(x_test)]\n",
    "SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 80, 110, 140, 170, 200]\n",
    "TRIALS = 10\n",
    "\n",
    "NUM_CLASSES_WATERTANK = 11\n",
    "NUM_CLASSES_TURNEDTABLE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten train & test data for SVM\n",
    "x_train_batch_norm_48 = flatten(x_train_batch_norm_48.numpy())\n",
    "x_train_batch_norm_49 = flatten(x_train_batch_norm_49.numpy())\n",
    "x_train_batch_norm_50 = flatten(x_train_batch_norm_50.numpy())\n",
    "\n",
    "x_test_batch_norm_48 = flatten(x_test_batch_norm_48.numpy())\n",
    "x_test_batch_norm_49 = flatten(x_test_batch_norm_49.numpy())\n",
    "x_test_batch_norm_50 = flatten(x_test_batch_norm_50.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505,)\n",
      "(645,)\n"
     ]
    }
   ],
   "source": [
    "# these two are not modified (only x_test, x_train)\n",
    "print(y_train.numpy().shape)\n",
    "print(y_test.numpy().shape)\n",
    "\n",
    "y_train = y_train.numpy() # convert from tf tensor --> numpy\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run svm tl evaluation with spc for each n-th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_with_spc(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Takes embeddings from pretrained model and evaluates transfer learning \n",
    "    with few samples per class.\n",
    "    \"\"\"\n",
    "    # NOTE: svm takes original labels (not one-hot encoding)\n",
    "    for spc in SAMPLES_PER_CLASS:\n",
    "        accuracies = []\n",
    "\n",
    "        for i in range(TRIALS):\n",
    "            x_sample, y_sample = classSampling(x_train, y_train, spc, NUM_CLASSES_TURNEDTABLE)\n",
    "\n",
    "            svm = SVC(C=1.0, decision_function_shape = 'ovo', kernel=\"linear\")\n",
    "            svm.fit(x_sample, y_sample)\n",
    "\n",
    "            train_acc = svm.score(x_sample, y_sample)\n",
    "            test_acc = svm.score(x_test, y_test)\n",
    "\n",
    "            print(\"SPC {} Train Accuracy: {:.3f}\".format(spc, train_acc))\n",
    "            print(\"SPC {} Test Accuracy: {:.3f}\".format(spc, test_acc))\n",
    "            print()\n",
    "\n",
    "            accuracies.append(test_acc)\n",
    "\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "\n",
    "        mean_acc = round(100 * mean_acc, 3)\n",
    "        std_acc = round(100 * std_acc, 3)\n",
    "\n",
    "        print(\"After {} trials - Test Accuracy is {} +- {}\".format(TRIALS, mean_acc, std_acc ))\n",
    "        print(\"------------------------------------------------------------------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.594\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.586\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.580\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.552\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.605\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.600\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.572\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.597\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.577\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.560\n",
      "\n",
      "After 10 trials - Test Accuracy is 58.217 +- 1.657\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.679\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.653\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.678\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.653\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.651\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.690\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.650\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.674\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.690\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.698\n",
      "\n",
      "After 10 trials - Test Accuracy is 67.147 +- 1.751\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.667\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.727\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.710\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.736\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.674\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.729\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.726\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.721\n",
      "\n",
      "After 10 trials - Test Accuracy is 71.318 +- 2.233\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.736\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.749\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.726\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.749\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.761\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.730\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.757\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.757\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.752\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.750\n",
      "\n",
      "After 10 trials - Test Accuracy is 74.667 +- 1.131\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.752\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.743\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.752\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.791\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.798\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.757\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.772\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.774\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.778\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.803\n",
      "\n",
      "After 10 trials - Test Accuracy is 77.194 +- 1.991\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.819\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.814\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_batch_norm_48, y_train, x_test_batch_norm_48, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.620\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.681\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.713\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.691\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.688\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.690\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.662\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.699\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.712\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.729\n",
      "\n",
      "After 10 trials - Test Accuracy is 68.853 +- 2.884\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.812\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.805\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.775\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.778\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.775\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.977 +- 1.215\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.854\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.843\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.839\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.814\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.867\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.823\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.837\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.828\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.833\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.845\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.829 +- 1.446\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.874\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.848\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.865\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.870\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.881\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.876\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.850\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.879\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.881\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.867\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.899 +- 1.133\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.870\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.881\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.879\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.912\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.859\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.904\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.874\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.876\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.186 +- 1.464\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.907\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.926\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.904\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.916\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.909\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.891\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.893\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.913\n",
      "\n",
      "After 10 trials - Test Accuracy is 91.039 +- 1.133\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.932\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.921\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.909\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.919\n",
      "\n",
      "After 10 trials - Test Accuracy is 92.589 +- 0.73\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.946\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.941\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.950\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.930\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.944\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.926\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.935\n",
      "\n",
      "After 10 trials - Test Accuracy is 93.907 +- 0.704\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.938\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.955\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.944\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.941\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.949\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.938\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.952\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.961\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.791 +- 0.718\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.941\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.957\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.949\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.947\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.943\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.936\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.943\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.667 +- 0.56\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_batch_norm_49, y_train, x_test_batch_norm_49, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.648\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.684\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.628\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.670\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.647\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.625\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.662\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.679\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.640\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.569\n",
      "\n",
      "After 10 trials - Test Accuracy is 64.512 +- 3.174\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.722\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.738\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.744\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.707\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.718\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.741\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.729\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.732\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.724\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.712\n",
      "\n",
      "After 10 trials - Test Accuracy is 72.667 +- 1.179\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.811\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.780\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.766\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.795\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.769\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.794\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.771\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.784\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.780\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.778\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.279 +- 1.316\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.803\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.797\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.812\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.802\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.840\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.811\n",
      "\n",
      "After 10 trials - Test Accuracy is 80.961 +- 1.115\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.809\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.847\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.845\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.840\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.843\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.853\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.839\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.736 +- 1.132\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.871\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.865\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.881\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.842\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.864\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.864\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.854\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.854\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.859\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.878\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.31 +- 1.101\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.867\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.879\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.893\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.876\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.887\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.870\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.874\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.901\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.264 +- 1.052\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.876\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.884\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.890\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.891\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.898\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.890\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.898\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.868 +- 0.608\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.910\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.913\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.893\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.895\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.899\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.901\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.357 +- 0.619\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.899\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.893\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.905\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.918\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.895\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.902\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.904\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.905\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.901\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.895\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.171 +- 0.691\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_batch_norm_50, y_train, x_test_batch_norm_50, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rotnet] *",
   "language": "python",
   "name": "conda-env-rotnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
