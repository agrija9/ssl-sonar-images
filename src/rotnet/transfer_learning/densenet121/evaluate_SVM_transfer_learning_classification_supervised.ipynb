{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate transfer learning on Turnedtable Watertank (Dataset 2)  using an SVM Classifier: Supervised approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Tensorflow for GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tensorflow Version: 2.2.0\n",
      "[INFO] Tensorflow built with CUDA\n",
      "[INFO] Number GPUs Available:  1\n",
      "[INFO] List of GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(\"[INFO] Tensorflow Version:\", tf.__version__)\n",
    "\n",
    "if tf.config.list_physical_devices(\"GPU\") and tf.test.is_built_with_cuda():\n",
    "    print(\"[INFO] Tensorflow built with CUDA\")\n",
    "    print(\"[INFO] Number GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    print(\"[INFO] List of GPU devices:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "    physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    # tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "else:\n",
    "    print(\"[ERROR] GPU not detected, make sure tensorflow-gpu is installed and that GPU is recognized\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "def flatten(x):\n",
    "    return x.reshape((x.shape[0], -1))\n",
    "\n",
    "def classSampling(X, y, samplesPerClass, numberOfClasses):\n",
    "    X_ret = np.zeros((samplesPerClass * numberOfClasses, X.shape[1]), dtype = np.float32)\n",
    "    y_ret = np.zeros((samplesPerClass * numberOfClasses), dtype = np.uint8)\n",
    "    count = 0\n",
    "\n",
    "    for classIdx in range(numberOfClasses):\n",
    "        indices = np.where(y == classIdx)[0]\n",
    "\n",
    "        #if len(indices) < samplesPerClass:\n",
    "        #    raise IndexError(\"Not enough samples for class {} to produce {} samples per class. Only {} class samples available\".format(classIdx, samplesPerClass, len(indices)))\n",
    "\n",
    "        doResample = len(indices) < samplesPerClass\n",
    "\n",
    "        chosenIndices = np.random.choice(indices, samplesPerClass, replace = doResample)\n",
    "\n",
    "        for ci in chosenIndices:\n",
    "            X_ret[count] = X[ci]\n",
    "            y_ret[count] = y[ci]\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    return X_ret, y_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarTurnedTableSupervised(object):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def _normalize_images(self, images):\n",
    "        \"\"\"\n",
    "        Normalize sonar images by 1/255.\n",
    "        \"\"\"\n",
    "        return [element/255.0 for element in images]\n",
    "\n",
    "    def get_sonar_data(self):\n",
    "        \"\"\"\n",
    "        Reads from HDF5 file containing sonar data (resized to fix dims).\n",
    "        Returns list of np arrays containing image data.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"[INFO] Retrieving Sonar Turned Table Supervised Data\")\n",
    "\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            # list all groups\n",
    "            print(\"hdf5 dataset keys: %s\" % f.keys())\n",
    "\n",
    "            # get images and labels\n",
    "            x_train = f[\"x_train\"][...].astype(np.float32)\n",
    "            y_train = f[\"y_train\"][...]\n",
    "\n",
    "            x_test = f[\"x_test\"][...].astype(np.float32)\n",
    "            y_test = f[\"y_test\"][...]\n",
    "\n",
    "            _, x_val, _, y_val = train_test_split(x_test, y_test, train_size=0.5)\n",
    "\n",
    "            print(\"[INFO] Data dimensions\")\n",
    "            print(\"Train\", len(x_train))\n",
    "            print(\"Val\", len(x_val))\n",
    "            print(\"Test\", len(x_test))\n",
    "\n",
    "            # matias normalization\n",
    "            # multiply by 255 because hdf5 file comes as 1/255\n",
    "            x_train *= 255.0\n",
    "            x_val *= 255.0\n",
    "            x_test *= 255.0\n",
    "\n",
    "            x_train -= 84.51\n",
    "            x_val -= 84.51\n",
    "            x_test  -= 84.51\n",
    "\n",
    "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "    \n",
    "def load_sonar_turnedtable_supervised(file_path):\n",
    "    \"\"\"\n",
    "    Loads test data from turnedtable dataset.\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print(\"[INFO] Loading Tenorflow dataset\")\n",
    "\n",
    "    dataset_object = SonarTurnedTableSupervised(file_path)\n",
    "\n",
    "    # Read data\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = dataset_object.get_sonar_data()\n",
    "\n",
    "    # Train data\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(len(x_train))\n",
    "    train_dataset = train_dataset.prefetch(25)\n",
    "\n",
    "    # Validation data\n",
    "    # val_dataset = tf.data.Dataset.from_tensor_slices((x_val, labels_val))\n",
    "    # val_dataset = val_dataset.shuffle(buffer_size=len(x_val)).batch(batch_size)\n",
    "    # val_dataset = val_dataset.prefetch(25)\n",
    "\n",
    "    # Test data\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = test_dataset.shuffle(buffer_size=len(x_test)).batch(len(x_test)) # feed full test set\n",
    "    test_dataset = test_dataset.prefetch(25)\n",
    "\n",
    "    print()\n",
    "    print(\"[INFO] Tensorflow data dimensions\")\n",
    "    # print(train_dataset)\n",
    "    # print(val_dataset)\n",
    "    print(test_dataset)\n",
    "\n",
    "    # return train_dataset, val_dataset, test_dataset\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 102, 102, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 48, 48, 64)   3136        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 48, 48, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 48, 48, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 50, 50, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 24, 24, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 24, 24, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 24, 24, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 24, 24, 64)   4096        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 24, 24, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 24, 24, 80)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 24, 24, 80)   320         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 24, 24, 80)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 24, 24, 64)   5120        conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 24, 24, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 24, 24, 96)   0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 24, 24, 96)   384         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 24, 24, 96)   0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 24, 24, 64)   6144        conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 24, 24, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 24, 24, 112)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 24, 24, 112)  448         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 24, 24, 112)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 24, 24, 64)   7168        conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 24, 24, 64)   0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 24, 24, 128)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 24, 24, 128)  512         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 24, 24, 128)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 24, 24, 64)   8192        conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 24, 24, 64)   0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 24, 24, 144)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 24, 24, 144)  576         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 24, 24, 144)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 24, 24, 64)   9216        conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 24, 24, 64)   0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 24, 24, 160)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 24, 24, 160)  640         conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 24, 24, 160)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 24, 24, 80)   12800       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 12, 12, 80)   0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 12, 12, 80)   320         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 12, 12, 80)   0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 12, 12, 64)   5120        conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 12, 12, 64)   0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 12, 12, 96)   0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 12, 12, 96)   384         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 12, 12, 96)   0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 12, 12, 64)   6144        conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 12, 12, 64)   0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 12, 12, 112)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 12, 12, 112)  448         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 12, 12, 112)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 12, 12, 64)   7168        conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 12, 12, 64)   0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 12, 12, 128)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 12, 12, 128)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 12, 12, 64)   8192        conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 12, 12, 64)   0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 12, 12, 144)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 12, 12, 144)  576         conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 12, 12, 144)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 12, 12, 64)   9216        conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 12, 12, 64)   0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 12, 12, 160)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 12, 12, 160)  640         conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 12, 12, 160)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 12, 12, 64)   10240       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 12, 12, 64)   0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 12, 12, 176)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 12, 12, 176)  704         conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 12, 12, 176)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 12, 12, 64)   11264       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 12, 12, 64)   0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 12, 12, 192)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 12, 12, 192)  768         conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 12, 12, 192)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 12, 12, 64)   12288       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 12, 12, 64)   0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 12, 12, 208)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 12, 12, 208)  832         conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 12, 12, 208)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 12, 12, 64)   13312       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 12, 12, 64)   0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 12, 12, 224)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 12, 12, 224)  896         conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 12, 12, 224)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 12, 12, 64)   14336       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 12, 12, 64)   256         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 12, 12, 64)   0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 12, 12, 16)   9216        conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 12, 12, 240)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 12, 12, 240)  960         conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 12, 12, 240)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 12, 12, 64)   15360       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 12, 12, 64)   256         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 12, 12, 64)   0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 12, 12, 16)   9216        conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 12, 12, 256)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 12, 12, 256)  1024        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 12, 12, 256)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 12, 12, 64)   16384       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 12, 12, 64)   256         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 12, 12, 64)   0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 12, 12, 16)   9216        conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 12, 12, 272)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 12, 12, 272)  1088        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 12, 12, 272)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 12, 12, 136)  36992       pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 6, 6, 136)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 6, 6, 136)    544         pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 6, 6, 136)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 6, 6, 64)     8704        conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 6, 6, 64)     0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 6, 6, 152)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 6, 6, 152)    608         conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 6, 6, 152)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 6, 6, 64)     9728        conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 6, 6, 64)     0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 6, 6, 168)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 6, 6, 168)    672         conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 6, 6, 168)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 6, 6, 64)     10752       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 6, 6, 64)     0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 6, 6, 184)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 6, 6, 184)    736         conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 6, 6, 184)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 6, 6, 64)     11776       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 6, 6, 64)     0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 6, 6, 200)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 6, 6, 200)    800         conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 6, 6, 200)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 6, 6, 64)     12800       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 6, 6, 64)     0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 6, 6, 216)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 6, 6, 216)    864         conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 6, 6, 216)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 6, 6, 64)     13824       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 6, 6, 64)     0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 6, 6, 232)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 6, 6, 232)    928         conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 6, 6, 232)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 6, 6, 64)     14848       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 6, 6, 64)     0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 6, 6, 248)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 6, 6, 248)    992         conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 6, 6, 248)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 6, 6, 64)     15872       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 6, 6, 64)     0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 6, 6, 264)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 6, 6, 264)    1056        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 6, 6, 264)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 6, 6, 64)     16896       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 6, 6, 64)     0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 6, 6, 280)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 6, 6, 280)    1120        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 6, 6, 280)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 6, 6, 64)     17920       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 6, 6, 296)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 6, 6, 296)    1184        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 6, 6, 296)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 6, 6, 64)     18944       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 6, 6, 312)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 6, 6, 312)    1248        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 6, 6, 312)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 6, 6, 64)     19968       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 6, 6, 328)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 6, 6, 328)    1312        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 6, 6, 328)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 6, 6, 64)     20992       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 6, 6, 344)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 6, 6, 344)    1376        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 6, 6, 344)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 6, 6, 64)     22016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 6, 6, 360)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 6, 6, 360)    1440        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 6, 6, 360)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 6, 6, 64)     23040       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 6, 6, 376)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 6, 6, 376)    1504        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 6, 6, 376)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 6, 6, 64)     24064       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 6, 6, 392)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 6, 6, 392)    1568        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 6, 6, 392)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 6, 6, 64)     25088       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 6, 6, 408)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 6, 6, 408)    1632        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 6, 6, 408)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 6, 6, 64)     26112       conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 6, 6, 424)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 6, 6, 424)    1696        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 6, 6, 424)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 6, 6, 64)     27136       conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 6, 6, 440)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 6, 6, 440)    1760        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 6, 6, 440)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 6, 6, 64)     28160       conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 6, 6, 456)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 6, 6, 456)    1824        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 6, 6, 456)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 6, 6, 64)     29184       conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 6, 6, 472)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 6, 6, 472)    1888        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 6, 6, 472)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 6, 6, 64)     30208       conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 6, 6, 488)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 6, 6, 488)    1952        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 6, 6, 488)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 6, 6, 64)     31232       conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 6, 6, 504)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 6, 6, 504)    2016        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 6, 6, 504)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 6, 6, 64)     32256       conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 6, 6, 520)    0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 6, 6, 520)    2080        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 6, 6, 520)    0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 6, 6, 260)    135200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 3, 3, 260)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 3, 3, 260)    1040        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 3, 3, 260)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 3, 3, 64)     16640       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 3, 3, 64)     0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 3, 3, 276)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 3, 3, 276)    1104        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 3, 3, 276)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 3, 3, 64)     17664       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 3, 3, 64)     0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 3, 3, 292)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 3, 3, 292)    1168        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 3, 3, 292)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 3, 3, 64)     18688       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 3, 3, 64)     0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 3, 3, 308)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 3, 3, 308)    1232        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 3, 3, 308)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 3, 3, 64)     19712       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 3, 3, 64)     0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 3, 3, 324)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 3, 3, 324)    1296        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 3, 3, 324)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 3, 3, 64)     20736       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 3, 3, 64)     0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 3, 3, 340)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 3, 3, 340)    1360        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 3, 3, 340)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 3, 3, 64)     21760       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 3, 3, 64)     0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 3, 3, 356)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 3, 3, 356)    1424        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 3, 3, 356)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 3, 3, 64)     22784       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 3, 3, 64)     0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 3, 3, 372)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 3, 3, 372)    1488        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 3, 3, 372)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 3, 3, 64)     23808       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 3, 3, 64)     0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 3, 3, 388)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 3, 3, 388)    1552        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 3, 3, 388)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 3, 3, 64)     24832       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 3, 3, 64)     0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 3, 3, 404)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 3, 3, 404)    1616        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 3, 3, 404)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 3, 3, 64)     25856       conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 3, 3, 420)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 3, 3, 420)    1680        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 3, 3, 420)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 3, 3, 64)     26880       conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 3, 3, 436)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 3, 3, 436)    1744        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 3, 3, 436)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 3, 3, 64)     27904       conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 3, 3, 452)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 3, 3, 452)    1808        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 3, 3, 452)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 3, 3, 64)     28928       conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 3, 3, 468)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 3, 3, 468)    1872        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 3, 3, 468)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 3, 3, 64)     29952       conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 3, 3, 484)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 3, 3, 484)    1936        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 3, 3, 484)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 3, 3, 64)     30976       conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 3, 3, 500)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 3, 3, 500)    2000        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 3, 3, 500)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 3, 3, 64)     32000       conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 3, 3, 516)    0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 3, 3, 516)    2064        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 3, 3, 516)    0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 516)          0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 11)           5687        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,864,519\n",
      "Trainable params: 1,821,231\n",
      "Non-trainable params: 43,288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from architectures.mobilenet import mobilenet\n",
    "\n",
    "NUM_CLASSES_TURNEDTABLE = 12\n",
    "PRETRAINED_NUM_CLASSES = 11 # 11 supervised, 4 self-supervised\n",
    "input_shape = [96, 96, 1]\n",
    "\n",
    "model_name = \"mobilenet\"\n",
    "pretraining_mode = \"supervised_learning\"\n",
    "layers = [\"conv_pw_11_relu\", \"flatten\", \"conv_pw_12_relu\"]\n",
    "\n",
    "model = mobilenet(input_shape, PRETRAINED_NUM_CLASSES)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 4.66485694e-03 -3.67367379e-02  2.27108411e-02 ...  4.99464944e-03\n",
      "    -1.35363303e-02  3.47356535e-02]]\n",
      "\n",
      "  [[ 1.99087150e-02 -1.20914765e-02  9.17285681e-04 ...  2.40082331e-02\n",
      "     4.19551469e-02  3.78132239e-03]]\n",
      "\n",
      "  [[-4.13547494e-02 -9.29193944e-03 -1.22439135e-02 ... -4.31841277e-02\n",
      "    -1.55216772e-02  2.72484310e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-3.56882997e-02 -1.62722357e-02  3.51550691e-02 ...  1.76027119e-02\n",
      "     3.71384658e-02 -4.31046858e-02]]\n",
      "\n",
      "  [[ 3.45821418e-02  1.13544092e-02 -2.82610953e-03 ... -3.64640355e-02\n",
      "    -3.99637669e-02  3.98543105e-03]]\n",
      "\n",
      "  [[-1.34760533e-02  2.65032463e-02  1.67077556e-02 ...  2.56441534e-03\n",
      "    -3.16720530e-02 -1.54752657e-02]]]\n",
      "\n",
      "\n",
      " [[[ 2.40250714e-02 -2.04387568e-02 -1.07967705e-02 ... -2.57472545e-02\n",
      "     1.37788057e-02 -9.17182863e-03]]\n",
      "\n",
      "  [[ 3.73360328e-02 -3.19898538e-02 -2.58156043e-02 ... -2.48693619e-02\n",
      "     1.50026567e-02  3.44313942e-02]]\n",
      "\n",
      "  [[ 4.18304093e-02  8.57009739e-03  1.34905800e-02 ...  2.01280750e-02\n",
      "     1.44839175e-02  1.15773194e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 3.83135192e-02 -5.93677163e-03 -3.82195041e-03 ... -5.09612262e-04\n",
      "     3.34626921e-02  6.43172115e-03]]\n",
      "\n",
      "  [[ 3.85492481e-02  2.66499110e-02  3.79820280e-02 ...  1.16440244e-02\n",
      "    -1.69873722e-02  2.93670967e-03]]\n",
      "\n",
      "  [[ 2.37252302e-02 -1.79316588e-02 -3.34547833e-02 ...  3.36496271e-02\n",
      "     5.79323247e-03  2.89714374e-02]]]\n",
      "\n",
      "\n",
      " [[[-3.48268002e-02  4.11329456e-02  1.54579654e-02 ... -5.34845144e-03\n",
      "     1.15127563e-02 -5.52497804e-05]]\n",
      "\n",
      "  [[ 2.75255777e-02  1.49100535e-02  4.33750190e-02 ... -3.13368142e-02\n",
      "     4.26492654e-02 -3.32537927e-02]]\n",
      "\n",
      "  [[ 8.37688893e-03  3.56142782e-02 -1.75532382e-02 ... -4.09826003e-02\n",
      "    -1.21105872e-02 -3.40840966e-03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-3.31798755e-02 -9.37855244e-03 -2.40311865e-02 ...  2.99819075e-02\n",
      "    -1.09119974e-02  2.30647139e-02]]\n",
      "\n",
      "  [[-2.06955038e-02  3.42553742e-02  2.98802145e-02 ... -1.25254132e-02\n",
      "    -1.16988495e-02  9.02045518e-04]]\n",
      "\n",
      "  [[-2.36503556e-02  1.34838335e-02 -2.66164336e-02 ...  2.03178264e-02\n",
      "     1.79247670e-02 -4.48621437e-03]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 3.20210718e-02 -2.37386450e-02 -2.04592049e-02 ... -1.22942980e-02\n",
      "     6.37314096e-03  2.01219507e-02]]\n",
      "\n",
      "  [[-1.87175665e-02  3.23987268e-02 -2.01829523e-03 ...  9.45242867e-03\n",
      "     2.94815786e-02 -4.26711328e-02]]\n",
      "\n",
      "  [[-2.54391599e-02 -1.20403133e-02 -3.11530121e-02 ...  8.88864323e-03\n",
      "    -1.59999765e-02  3.26436348e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-4.32077721e-02  9.08225775e-03  2.59938464e-03 ... -3.81142162e-02\n",
      "     7.15707242e-03  2.23435648e-02]]\n",
      "\n",
      "  [[-3.19864377e-02 -3.51119936e-02 -4.92485985e-03 ...  9.69380140e-04\n",
      "     2.67775245e-02 -3.12434658e-02]]\n",
      "\n",
      "  [[ 1.50517374e-03  4.10549082e-02  2.69248374e-02 ... -6.40973449e-04\n",
      "    -9.30584595e-03 -4.54263389e-03]]]\n",
      "\n",
      "\n",
      " [[[-3.07783708e-02 -3.39708030e-02 -4.63145226e-03 ...  2.71318816e-02\n",
      "     1.17526986e-02 -2.16718763e-04]]\n",
      "\n",
      "  [[-1.78492256e-02 -3.44221257e-02 -3.37434784e-02 ... -4.08294052e-03\n",
      "    -1.67090818e-03 -1.18953288e-02]]\n",
      "\n",
      "  [[ 3.03459056e-02 -2.51787808e-02 -3.41935046e-02 ...  1.74358077e-02\n",
      "    -9.93409008e-03 -4.18235175e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-3.69398929e-02  2.77389213e-03  4.12563793e-02 ...  2.76373439e-02\n",
      "     2.50177197e-02  1.50165223e-02]]\n",
      "\n",
      "  [[ 3.84501033e-02  8.49406794e-03 -3.51398401e-02 ...  3.44860740e-02\n",
      "    -3.28209251e-04  2.55697034e-02]]\n",
      "\n",
      "  [[ 7.93216750e-03  1.56141371e-02 -1.01472847e-02 ... -3.06963716e-02\n",
      "    -2.69713122e-02  3.91827188e-02]]]\n",
      "\n",
      "\n",
      " [[[ 2.68824287e-02  2.18804590e-02 -2.35851202e-02 ...  1.87813826e-02\n",
      "     4.14461531e-02  3.56754996e-02]]\n",
      "\n",
      "  [[ 3.89261954e-02 -4.00414690e-02 -5.37291542e-03 ... -2.28688754e-02\n",
      "    -1.00518130e-02  1.53780058e-02]]\n",
      "\n",
      "  [[ 4.19152416e-02 -3.09670996e-02  1.77068673e-02 ... -4.08948176e-02\n",
      "     1.01043284e-02  3.38832401e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.12330036e-02 -1.93486661e-02 -2.70673521e-02 ...  2.80445069e-03\n",
      "     1.74404755e-02  3.70683894e-03]]\n",
      "\n",
      "  [[-3.37706506e-03 -1.21009238e-02 -2.97432393e-02 ...  3.76911573e-02\n",
      "     1.30934641e-02 -1.72558334e-02]]\n",
      "\n",
      "  [[-3.98377366e-02  1.26147680e-02 -2.49708071e-03 ... -6.07819855e-03\n",
      "     2.59313397e-02 -3.50266732e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights BEFORE loading pretrained model (second conv layer)\n",
    "print(model.layers[2].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pretrained checkpoint restored correctly: ../../../pretraining/results/supervised_learning/checkpoints/sonar1/densenet/batch_size_128/96x96_substract_mean_online_aug_width_16/ckpt-21\n"
     ]
    }
   ],
   "source": [
    "# path to pretrained model checkpoint\n",
    "pretrained_checkpoint_prefix = os.path.join(\"../../../pretraining/results/\" + pretraining_mode + \"/checkpoints/sonar1/\" + model_name + \"/batch_size_128/96x96_substract_mean_online_aug_width_32\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.5, epsilon=1)\n",
    "\n",
    "# define pretrained checkpoint model\n",
    "checkpoint_pretrained = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=model) # 4 ssl, 11 sl\n",
    "manager_pretrained = tf.train.CheckpointManager(checkpoint_pretrained, pretrained_checkpoint_prefix, max_to_keep=3)\n",
    "\n",
    "# restore model weights\n",
    "checkpoint_pretrained.restore(manager_pretrained.latest_checkpoint)\n",
    "\n",
    "if manager_pretrained.latest_checkpoint:\n",
    "    print(\"[INFO] Pretrained checkpoint restored correctly: {}\".format(manager_pretrained.latest_checkpoint))\n",
    "else:\n",
    "    print(\"[INFO] Could not restore pretrained checkpoint correctly, make sure path to pre-trained folder is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-3.80477868e-02 -1.86644085e-02  5.32500818e-02 ... -4.27079760e-02\n",
      "     5.60891628e-02 -2.59771314e-03]]\n",
      "\n",
      "  [[ 3.97802098e-03 -2.00276617e-02  2.73288600e-02 ...  2.01250408e-02\n",
      "     2.24691052e-02 -6.85801730e-02]]\n",
      "\n",
      "  [[-9.43620317e-03  1.82653219e-02  4.47336100e-02 ... -4.63400632e-02\n",
      "     4.27512117e-02 -3.92915569e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-2.78305411e-02 -2.30991896e-02  3.27819139e-02 ... -4.42118943e-02\n",
      "     2.21572872e-02 -8.57996382e-03]]\n",
      "\n",
      "  [[-3.68193239e-02  5.20618912e-03 -2.89888233e-02 ... -3.87197994e-02\n",
      "     1.77967101e-02 -3.11451945e-02]]\n",
      "\n",
      "  [[-2.38026064e-02 -3.42664160e-02 -4.74740844e-03 ...  1.67720150e-02\n",
      "    -3.37036705e-04 -3.29889730e-02]]]\n",
      "\n",
      "\n",
      " [[[ 5.08058656e-05  5.67482971e-03 -5.16554601e-02 ...  1.14891697e-02\n",
      "    -3.41569409e-02 -3.19605470e-02]]\n",
      "\n",
      "  [[ 4.19862978e-02 -3.94935608e-02 -4.05680425e-02 ...  1.59375537e-02\n",
      "    -3.91847752e-02 -3.30012962e-02]]\n",
      "\n",
      "  [[ 1.44974617e-02 -4.56194393e-02  7.97926541e-03 ...  9.54675674e-03\n",
      "    -2.20969301e-02 -4.29484025e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 5.06830029e-02 -2.09732447e-02  2.80379839e-02 ... -1.61925773e-03\n",
      "    -4.10502031e-02 -1.32489856e-02]]\n",
      "\n",
      "  [[-5.64618036e-04 -1.18780304e-02 -2.42110323e-02 ... -3.83443050e-02\n",
      "    -8.69677123e-03  1.76227633e-02]]\n",
      "\n",
      "  [[ 5.44338161e-03 -2.36332249e-02 -3.90916243e-02 ... -2.01666946e-04\n",
      "    -3.44757028e-02 -2.41004340e-02]]]\n",
      "\n",
      "\n",
      " [[[ 4.14957069e-02 -2.61492264e-02 -5.03453352e-02 ...  2.36526486e-02\n",
      "    -3.62771377e-02  1.07219052e-02]]\n",
      "\n",
      "  [[ 4.13819589e-02 -8.24433379e-03 -2.52148900e-02 ... -1.07541345e-02\n",
      "    -3.93668748e-02 -6.96544955e-03]]\n",
      "\n",
      "  [[-3.91687341e-02  7.10117398e-04  2.01707184e-02 ...  1.19690765e-02\n",
      "    -4.57301475e-02 -6.44172728e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.37767678e-02 -4.08607833e-02  3.06678973e-02 ... -3.30491811e-02\n",
      "    -2.82273125e-02  1.27227884e-02]]\n",
      "\n",
      "  [[ 1.41967880e-02 -1.96258202e-02  1.71818249e-02 ...  2.08447315e-02\n",
      "    -4.10522446e-02 -1.56851932e-02]]\n",
      "\n",
      "  [[ 3.50860786e-03 -2.84858458e-02  5.05732186e-02 ... -1.21511491e-02\n",
      "     3.52142402e-03  2.59951153e-03]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-5.03998017e-03 -2.07528789e-02 -1.54670617e-02 ... -8.87750462e-03\n",
      "    -3.79561558e-02 -1.51489750e-02]]\n",
      "\n",
      "  [[-1.94168221e-02  2.60096788e-03 -4.75792065e-02 ...  1.13463979e-02\n",
      "     1.45193394e-02 -2.00687516e-02]]\n",
      "\n",
      "  [[ 3.97992693e-02 -2.69309003e-02 -2.09516529e-02 ... -5.08272387e-02\n",
      "    -1.51907038e-02 -3.01969275e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-7.68873794e-03 -3.16096097e-02  5.25043672e-03 ... -1.73784513e-02\n",
      "    -1.97893679e-02  1.12714907e-02]]\n",
      "\n",
      "  [[ 4.02420722e-02  2.22817976e-02  4.95529659e-02 ... -5.26367649e-02\n",
      "     3.48509178e-02  1.32205738e-02]]\n",
      "\n",
      "  [[ 4.02667001e-02  1.33077269e-02  3.33124883e-02 ... -3.24409232e-02\n",
      "     2.98305899e-02  1.33524346e-03]]]\n",
      "\n",
      "\n",
      " [[[ 6.45925198e-03 -2.32669748e-02 -1.58647671e-02 ... -1.75099038e-02\n",
      "    -2.14982033e-02 -9.97579936e-03]]\n",
      "\n",
      "  [[-3.42748947e-02 -2.88009513e-02 -2.79873088e-02 ... -1.29683679e-02\n",
      "    -1.86806303e-02 -7.85720535e-04]]\n",
      "\n",
      "  [[ 1.68370623e-02 -4.69921576e-03 -5.53568453e-03 ... -3.09807118e-02\n",
      "    -2.46799570e-02  1.23861469e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.49516014e-02 -6.98037539e-03 -5.28281406e-02 ... -2.73400191e-02\n",
      "    -5.31715229e-02 -2.32389662e-03]]\n",
      "\n",
      "  [[ 3.05028986e-02 -4.60124537e-02  2.65914574e-02 ...  5.18987374e-03\n",
      "    -7.40745142e-02 -3.86181585e-02]]\n",
      "\n",
      "  [[ 5.45883328e-02 -2.55435314e-02  4.43629846e-02 ...  1.14635928e-02\n",
      "    -4.30897251e-02  3.26583721e-03]]]\n",
      "\n",
      "\n",
      " [[[-4.63544019e-02 -3.65573280e-02 -6.04407303e-03 ...  5.46714338e-03\n",
      "    -5.20618036e-02  3.80588695e-02]]\n",
      "\n",
      "  [[-1.60889998e-02  2.40871846e-03 -5.88438809e-02 ... -1.25758394e-04\n",
      "     1.81448516e-02  5.07964604e-02]]\n",
      "\n",
      "  [[-4.44141664e-02 -5.41422926e-02 -5.17992536e-04 ... -2.54950151e-02\n",
      "    -6.31286949e-02  1.07940501e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 4.06713448e-02 -2.81392541e-02 -1.53408349e-02 ... -1.32721066e-02\n",
      "     6.96314173e-03 -4.57406268e-02]]\n",
      "\n",
      "  [[ 1.02433413e-02  1.29994843e-02  8.01043399e-03 ... -1.84600521e-02\n",
      "     1.38507513e-02 -1.34531269e-02]]\n",
      "\n",
      "  [[ 5.73547818e-02 -3.32110412e-02 -2.35611536e-02 ...  1.09951971e-02\n",
      "     1.46446992e-02  4.11350764e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights AFTER loading pretrained model (second conv layer)\n",
    "print(model.layers[2].get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models up to intermediate layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate layers from model: ['conv5_block15_0_relu', 'conv5_block16_0_relu', 'avg_pool']\n"
     ]
    }
   ],
   "source": [
    "print(\"Intermediate layers from model:\", layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63297838/how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction\n",
    "model_conv_pw_11_relu = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                       outputs=model.get_layer(layers[0]).output)\n",
    "\n",
    "model_flatten_5 = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                 outputs=model.get_layer(layers[1]).output)\n",
    "\n",
    "model_conv_pw_12_relu = tf.keras.Model(inputs=model.get_layer(\"input_1\").output, \n",
    "                                       outputs=model.get_layer(layers[2]).output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate vector embeddings for train and test data (up to n-th layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Loading Tenorflow dataset\n",
      "[INFO] Retrieving Sonar Turned Table Supervised Data\n",
      "hdf5 dataset keys: <KeysViewHDF5 ['class_names', 'x_test', 'x_train', 'y_test', 'y_train']>\n",
      "[INFO] Data dimensions\n",
      "Train 1505\n",
      "Val 323\n",
      "Test 645\n",
      "\n",
      "[INFO] Tensorflow data dimensions\n",
      "<PrefetchDataset shapes: ((None, 96, 96, 1), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# define tensorflow dataset\n",
    "data_dir = \"../../../../../../datasets/sonar_turntable_dataset_2/marine-debris-turntable-classification-object_classes-platform-96x96.hdf5\"\n",
    "train_dataset, test_dataset = load_sonar_turnedtable_supervised(data_dir)\n",
    "\n",
    "# load tensorflow tensors individually\n",
    "x_train, y_train = next(iter(train_dataset))\n",
    "x_test, y_test = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a forward pass to generate embeddings (both train and test data) (for each n-th layer)\n",
    "\n",
    "# NOTE: when doing this all tensors are loaded into memory, this saturates NVIDIA memory (nvidia-smi)\n",
    "x_train_conv_pw_11_relu = model_conv_pw_11_relu([x_train], training=False)\n",
    "x_train_flatten_5 = model_flatten_5([x_train], training=False)\n",
    "x_train_conv_pw_12_relu = model_conv_pw_12_relu([x_train], training=False)\n",
    "\n",
    "x_test_conv_pw_11_relu = model_conv_pw_11_relu([x_test], training=False)\n",
    "x_test_flatten_5 = model_flatten_5([x_test], training=False)\n",
    "x_test_conv_pw_12_relu = model_conv_pw_12_relu([x_test], training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning setup: classification with subsamples per object class (few shot learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning params\n",
    "# SAMPLES_PER_CLASS = [1, 5, 10, 20, 30, 40, 50] # NOTE: taking more samples per class since it is 88 for 50\n",
    "# SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 70, 90, 110, 130, 150, len(x_test)]\n",
    "SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 80, 110, 140, 170, 200]\n",
    "TRIALS = 10\n",
    "\n",
    "NUM_CLASSES_WATERTANK = 11\n",
    "NUM_CLASSES_TURNEDTABLE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505, 4356)\n",
      "(645, 4356)\n"
     ]
    }
   ],
   "source": [
    "# Flatten train & test data for SVM\n",
    "x_train_conv_pw_11_relu = flatten(x_train_conv_pw_11_relu.numpy())\n",
    "x_train_flatten_5 = flatten(x_train_flatten_5.numpy())\n",
    "x_train_conv_pw_12_relu = flatten(x_train_conv_pw_12_relu.numpy())\n",
    "\n",
    "x_test_conv_pw_11_relu = flatten(x_test_conv_pw_11_relu.numpy())\n",
    "x_test_flatten_5 = flatten(x_test_flatten_5.numpy())\n",
    "x_test_conv_pw_12_relu = flatten(x_test_conv_pw_12_relu.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505,)\n",
      "(645,)\n"
     ]
    }
   ],
   "source": [
    "# these two are not modified (only x_test, x_train)\n",
    "print(y_train.numpy().shape)\n",
    "print(y_test.numpy().shape)\n",
    "\n",
    "y_train = y_train.numpy() # convert from tf tensor --> numpy\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run svm tl evaluation with spc for each n-th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_with_spc(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Takes embeddings from pretrained model and evaluates transfer learning \n",
    "    with few samples per class.\n",
    "    \"\"\"\n",
    "    # NOTE: svm takes original labels (not one-hot encoding)\n",
    "    for spc in SAMPLES_PER_CLASS:\n",
    "        accuracies = []\n",
    "\n",
    "        for i in range(TRIALS):\n",
    "            x_sample, y_sample = classSampling(x_train, y_train, spc, NUM_CLASSES_TURNEDTABLE)\n",
    "\n",
    "            svm = SVC(C=1.0, decision_function_shape = 'ovo', kernel=\"linear\")\n",
    "            svm.fit(x_sample, y_sample)\n",
    "\n",
    "            train_acc = svm.score(x_sample, y_sample)\n",
    "            test_acc = svm.score(x_test, y_test)\n",
    "\n",
    "            print(\"SPC {} Train Accuracy: {:.3f}\".format(spc, train_acc))\n",
    "            print(\"SPC {} Test Accuracy: {:.3f}\".format(spc, test_acc))\n",
    "            print()\n",
    "\n",
    "            accuracies.append(test_acc)\n",
    "\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "\n",
    "        mean_acc = round(100 * mean_acc, 3)\n",
    "        std_acc = round(100 * std_acc, 3)\n",
    "\n",
    "        print(\"After {} trials - Test Accuracy is {} +- {}\".format(TRIALS, mean_acc, std_acc ))\n",
    "        print(\"------------------------------------------------------------------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.710\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.712\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.606\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.682\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.678\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.705\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.704\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.676\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.740\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.685\n",
      "\n",
      "After 10 trials - Test Accuracy is 68.977 +- 3.349\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.792\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.812\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.753\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.802\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.764\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.843\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.809\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.792\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.789\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.797\n",
      "\n",
      "After 10 trials - Test Accuracy is 79.55 +- 2.368\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.826\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.836\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.865\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.867\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.817\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.811\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.798\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.853\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.876\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.848\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.969 +- 2.484\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.848\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.891\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.865\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.860\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.878\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.851\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.854\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.870\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.843\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.865\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.264 +- 1.38\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.876\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.915\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.915\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.893\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.893\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.887\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.896\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.888\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.871\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.895\n",
      "\n",
      "After 10 trials - Test Accuracy is 89.287 +- 1.333\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.924\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.915\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.915\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.905\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.910\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.912\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.924\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.929\n",
      "\n",
      "After 10 trials - Test Accuracy is 91.783 +- 0.714\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.930\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.943\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.935\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.936\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.938\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.924\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.926\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.946\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.949\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.930\n",
      "\n",
      "After 10 trials - Test Accuracy is 93.566 +- 0.791\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.960\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.949\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.940\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.947\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.933\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.952\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.935\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.936\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.372 +- 0.788\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.940\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.957\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.957\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.953\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.952\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.961\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.947\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.955\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.960\n",
      "\n",
      "After 10 trials - Test Accuracy is 95.318 +- 0.604\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.953\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.963\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.946\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.960\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.958\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.953\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.964\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.953\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.960\n",
      "\n",
      "After 10 trials - Test Accuracy is 95.612 +- 0.551\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_conv_pw_11_relu, y_train, x_test_conv_pw_11_relu, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.622\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.634\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.643\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.654\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.594\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.608\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.698\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.633\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.628\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.653\n",
      "\n",
      "After 10 trials - Test Accuracy is 63.659 +- 2.708\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.704\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.732\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.740\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.744\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.705\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.752\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.767\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.760\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.727\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.741\n",
      "\n",
      "After 10 trials - Test Accuracy is 73.721 +- 1.989\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.774\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.797\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.778\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.738\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.814\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.809\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.781\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.797\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.789\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.798\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.76 +- 2.059\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.837\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.798\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.823\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.839\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.829\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.803\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.828\n",
      "\n",
      "After 10 trials - Test Accuracy is 81.829 +- 1.397\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.850\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.825\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.843\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.839\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.831\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.837\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.831\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.823\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.817\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.287 +- 0.927\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.881\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.871\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.868\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.878\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.859\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.868\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.873\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.867\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.862\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.884\n",
      "\n",
      "After 10 trials - Test Accuracy is 87.101 +- 0.749\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.887\n",
      "\n",
      "SPC 110 Train Accuracy: 0.999\n",
      "SPC 110 Test Accuracy: 0.887\n",
      "\n",
      "SPC 110 Train Accuracy: 0.999\n",
      "SPC 110 Test Accuracy: 0.893\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.868\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.896\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.888\n",
      "\n",
      "SPC 110 Train Accuracy: 0.999\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 0.999\n",
      "SPC 110 Test Accuracy: 0.871\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.605 +- 0.858\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.895\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.896\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.918\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.904\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.904\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.896\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.909\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.913\n",
      "\n",
      "SPC 140 Train Accuracy: 0.999\n",
      "SPC 140 Test Accuracy: 0.876\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.895\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.047 +- 1.122\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.924\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.910\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.888\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.915\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.921\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.899\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.912\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.868 +- 0.979\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.919\n",
      "\n",
      "SPC 200 Train Accuracy: 0.999\n",
      "SPC 200 Test Accuracy: 0.918\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.926\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.918\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.918\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.918\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.915\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.926\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.916\n",
      "\n",
      "SPC 200 Train Accuracy: 0.999\n",
      "SPC 200 Test Accuracy: 0.924\n",
      "\n",
      "After 10 trials - Test Accuracy is 91.969 +- 0.372\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_flatten_5, y_train, x_test_flatten_5, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.735\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.730\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.715\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.712\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.684\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.687\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.657\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.704\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.740\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.633\n",
      "\n",
      "After 10 trials - Test Accuracy is 69.953 +- 3.296\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.809\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.798\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.806\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.755\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.816\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.760\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.784\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.780\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.834\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.763\n",
      "\n",
      "After 10 trials - Test Accuracy is 79.054 +- 2.513\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.820\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.842\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.845\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.854\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.833\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.828\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.826\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.802\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.828\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.823\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.008 +- 1.391\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.859\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.878\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.874\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.879\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.859\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.860\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.871\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.868\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.848\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.873\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.698 +- 0.948\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.901\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.881\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.885\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.904\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.881\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.878\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.887\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.893\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.729 +- 0.855\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.909\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.919\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.916\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.929\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.932\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.907\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.913\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.933\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.898\n",
      "\n",
      "After 10 trials - Test Accuracy is 91.783 +- 1.101\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.938\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.941\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.946\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.938\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.924\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.935\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.943\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.932\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.946\n",
      "\n",
      "After 10 trials - Test Accuracy is 93.752 +- 0.643\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.961\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.940\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.936\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.950\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.946\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.941\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.946\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.953\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.543 +- 0.733\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.955\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.955\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.955\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.946\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.940\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.944\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.963\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.946\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.947\n",
      "\n",
      "After 10 trials - Test Accuracy is 95.008 +- 0.653\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.955\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.953\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.961\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.960\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.963\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.953\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.955\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.957\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.963\n",
      "\n",
      "After 10 trials - Test Accuracy is 95.705 +- 0.41\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_conv_pw_12_relu, y_train, x_test_conv_pw_12_relu, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot tl results for each n-th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (7,6)\n",
    "\n",
    "# NOTE: avg pool is much faster to compute\n",
    "conv5_block15_accs = [69.953, 79.054, 83.008, 86.698, 88.729, 91.783, 93.752, 94.543, 95.008, 95.705]\n",
    "conv5_block16_accs = [68.977, 79.55, 83.969, 86.264, 89.287, 91.783, 93.566, 94.372, 95.318, 95.612]\n",
    "avg_pool_accs = [63.659, 73.721, 78.76, 81.829, 83.287, 87.101, 88.605, 90.047, 90.868, 91.969]\n",
    "\n",
    "plt.ylim(65, 100)\n",
    "plt.plot(SAMPLES_PER_CLASS, conv5_block15_accs, marker='o', linestyle='--', color='r', label=layers[0]+\" supervised\")\n",
    "plt.plot(SAMPLES_PER_CLASS, conv5_block16_accs, marker='o', linestyle='--', color='b', label=layers[1]+\" supervised\")\n",
    "plt.plot(SAMPLES_PER_CLASS, avg_pool_accs, marker='o', linestyle='--', color='g', label=layers[2]+\" supervised\")\n",
    "\n",
    "plt.xlabel(\"Samples per class\", fontsize=18)\n",
    "plt.ylabel(\"Test accuracy\", fontsize=18) \n",
    "plt.grid()\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(SAMPLES_PER_CLASS, fontsize=14, rotation=45)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rotnet] *",
   "language": "python",
   "name": "conda-env-rotnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
