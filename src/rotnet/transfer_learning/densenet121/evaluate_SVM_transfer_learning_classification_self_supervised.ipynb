{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate transfer learning on Turnedtable Watertank (Dataset 2)  using an SVM Classifier: Self-supervised approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Tensorflow for GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tensorflow Version: 2.2.0\n",
      "[INFO] Tensorflow built with CUDA\n",
      "[INFO] Number GPUs Available:  1\n",
      "[INFO] List of GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(\"[INFO] Tensorflow Version:\", tf.__version__)\n",
    "\n",
    "if tf.config.list_physical_devices(\"GPU\") and tf.test.is_built_with_cuda():\n",
    "    print(\"[INFO] Tensorflow built with CUDA\")\n",
    "    print(\"[INFO] Number GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    print(\"[INFO] List of GPU devices:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "    physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    # tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "else:\n",
    "    print(\"[ERROR] GPU not detected, make sure tensorflow-gpu is installed and that GPU is recognized\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "def flatten(x):\n",
    "    return x.reshape((x.shape[0], -1))\n",
    "\n",
    "def classSampling(X, y, samplesPerClass, numberOfClasses):\n",
    "    X_ret = np.zeros((samplesPerClass * numberOfClasses, X.shape[1]), dtype = np.float32)\n",
    "    y_ret = np.zeros((samplesPerClass * numberOfClasses), dtype = np.uint8)\n",
    "    count = 0\n",
    "\n",
    "    for classIdx in range(numberOfClasses):\n",
    "        indices = np.where(y == classIdx)[0]\n",
    "\n",
    "        #if len(indices) < samplesPerClass:\n",
    "        #    raise IndexError(\"Not enough samples for class {} to produce {} samples per class. Only {} class samples available\".format(classIdx, samplesPerClass, len(indices)))\n",
    "\n",
    "        doResample = len(indices) < samplesPerClass\n",
    "\n",
    "        chosenIndices = np.random.choice(indices, samplesPerClass, replace = doResample)\n",
    "\n",
    "        for ci in chosenIndices:\n",
    "            X_ret[count] = X[ci]\n",
    "            y_ret[count] = y[ci]\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    return X_ret, y_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonarTurnedTableSupervised(object):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def _normalize_images(self, images):\n",
    "        \"\"\"\n",
    "        Normalize sonar images by 1/255.\n",
    "        \"\"\"\n",
    "        return [element/255.0 for element in images]\n",
    "\n",
    "    def get_sonar_data(self):\n",
    "        \"\"\"\n",
    "        Reads from HDF5 file containing sonar data (resized to fix dims).\n",
    "        Returns list of np arrays containing image data.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"[INFO] Retrieving Sonar Turned Table Supervised Data\")\n",
    "\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            # list all groups\n",
    "            print(\"hdf5 dataset keys: %s\" % f.keys())\n",
    "\n",
    "            # get images and labels\n",
    "            x_train = f[\"x_train\"][...].astype(np.float32)\n",
    "            y_train = f[\"y_train\"][...]\n",
    "\n",
    "            x_test = f[\"x_test\"][...].astype(np.float32)\n",
    "            y_test = f[\"y_test\"][...]\n",
    "\n",
    "            _, x_val, _, y_val = train_test_split(x_test, y_test, train_size=0.5)\n",
    "\n",
    "            print(\"[INFO] Data dimensions\")\n",
    "            print(\"Train\", len(x_train))\n",
    "            print(\"Val\", len(x_val))\n",
    "            print(\"Test\", len(x_test))\n",
    "\n",
    "            # matias normalization\n",
    "            # multiply by 255 because hdf5 file comes as 1/255\n",
    "            x_train *= 255.0\n",
    "            x_val *= 255.0\n",
    "            x_test *= 255.0\n",
    "\n",
    "            x_train -= 84.51\n",
    "            x_val -= 84.51\n",
    "            x_test  -= 84.51\n",
    "\n",
    "        return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "    \n",
    "def load_sonar_turnedtable_supervised(file_path):\n",
    "    \"\"\"\n",
    "    Loads test data from turnedtable dataset.\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print(\"[INFO] Loading Tenorflow dataset\")\n",
    "\n",
    "    dataset_object = SonarTurnedTableSupervised(file_path)\n",
    "\n",
    "    # Read data\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = dataset_object.get_sonar_data()\n",
    "\n",
    "    # Train data\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(len(x_train))\n",
    "    train_dataset = train_dataset.prefetch(25)\n",
    "\n",
    "    # Validation data\n",
    "    # val_dataset = tf.data.Dataset.from_tensor_slices((x_val, labels_val))\n",
    "    # val_dataset = val_dataset.shuffle(buffer_size=len(x_val)).batch(batch_size)\n",
    "    # val_dataset = val_dataset.prefetch(25)\n",
    "\n",
    "    # Test data\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = test_dataset.shuffle(buffer_size=len(x_test)).batch(len(x_test)) # feed full test set\n",
    "    test_dataset = test_dataset.prefetch(25)\n",
    "\n",
    "    print()\n",
    "    print(\"[INFO] Tensorflow data dimensions\")\n",
    "    # print(train_dataset)\n",
    "    # print(val_dataset)\n",
    "    print(test_dataset)\n",
    "\n",
    "    # return train_dataset, val_dataset, test_dataset\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 102, 102, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 48, 48, 64)   3136        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 48, 48, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 48, 48, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 50, 50, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 24, 24, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 24, 24, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 24, 24, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 24, 24, 64)   4096        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 24, 24, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 24, 24, 80)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 24, 24, 80)   320         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 24, 24, 80)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 24, 24, 64)   5120        conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 24, 24, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 24, 24, 96)   0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 24, 24, 96)   384         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 24, 24, 96)   0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 24, 24, 64)   6144        conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 24, 24, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 24, 24, 112)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 24, 24, 112)  448         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 24, 24, 112)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 24, 24, 64)   7168        conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 24, 24, 64)   0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 24, 24, 128)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 24, 24, 128)  512         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 24, 24, 128)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 24, 24, 64)   8192        conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 24, 24, 64)   0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 24, 24, 144)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 24, 24, 144)  576         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 24, 24, 144)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 24, 24, 64)   9216        conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 24, 24, 64)   256         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 24, 24, 64)   0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 24, 24, 16)   9216        conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 24, 24, 160)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 24, 24, 160)  640         conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 24, 24, 160)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 24, 24, 80)   12800       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 12, 12, 80)   0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 12, 12, 80)   320         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 12, 12, 80)   0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 12, 12, 64)   5120        conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 12, 12, 64)   0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 12, 12, 96)   0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 12, 12, 96)   384         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 12, 12, 96)   0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 12, 12, 64)   6144        conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 12, 12, 64)   0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 12, 12, 112)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 12, 12, 112)  448         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 12, 12, 112)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 12, 12, 64)   7168        conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 12, 12, 64)   0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 12, 12, 128)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 12, 12, 128)  512         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 12, 12, 128)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 12, 12, 64)   8192        conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 12, 12, 64)   0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 12, 12, 144)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 12, 12, 144)  576         conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 12, 12, 144)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 12, 12, 64)   9216        conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 12, 12, 64)   0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 12, 12, 160)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 12, 12, 160)  640         conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 12, 12, 160)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 12, 12, 64)   10240       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 12, 12, 64)   0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 12, 12, 176)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 12, 12, 176)  704         conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 12, 12, 176)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 12, 12, 64)   11264       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 12, 12, 64)   0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 12, 12, 192)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 12, 12, 192)  768         conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 12, 12, 192)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 12, 12, 64)   12288       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 12, 12, 64)   0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 12, 12, 208)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 12, 12, 208)  832         conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 12, 12, 208)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 12, 12, 64)   13312       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 12, 12, 64)   256         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 12, 12, 64)   0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 12, 12, 16)   9216        conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 12, 12, 224)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 12, 12, 224)  896         conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 12, 12, 224)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 12, 12, 64)   14336       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 12, 12, 64)   256         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 12, 12, 64)   0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 12, 12, 16)   9216        conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 12, 12, 240)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 12, 12, 240)  960         conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 12, 12, 240)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 12, 12, 64)   15360       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 12, 12, 64)   256         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 12, 12, 64)   0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 12, 12, 16)   9216        conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 12, 12, 256)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 12, 12, 256)  1024        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 12, 12, 256)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 12, 12, 64)   16384       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 12, 12, 64)   256         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 12, 12, 64)   0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 12, 12, 16)   9216        conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 12, 12, 272)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 12, 12, 272)  1088        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 12, 12, 272)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 12, 12, 136)  36992       pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 6, 6, 136)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 6, 6, 136)    544         pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 6, 6, 136)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 6, 6, 64)     8704        conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 6, 6, 64)     0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 6, 6, 152)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 6, 6, 152)    608         conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 6, 6, 152)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 6, 6, 64)     9728        conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 6, 6, 64)     0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 6, 6, 168)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 6, 6, 168)    672         conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 6, 6, 168)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 6, 6, 64)     10752       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 6, 6, 64)     0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 6, 6, 184)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 6, 6, 184)    736         conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 6, 6, 184)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 6, 6, 64)     11776       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 6, 6, 64)     0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 6, 6, 200)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 6, 6, 200)    800         conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 6, 6, 200)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 6, 6, 64)     12800       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 6, 6, 64)     0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 6, 6, 216)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 6, 6, 216)    864         conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 6, 6, 216)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 6, 6, 64)     13824       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 6, 6, 64)     0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 6, 6, 232)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 6, 6, 232)    928         conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 6, 6, 232)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 6, 6, 64)     14848       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 6, 6, 64)     0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 6, 6, 248)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 6, 6, 248)    992         conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 6, 6, 248)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 6, 6, 64)     15872       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 6, 6, 64)     0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 6, 6, 264)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 6, 6, 264)    1056        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 6, 6, 264)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 6, 6, 64)     16896       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 6, 6, 64)     256         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 6, 6, 64)     0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 6, 6, 16)     9216        conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 6, 6, 280)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 6, 6, 280)    1120        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 6, 6, 280)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 6, 6, 64)     17920       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 6, 6, 296)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 6, 6, 296)    1184        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 6, 6, 296)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 6, 6, 64)     18944       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 6, 6, 312)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 6, 6, 312)    1248        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 6, 6, 312)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 6, 6, 64)     19968       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 6, 6, 328)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 6, 6, 328)    1312        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 6, 6, 328)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 6, 6, 64)     20992       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 6, 6, 344)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 6, 6, 344)    1376        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 6, 6, 344)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 6, 6, 64)     22016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 6, 6, 360)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 6, 6, 360)    1440        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 6, 6, 360)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 6, 6, 64)     23040       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 6, 6, 376)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 6, 6, 376)    1504        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 6, 6, 376)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 6, 6, 64)     24064       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 6, 6, 392)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 6, 6, 392)    1568        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 6, 6, 392)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 6, 6, 64)     25088       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 6, 6, 408)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 6, 6, 408)    1632        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 6, 6, 408)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 6, 6, 64)     26112       conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 6, 6, 424)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 6, 6, 424)    1696        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 6, 6, 424)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 6, 6, 64)     27136       conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 6, 6, 440)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 6, 6, 440)    1760        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 6, 6, 440)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 6, 6, 64)     28160       conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 6, 6, 456)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 6, 6, 456)    1824        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 6, 6, 456)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 6, 6, 64)     29184       conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 6, 6, 472)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 6, 6, 472)    1888        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 6, 6, 472)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 6, 6, 64)     30208       conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 6, 6, 488)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 6, 6, 488)    1952        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 6, 6, 488)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 6, 6, 64)     31232       conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 6, 6, 504)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 6, 6, 504)    2016        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 6, 6, 504)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 6, 6, 64)     32256       conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 6, 6, 64)     256         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 6, 6, 64)     0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 6, 6, 16)     9216        conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 6, 6, 520)    0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 6, 6, 520)    2080        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 6, 6, 520)    0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 6, 6, 260)    135200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 3, 3, 260)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 3, 3, 260)    1040        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 3, 3, 260)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 3, 3, 64)     16640       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 3, 3, 64)     0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 3, 3, 276)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 3, 3, 276)    1104        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 3, 3, 276)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 3, 3, 64)     17664       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 3, 3, 64)     0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 3, 3, 292)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 3, 3, 292)    1168        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 3, 3, 292)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 3, 3, 64)     18688       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 3, 3, 64)     0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 3, 3, 308)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 3, 3, 308)    1232        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 3, 3, 308)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 3, 3, 64)     19712       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 3, 3, 64)     0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 3, 3, 324)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 3, 3, 324)    1296        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 3, 3, 324)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 3, 3, 64)     20736       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 3, 3, 64)     0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 3, 3, 340)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 3, 3, 340)    1360        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 3, 3, 340)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 3, 3, 64)     21760       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 3, 3, 64)     0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 3, 3, 356)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 3, 3, 356)    1424        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 3, 3, 356)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 3, 3, 64)     22784       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 3, 3, 64)     0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 3, 3, 372)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 3, 3, 372)    1488        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 3, 3, 372)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 3, 3, 64)     23808       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 3, 3, 64)     0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 3, 3, 388)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 3, 3, 388)    1552        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 3, 3, 388)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 3, 3, 64)     24832       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 3, 3, 64)     256         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 3, 3, 64)     0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 3, 3, 16)     9216        conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 3, 3, 404)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 3, 3, 404)    1616        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 3, 3, 404)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 3, 3, 64)     25856       conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 3, 3, 420)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 3, 3, 420)    1680        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 3, 3, 420)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 3, 3, 64)     26880       conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 3, 3, 436)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 3, 3, 436)    1744        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 3, 3, 436)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 3, 3, 64)     27904       conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 3, 3, 452)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 3, 3, 452)    1808        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 3, 3, 452)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 3, 3, 64)     28928       conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 3, 3, 468)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 3, 3, 468)    1872        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 3, 3, 468)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 3, 3, 64)     29952       conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 3, 3, 484)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 3, 3, 484)    1936        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 3, 3, 484)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 3, 3, 64)     30976       conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 3, 3, 500)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 3, 3, 500)    2000        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 3, 3, 500)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 3, 3, 64)     32000       conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 3, 3, 64)     256         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 3, 3, 64)     0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 3, 3, 16)     9216        conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 3, 3, 516)    0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 3, 3, 516)    2064        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 3, 3, 516)    0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 516)          0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 4)            2068        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,860,900\n",
      "Trainable params: 1,817,612\n",
      "Non-trainable params: 43,288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from architectures.densenet import DenseNet121\n",
    "\n",
    "NUM_CLASSES_TURNEDTABLE = 12\n",
    "PRETRAINED_NUM_CLASSES = 4 # 11 supervised, 4 self-supervised\n",
    "input_shape = [96, 96, 1]\n",
    "\n",
    "model_name = \"densenet\"\n",
    "layers = [\"conv5_block15_0_relu\", \"conv5_block16_0_relu\", \"avg_pool\"]\n",
    "\n",
    "densenet = DenseNet121(input_shape, PRETRAINED_NUM_CLASSES)\n",
    "\n",
    "densenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-2.2330433e-02 -5.2833110e-03  1.7019548e-03 ...  1.8319588e-02\n",
      "     1.3074372e-02 -8.2656741e-04]]\n",
      "\n",
      "  [[-2.9247750e-02 -1.6578529e-02  1.7775297e-02 ...  3.9136659e-02\n",
      "    -1.0952678e-02 -2.4488635e-02]]\n",
      "\n",
      "  [[ 1.4124062e-02 -6.5119714e-03 -9.7277500e-03 ... -2.8765175e-02\n",
      "    -3.5280056e-02 -6.2566213e-03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 7.3371492e-03 -2.7345344e-02  1.1993427e-02 ... -3.6385402e-02\n",
      "     4.3337282e-02  9.1407523e-03]]\n",
      "\n",
      "  [[-1.4882712e-02 -3.4112871e-02  4.0055905e-02 ... -3.7502460e-03\n",
      "    -3.9334603e-02  3.3729877e-02]]\n",
      "\n",
      "  [[-1.1524979e-02  7.7619925e-03  3.8866464e-02 ...  2.3782592e-02\n",
      "    -2.6207931e-02 -5.5283830e-03]]]\n",
      "\n",
      "\n",
      " [[[ 1.2665246e-02  2.8192509e-02  3.7521534e-03 ... -6.2553585e-03\n",
      "     3.5190806e-03 -2.4418609e-02]]\n",
      "\n",
      "  [[-4.3346740e-02  2.5528062e-02  2.9784445e-02 ... -2.0451423e-02\n",
      "    -2.3807347e-02  5.3092204e-03]]\n",
      "\n",
      "  [[ 2.4830032e-02 -1.6430335e-02  2.5094751e-02 ... -1.3534913e-02\n",
      "     4.3254383e-03  1.6232539e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-8.5826963e-05  1.7647769e-02  2.8799128e-02 ... -2.4817921e-02\n",
      "    -2.2767952e-02 -1.2053054e-02]]\n",
      "\n",
      "  [[-1.8361675e-02 -2.5700890e-03 -2.0870501e-02 ... -9.4956309e-03\n",
      "    -3.2942027e-02 -4.3363493e-02]]\n",
      "\n",
      "  [[ 1.6445294e-04 -4.3466613e-03  3.3678409e-02 ...  6.0118586e-03\n",
      "     3.7027065e-02  9.5695183e-03]]]\n",
      "\n",
      "\n",
      " [[[ 1.5659835e-02  1.7681196e-03 -3.9115116e-02 ... -2.8577447e-04\n",
      "     3.4516390e-02  3.0627731e-02]]\n",
      "\n",
      "  [[ 2.8056446e-02 -1.4183087e-02 -4.1247625e-02 ...  4.0531527e-02\n",
      "    -2.9195575e-02  8.1905089e-03]]\n",
      "\n",
      "  [[ 1.4484338e-03  3.0785728e-02 -3.8580380e-02 ...  4.3032568e-02\n",
      "     1.5429020e-02 -3.7511203e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-1.5577070e-02 -2.1314560e-02 -8.9307092e-03 ... -1.4588991e-02\n",
      "     2.4806734e-02 -1.0058135e-02]]\n",
      "\n",
      "  [[-9.7117200e-03 -6.0238205e-03  3.9950717e-02 ... -2.7901441e-02\n",
      "    -3.0823089e-03  1.4512416e-02]]\n",
      "\n",
      "  [[ 4.0405568e-02  1.7375592e-02  2.3677614e-02 ... -3.3220463e-02\n",
      "    -3.4046780e-02 -3.0374525e-02]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-2.5244020e-03  2.0369235e-02 -2.1116372e-02 ... -3.2345984e-02\n",
      "    -4.1386083e-02  7.2968565e-03]]\n",
      "\n",
      "  [[-3.9839391e-02 -3.3729337e-03 -1.1035979e-02 ... -4.1612271e-02\n",
      "    -1.3371205e-02 -4.4292286e-03]]\n",
      "\n",
      "  [[-9.2199370e-03 -7.3073171e-03 -2.1123366e-02 ...  2.7268652e-02\n",
      "    -1.3520809e-02 -1.4704064e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 6.3518360e-03 -4.2769521e-02 -2.0902455e-03 ...  3.4270141e-02\n",
      "     3.9863970e-02  3.7390586e-02]]\n",
      "\n",
      "  [[ 4.0802125e-02  1.9330978e-03  1.2230553e-02 ... -2.5378883e-02\n",
      "    -2.0323675e-02  6.4297020e-04]]\n",
      "\n",
      "  [[ 1.9517671e-02 -1.1415370e-02 -2.7626213e-02 ...  1.6289517e-02\n",
      "    -2.4883611e-02  3.0280303e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.0855261e-02  3.1336319e-02 -7.7447630e-03 ... -2.5550991e-02\n",
      "    -1.0845151e-02  2.8652120e-02]]\n",
      "\n",
      "  [[-3.5458770e-02 -2.4400489e-02  9.0632550e-03 ...  4.0225793e-02\n",
      "    -2.6348097e-02  2.0072673e-02]]\n",
      "\n",
      "  [[ 7.4645355e-03  2.4125475e-02 -1.5513534e-02 ...  7.0212781e-04\n",
      "    -6.6468790e-03 -2.8702911e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-3.1682402e-03 -3.8982898e-02  3.1992409e-02 ...  2.9089753e-02\n",
      "     3.6123913e-02  1.0890607e-02]]\n",
      "\n",
      "  [[ 4.2188507e-02 -7.2517619e-04 -1.4155086e-02 ... -3.0961512e-02\n",
      "    -1.8669749e-02  3.7436094e-02]]\n",
      "\n",
      "  [[-1.1409707e-03  3.4605052e-02  4.9102195e-03 ... -2.7757943e-02\n",
      "     3.7343949e-03 -3.2750204e-02]]]\n",
      "\n",
      "\n",
      " [[[ 4.2299170e-02 -1.5883882e-02  3.6862567e-03 ...  3.4166649e-03\n",
      "     2.6055921e-02 -2.5098676e-02]]\n",
      "\n",
      "  [[ 4.0274005e-02 -1.7420307e-02 -3.2370098e-02 ... -2.8770372e-02\n",
      "     1.9838411e-02  1.8409222e-02]]\n",
      "\n",
      "  [[-4.2082809e-02 -2.3172345e-02  2.7775001e-02 ...  2.5531236e-02\n",
      "    -2.9537849e-02  3.3265661e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-7.1604364e-03 -8.0456547e-03 -3.5131902e-02 ...  3.9895188e-02\n",
      "     3.1134117e-02 -6.1941184e-03]]\n",
      "\n",
      "  [[-1.4261743e-02 -1.3001934e-02 -3.9141625e-03 ...  9.0448782e-03\n",
      "    -3.4095798e-02 -3.4723803e-02]]\n",
      "\n",
      "  [[-7.7653453e-03  2.1697395e-03  4.0908013e-02 ... -7.3136091e-03\n",
      "     3.0287798e-02  3.3876587e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights BEFORE loading pretrained model (second conv layer)\n",
    "print(densenet.layers[2].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pretrained checkpoint restored correctly: ../../../pretraining/results/self_supervised_learning/checkpoints/sonar1/densenet/batch_size_128/96x96_substract_mean_online_aug_width_16/ckpt-21\n"
     ]
    }
   ],
   "source": [
    "# path to pretrained model checkpoint\n",
    "pretrained_checkpoint_prefix = os.path.join(\"../../../pretraining/results/self_supervised_learning/checkpoints/sonar1/densenet/batch_size_128/96x96_substract_mean_online_aug_width_16\")\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.5, epsilon=1)\n",
    "\n",
    "# define pretrained checkpoint model\n",
    "checkpoint_pretrained = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=densenet) # 4 ssl, 11 sl\n",
    "manager_pretrained = tf.train.CheckpointManager(checkpoint_pretrained, pretrained_checkpoint_prefix, max_to_keep=3)\n",
    "\n",
    "# restore model weights\n",
    "checkpoint_pretrained.restore(manager_pretrained.latest_checkpoint)\n",
    "\n",
    "if manager_pretrained.latest_checkpoint:\n",
    "    print(\"[INFO] Pretrained checkpoint restored correctly: {}\".format(manager_pretrained.latest_checkpoint))\n",
    "else:\n",
    "    print(\"[INFO] Could not restore pretrained checkpoint correctly, make sure path to pre-trained folder is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 2.06955504e-02 -4.00548428e-02 -7.49467500e-03 ...  3.69174890e-02\n",
      "    -1.49117718e-02  5.34790121e-02]]\n",
      "\n",
      "  [[-3.17600071e-02 -2.73128115e-02 -2.68461034e-02 ...  1.15263145e-02\n",
      "    -1.56690311e-02  4.32947464e-02]]\n",
      "\n",
      "  [[ 4.36650440e-02 -4.18559788e-03  4.05532606e-02 ...  1.75015317e-04\n",
      "     5.57239093e-02  1.62203833e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-5.92385903e-02 -2.44358671e-03 -1.33844707e-02 ...  9.13190935e-03\n",
      "     3.80129851e-02  5.21459617e-02]]\n",
      "\n",
      "  [[-1.12355156e-02 -2.82321256e-02  2.13806462e-02 ...  3.47978361e-02\n",
      "    -1.49745559e-02  5.21914586e-02]]\n",
      "\n",
      "  [[ 3.90795339e-03  5.91100054e-03  3.69042940e-02 ...  3.43068689e-02\n",
      "    -6.19086735e-02  2.14096364e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.81733118e-03 -1.72785129e-02 -2.55401805e-02 ... -4.19607796e-02\n",
      "     9.95061733e-03  2.02615038e-02]]\n",
      "\n",
      "  [[ 2.65839528e-02 -1.50399711e-02 -2.55942140e-02 ... -3.92557345e-02\n",
      "    -8.51210207e-04 -3.65448669e-02]]\n",
      "\n",
      "  [[-1.95182003e-02 -1.19072646e-02  2.94016022e-02 ... -2.93623395e-02\n",
      "     5.41791804e-02 -4.58686315e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-3.23628075e-02 -4.20980118e-02  1.82083272e-03 ...  3.53905037e-02\n",
      "     2.00960469e-02 -3.84544171e-02]]\n",
      "\n",
      "  [[-8.02768208e-03  2.96847243e-02  6.18306315e-03 ...  3.74717824e-03\n",
      "    -1.88734606e-02 -3.55962478e-02]]\n",
      "\n",
      "  [[ 1.62200890e-02 -1.70513708e-03  5.89999966e-02 ...  3.12880352e-02\n",
      "    -3.91581655e-02 -2.47631781e-02]]]\n",
      "\n",
      "\n",
      " [[[-2.89289858e-02 -6.85470626e-02  9.56818834e-03 ... -3.74226011e-02\n",
      "    -3.20950486e-02 -3.32979709e-02]]\n",
      "\n",
      "  [[-5.29851280e-02 -1.34384334e-02 -4.92825173e-03 ... -2.82730404e-02\n",
      "     2.50939522e-02  1.72149055e-02]]\n",
      "\n",
      "  [[ 2.93670166e-02 -2.64971871e-02 -6.08413247e-03 ... -4.56696469e-03\n",
      "     1.39290572e-03 -2.69517079e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-2.18123058e-03 -2.81803366e-02 -1.67587306e-02 ... -6.35887682e-02\n",
      "     3.21328752e-02 -2.66355276e-02]]\n",
      "\n",
      "  [[-4.44536731e-02  4.76800650e-02 -1.55167107e-03 ... -2.58673690e-02\n",
      "     3.06778960e-03 -9.55657382e-03]]\n",
      "\n",
      "  [[-9.78155294e-04  5.34533383e-03  7.37369061e-02 ... -2.47781165e-03\n",
      "     1.74189974e-02 -5.77959754e-02]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-4.62436564e-02 -4.11095992e-02 -1.47581249e-02 ... -2.33444455e-03\n",
      "    -1.20242136e-02  1.33324787e-02]]\n",
      "\n",
      "  [[-6.14647269e-02  3.41715175e-03 -3.46122012e-02 ...  4.86797988e-02\n",
      "     1.85202453e-02 -1.79097950e-02]]\n",
      "\n",
      "  [[ 1.91597175e-02 -2.74948739e-02 -3.23584378e-02 ...  2.66665351e-02\n",
      "    -4.21607085e-02  2.13840641e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.81580205e-02  4.21434939e-02 -1.08101806e-02 ...  8.42449517e-05\n",
      "     1.08915549e-02  2.14165933e-02]]\n",
      "\n",
      "  [[-3.58071551e-02  9.51575488e-02  6.60324916e-02 ...  1.14080403e-02\n",
      "     7.25918934e-02 -8.16002116e-03]]\n",
      "\n",
      "  [[-6.39355630e-02 -4.89938371e-02  4.24213968e-02 ... -2.61218604e-02\n",
      "     3.68564017e-02  1.17409145e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.32078063e-02  1.21601217e-03 -6.25320990e-03 ... -3.37088257e-02\n",
      "     1.65533740e-03 -2.24988014e-02]]\n",
      "\n",
      "  [[-2.63297223e-02  1.50400195e-02  6.59287255e-03 ...  9.33555327e-03\n",
      "    -2.89357770e-02  3.12094130e-02]]\n",
      "\n",
      "  [[ 9.47725959e-03 -4.91337702e-02 -3.15307677e-02 ...  1.34362839e-02\n",
      "     1.91200208e-02 -5.23307733e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.65139791e-02 -1.24914700e-03  5.51294237e-02 ...  3.11077572e-02\n",
      "     2.85285693e-02 -1.99582744e-02]]\n",
      "\n",
      "  [[-3.81033793e-02  5.76533601e-02  5.53211607e-02 ... -1.81687996e-02\n",
      "     2.78185047e-02 -5.49143739e-03]]\n",
      "\n",
      "  [[-4.65299487e-02 -3.59439328e-02 -6.62521366e-03 ...  1.68585591e-02\n",
      "     1.74241569e-02 -1.54270027e-02]]]\n",
      "\n",
      "\n",
      " [[[-4.61152531e-02 -2.81217732e-02 -3.82319605e-03 ... -2.33483477e-03\n",
      "     2.36811750e-02 -3.76238041e-02]]\n",
      "\n",
      "  [[-3.05562150e-02 -5.62994517e-02 -1.67480931e-02 ... -4.64595817e-02\n",
      "    -4.50080298e-02  6.59285695e-04]]\n",
      "\n",
      "  [[ 3.19690350e-03 -4.71929424e-02 -3.38664018e-02 ... -5.11391833e-03\n",
      "    -2.04661209e-02  1.25638563e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 3.40386148e-04  1.79408956e-02  4.42745462e-02 ...  1.03373136e-02\n",
      "     2.16140095e-02 -2.54897568e-02]]\n",
      "\n",
      "  [[-4.36030664e-02  5.10667041e-02  7.63896704e-02 ... -1.23077855e-02\n",
      "     5.83552010e-02 -1.84149146e-02]]\n",
      "\n",
      "  [[-3.56606878e-02 -2.03187112e-02 -1.71649344e-02 ...  1.54044535e-02\n",
      "     3.78163606e-02 -6.40221778e-03]]]]\n"
     ]
    }
   ],
   "source": [
    "# check weights AFTER loading pretrained model (second conv layer)\n",
    "print(densenet.layers[2].get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models up to intermediate layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate layers from model: ['conv5_block15_0_relu', 'conv5_block16_0_relu', 'avg_pool']\n"
     ]
    }
   ],
   "source": [
    "print(\"Intermediate layers from model:\", layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/63297838/how-can-i-obtain-the-output-of-an-intermediate-layer-feature-extraction\n",
    "densenet_conv5_block15 = tf.keras.Model(inputs=densenet.get_layer(\"input_1\").output, \n",
    "                                       outputs=densenet.get_layer(layers[0]).output)\n",
    "\n",
    "densenet_conv5_block16 = tf.keras.Model(inputs=densenet.get_layer(\"input_1\").output, \n",
    "                                       outputs=densenet.get_layer(layers[1]).output)\n",
    "\n",
    "densenet_avg_pool = tf.keras.Model(inputs=densenet.get_layer(\"input_1\").output, \n",
    "                                  outputs=densenet.get_layer(layers[2]).output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate vector embeddings for train and test data (up to n-th layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Loading Tenorflow dataset\n",
      "[INFO] Retrieving Sonar Turned Table Supervised Data\n",
      "hdf5 dataset keys: <KeysViewHDF5 ['class_names', 'x_test', 'x_train', 'y_test', 'y_train']>\n",
      "[INFO] Data dimensions\n",
      "Train 1505\n",
      "Val 323\n",
      "Test 645\n",
      "\n",
      "[INFO] Tensorflow data dimensions\n",
      "<PrefetchDataset shapes: ((None, 96, 96, 1), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# define tensorflow dataset\n",
    "data_dir = \"../../../../../../datasets/sonar_turntable_dataset_2/marine-debris-turntable-classification-object_classes-platform-96x96.hdf5\"\n",
    "train_dataset, test_dataset = load_sonar_turnedtable_supervised(data_dir)\n",
    "\n",
    "# load tensorflow tensors individually\n",
    "x_train, y_train = next(iter(train_dataset))\n",
    "x_test, y_test = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a forward pass to generate embeddings (both train and test data) (for each n-th layer)\n",
    "# NOTE: when doing this all tensors are loaded into memory, this saturates NVIDIA memory (nvidia-smi)\n",
    "# x_train_conv5_block15 = densenet_conv5_block15([x_train], training=False)\n",
    "x_train_conv5_block16 = densenet_conv5_block16([x_train], training=False)\n",
    "x_train_avg_pool = densenet_avg_pool([x_train], training=False)\n",
    "\n",
    "# x_test_conv5_block15 = densenet_conv5_block15([x_test], training=False)\n",
    "x_test_conv5_block16 = densenet_conv5_block16([x_test], training=False)\n",
    "x_test_avg_pool = densenet_avg_pool([x_test], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1505, 3, 3, 500), dtype=float32, numpy=\n",
       "array([[[[9.63011861e-01, 5.37675992e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 9.20711279e-01, 9.90658164e-01],\n",
       "         [2.87190866e+00, 9.56079602e-01, 0.00000000e+00, ...,\n",
       "          3.44155878e-01, 7.15744495e-01, 0.00000000e+00],\n",
       "         [1.13016021e+00, 1.01371312e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 7.82152474e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.41334450e+00, 7.26205409e-01, 1.62474597e+00, ...,\n",
       "          0.00000000e+00, 2.88921684e-01, 5.62901020e-01],\n",
       "         [1.71219552e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          8.60551775e-01, 0.00000000e+00, 1.37993288e+00],\n",
       "         [2.68682241e+00, 1.40595937e+00, 0.00000000e+00, ...,\n",
       "          1.38171887e+00, 1.08545327e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[2.44812891e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          5.15688062e-01, 4.45809096e-01, 1.00522065e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.44166481e+00, ...,\n",
       "          7.40295470e-01, 3.65895689e-01, 5.18368542e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          4.72812727e-02, 0.00000000e+00, 1.08599722e-01]]],\n",
       "\n",
       "\n",
       "       [[[2.44239822e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          6.03126645e-01, 1.13788366e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 8.73905480e-01, 0.00000000e+00],\n",
       "         [3.07622343e-01, 0.00000000e+00, 5.29569209e-01, ...,\n",
       "          1.11347891e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[5.71892858e-01, 6.89448237e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.33883429e+00, 0.00000000e+00, 2.48961169e-02, ...,\n",
       "          9.30480003e-01, 0.00000000e+00, 3.98294598e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.50736195e-01, ...,\n",
       "          1.59566724e+00, 0.00000000e+00, 1.85806081e-01]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          5.15436411e-01, 6.54470921e-02, 8.83961201e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.55726951e-01, ...,\n",
       "          9.70596254e-01, 1.06106055e+00, 4.17518198e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          7.19272554e-01, 1.52360514e-01, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[1.97591305e+00, 0.00000000e+00, 3.62296343e-01, ...,\n",
       "          0.00000000e+00, 5.68014145e-01, 4.45511371e-01],\n",
       "         [2.39239264e+00, 7.88088560e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.08244038e+00, 0.00000000e+00],\n",
       "         [5.22363603e-01, 1.60293519e+00, 2.95227200e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.82509857e-01]],\n",
       "\n",
       "        [[8.27066004e-01, 6.65079474e-01, 1.46544671e+00, ...,\n",
       "          0.00000000e+00, 9.91347849e-01, 0.00000000e+00],\n",
       "         [1.71876884e+00, 1.87490857e+00, 1.11812103e+00, ...,\n",
       "          4.54664886e-01, 0.00000000e+00, 6.85143322e-02],\n",
       "         [7.19295025e-01, 1.34395921e+00, 4.85330462e-01, ...,\n",
       "          1.00912206e-01, 4.48083460e-01, 3.62260610e-01]],\n",
       "\n",
       "        [[6.71617925e-01, 0.00000000e+00, 2.41488743e+00, ...,\n",
       "          2.40305424e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.54905784e-01, 1.58993244e+00, ...,\n",
       "          2.38604307e-01, 3.29542547e-01, 3.91916782e-01],\n",
       "         [0.00000000e+00, 3.32915664e-01, 1.70901790e-03, ...,\n",
       "          2.41851136e-01, 0.00000000e+00, 6.59861445e-01]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[8.84786621e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.80800658e-01, 2.04757258e-01],\n",
       "         [8.33167493e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.64078403e-01, 5.40853560e-01],\n",
       "         [7.92366862e-01, 4.68026966e-01, 2.16383889e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 5.51143438e-02, 0.00000000e+00, ...,\n",
       "          2.21899594e-03, 0.00000000e+00, 1.87796187e+00],\n",
       "         [2.01241040e+00, 1.49510241e+00, 0.00000000e+00, ...,\n",
       "          8.85481685e-02, 0.00000000e+00, 1.32650328e+00],\n",
       "         [0.00000000e+00, 2.22799212e-01, 0.00000000e+00, ...,\n",
       "          1.16878462e+00, 4.01946634e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 1.54332101e-01, 0.00000000e+00, ...,\n",
       "          4.59661074e-02, 0.00000000e+00, 6.29842281e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.65887326e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.88194051e-01, 0.00000000e+00, 0.00000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[1.82513559e+00, 7.04340637e-02, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 6.47635698e-01, 7.15163291e-01],\n",
       "         [2.29133248e+00, 6.49450481e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 6.18821025e-01, 2.39645258e-01],\n",
       "         [9.98133481e-01, 1.71626306e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.78817725e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.07125807e+00, 8.96068662e-02, 1.16284621e+00, ...,\n",
       "          2.74199754e-01, 3.42695802e-01, 3.57660726e-02],\n",
       "         [1.44931400e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.01922691e+00, 0.00000000e+00, 2.08170339e-01],\n",
       "         [6.27198875e-01, 1.17382705e+00, 8.57527256e-02, ...,\n",
       "          4.90757138e-01, 0.00000000e+00, 4.23282981e-01]],\n",
       "\n",
       "        [[7.15931773e-01, 0.00000000e+00, 2.14494729e+00, ...,\n",
       "          1.64528713e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.33939886e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.41594201e-01, 0.00000000e+00, 5.67775249e-01]]],\n",
       "\n",
       "\n",
       "       [[[2.08019781e+00, 3.09426904e-01, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.02075446e+00, 9.06667948e-01],\n",
       "         [2.45072293e+00, 1.88076866e+00, 0.00000000e+00, ...,\n",
       "          6.60811722e-01, 9.28518891e-01, 0.00000000e+00],\n",
       "         [2.23971868e+00, 1.78761196e+00, 0.00000000e+00, ...,\n",
       "          1.44671008e-01, 3.05659354e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[1.52431917e+00, 0.00000000e+00, 1.19594812e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 8.17881942e-01],\n",
       "         [1.57815182e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.90194833e+00, 0.00000000e+00, 2.64832115e+00],\n",
       "         [1.68455696e+00, 1.40557694e+00, 0.00000000e+00, ...,\n",
       "          1.78948534e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 0.00000000e+00, 2.84849405e-01, ...,\n",
       "          0.00000000e+00, 8.30149889e-01, 5.59748948e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.28305459e+00, ...,\n",
       "          1.23727965e+00, 5.93990505e-01, 2.42194176e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          1.61311114e+00, 0.00000000e+00, 2.64786720e-01]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_conv5_block16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning setup: classification with subsamples per object class (few shot learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning params\n",
    "# SAMPLES_PER_CLASS = [1, 5, 10, 20, 30, 40, 50] # NOTE: taking more samples per class since it is 88 for 50\n",
    "# SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 70, 90, 110, 130, 150, len(x_test)]\n",
    "SAMPLES_PER_CLASS = [10, 20, 30, 40, 50, 80, 110, 140, 170, 200]\n",
    "TRIALS = 10\n",
    "\n",
    "NUM_CLASSES_WATERTANK = 11\n",
    "NUM_CLASSES_TURNEDTABLE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505, 4356)\n",
      "(645, 4356)\n"
     ]
    }
   ],
   "source": [
    "# Flatten train & test data for SVM\n",
    "x_train_conv5_block15 = flatten(x_train_conv5_block15.numpy())\n",
    "x_train_conv5_block16 = flatten(x_train_conv5_block16.numpy())\n",
    "x_train_avg_pool = flatten(x_train_avg_pool.numpy())\n",
    "\n",
    "x_test_conv5_block15 = flatten(x_test_conv5_block15.numpy())\n",
    "x_test_conv5_block16 = flatten(x_test_conv5_block16.numpy())\n",
    "x_test_avg_pool = flatten(x_test_avg_pool.numpy())\n",
    "\n",
    "print(x_train_conv5_block15.shape)\n",
    "print(x_test_conv5_block15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1505,)\n",
      "(645,)\n"
     ]
    }
   ],
   "source": [
    "# these two are not modified (only x_test, x_train)\n",
    "print(y_train.numpy().shape)\n",
    "print(y_test.numpy().shape)\n",
    "\n",
    "y_train = y_train.numpy() # convert from tf tensor --> numpy\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run svm tl evaluation with spc for each n-th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_with_spc(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Takes embeddings from pretrained model and evaluates transfer learning \n",
    "    with few samples per class.\n",
    "    \"\"\"\n",
    "    # NOTE: svm takes original labels (not one-hot encoding)\n",
    "    for spc in SAMPLES_PER_CLASS:\n",
    "        accuracies = []\n",
    "\n",
    "        for i in range(TRIALS):\n",
    "            x_sample, y_sample = classSampling(x_train, y_train, spc, NUM_CLASSES_TURNEDTABLE)\n",
    "\n",
    "            svm = SVC(C=1.0, decision_function_shape = 'ovo', kernel=\"linear\")\n",
    "            svm.fit(x_sample, y_sample)\n",
    "\n",
    "            train_acc = svm.score(x_sample, y_sample)\n",
    "            test_acc = svm.score(x_test, y_test)\n",
    "\n",
    "            print(\"SPC {} Train Accuracy: {:.3f}\".format(spc, train_acc))\n",
    "            print(\"SPC {} Test Accuracy: {:.3f}\".format(spc, test_acc))\n",
    "            print()\n",
    "\n",
    "            accuracies.append(test_acc)\n",
    "\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "\n",
    "        mean_acc = round(100 * mean_acc, 3)\n",
    "        std_acc = round(100 * std_acc, 3)\n",
    "\n",
    "        print(\"After {} trials - Test Accuracy is {} +- {}\".format(TRIALS, mean_acc, std_acc ))\n",
    "        print(\"------------------------------------------------------------------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.696\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.651\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.673\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.716\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.670\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.670\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.709\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.682\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.684\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.645\n",
      "\n",
      "After 10 trials - Test Accuracy is 67.953 +- 2.174\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.767\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.800\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.746\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.767\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.798\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.774\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.797\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.766\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.741\n",
      "\n",
      "After 10 trials - Test Accuracy is 77.395 +- 1.978\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.847\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.837\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.847\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.850\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.822\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.829\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.847\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.850\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.853\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.848\n",
      "\n",
      "After 10 trials - Test Accuracy is 84.279 +- 0.956\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.829\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.862\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.848\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.847\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.868\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.856\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.854\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.856\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.867\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.873\n",
      "\n",
      "After 10 trials - Test Accuracy is 85.597 +- 1.202\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.864\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.859\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.871\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.885\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.884\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.874\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.876\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.879\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.890\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.874\n",
      "\n",
      "After 10 trials - Test Accuracy is 87.566 +- 0.906\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.895\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.907\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.905\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.907\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.909\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.902\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.909\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.907\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.853 +- 0.8\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.935\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.907\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.918\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.926\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.930\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.915\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.909\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.916\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "After 10 trials - Test Accuracy is 92.109 +- 0.905\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.936\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.932\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.949\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.946\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.932\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.944\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.933\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "After 10 trials - Test Accuracy is 93.953 +- 0.58\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.940\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.944\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.940\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.946\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.949\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.944\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.940\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.944\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.465 +- 0.405\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.955\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.952\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.946\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.946\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.949\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.953\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.952\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.947\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.944\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.958\n",
      "\n",
      "After 10 trials - Test Accuracy is 95.023 +- 0.435\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_svm_with_spc(x_train_conv5_block15, y_train, x_test_conv5_block15, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.620\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.681\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.713\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.691\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.688\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.690\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.662\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.699\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.712\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.729\n",
      "\n",
      "After 10 trials - Test Accuracy is 68.853 +- 2.884\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.812\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.805\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.775\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.778\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.795\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.783\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.775\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.977 +- 1.215\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.854\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.843\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.839\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.814\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.867\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.823\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.837\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.828\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.833\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.845\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.829 +- 1.446\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.874\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.848\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.865\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.870\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.881\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.876\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.850\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.879\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.881\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.867\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.899 +- 1.133\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.870\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.881\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.879\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.912\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.882\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.859\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.904\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.874\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.876\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.186 +- 1.464\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.907\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.926\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.904\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.922\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.916\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.909\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.891\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.893\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.913\n",
      "\n",
      "After 10 trials - Test Accuracy is 91.039 +- 1.133\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.932\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.927\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.921\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.909\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.929\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.933\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.919\n",
      "\n",
      "After 10 trials - Test Accuracy is 92.589 +- 0.73\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.946\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.941\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.938\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.950\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.930\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.944\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.926\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.943\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.935\n",
      "\n",
      "After 10 trials - Test Accuracy is 93.907 +- 0.704\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.938\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.955\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.944\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.941\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.949\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.938\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.952\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.950\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.961\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.791 +- 0.718\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.941\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.950\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.957\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.949\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.947\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.943\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.936\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.943\n",
      "\n",
      "After 10 trials - Test Accuracy is 94.667 +- 0.56\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_conv5_block16, y_train, x_test_conv5_block16, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.648\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.684\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.628\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.670\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.647\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.625\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.662\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.679\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.640\n",
      "\n",
      "SPC 10 Train Accuracy: 1.000\n",
      "SPC 10 Test Accuracy: 0.569\n",
      "\n",
      "After 10 trials - Test Accuracy is 64.512 +- 3.174\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.722\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.738\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.744\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.707\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.718\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.741\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.729\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.732\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.724\n",
      "\n",
      "SPC 20 Train Accuracy: 1.000\n",
      "SPC 20 Test Accuracy: 0.712\n",
      "\n",
      "After 10 trials - Test Accuracy is 72.667 +- 1.179\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.811\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.780\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.766\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.795\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.769\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.794\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.771\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.784\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.780\n",
      "\n",
      "SPC 30 Train Accuracy: 1.000\n",
      "SPC 30 Test Accuracy: 0.778\n",
      "\n",
      "After 10 trials - Test Accuracy is 78.279 +- 1.316\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.803\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.797\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.812\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.809\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.802\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.840\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.806\n",
      "\n",
      "SPC 40 Train Accuracy: 1.000\n",
      "SPC 40 Test Accuracy: 0.811\n",
      "\n",
      "After 10 trials - Test Accuracy is 80.961 +- 1.115\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.809\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.847\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.845\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.840\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.843\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.853\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.833\n",
      "\n",
      "SPC 50 Train Accuracy: 1.000\n",
      "SPC 50 Test Accuracy: 0.839\n",
      "\n",
      "After 10 trials - Test Accuracy is 83.736 +- 1.132\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.871\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.865\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.881\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.842\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.864\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.864\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.854\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.854\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.859\n",
      "\n",
      "SPC 80 Train Accuracy: 1.000\n",
      "SPC 80 Test Accuracy: 0.878\n",
      "\n",
      "After 10 trials - Test Accuracy is 86.31 +- 1.101\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.867\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.879\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.893\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.876\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.887\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.890\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.870\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.874\n",
      "\n",
      "SPC 110 Train Accuracy: 1.000\n",
      "SPC 110 Test Accuracy: 0.901\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.264 +- 1.052\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.876\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.884\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.890\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.891\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.898\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.890\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.887\n",
      "\n",
      "SPC 140 Train Accuracy: 1.000\n",
      "SPC 140 Test Accuracy: 0.898\n",
      "\n",
      "After 10 trials - Test Accuracy is 88.868 +- 0.608\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.910\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.913\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.893\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.895\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.905\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.907\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.899\n",
      "\n",
      "SPC 170 Train Accuracy: 1.000\n",
      "SPC 170 Test Accuracy: 0.901\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.357 +- 0.619\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.899\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.893\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.905\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.918\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.895\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.902\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.904\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.905\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.901\n",
      "\n",
      "SPC 200 Train Accuracy: 1.000\n",
      "SPC 200 Test Accuracy: 0.895\n",
      "\n",
      "After 10 trials - Test Accuracy is 90.171 +- 0.691\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_svm_with_spc(x_train_avg_pool, y_train, x_test_avg_pool, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot tl results for each n-th layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (7,6)\n",
    "\n",
    "conv5_block15_accs = [67.953, 77.395, 84.279, 85.597, 87.566, 90.853, 92.109, 93.953, 94.465, 95.023]\n",
    "\n",
    "plt.ylim(65, 100)\n",
    "plt.plot(SAMPLES_PER_CLASS, conv5_block15_accs, marker='o', linestyle='--', color='r', label=layers[0]+\" self-supervised\")\n",
    "plt.xlabel(\"Samples per class\", fontsize=18)\n",
    "plt.ylabel(\"Test accuracy\", fontsize=18) \n",
    "plt.grid()\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(SAMPLES_PER_CLASS, fontsize=14, rotation=45)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rotnet] *",
   "language": "python",
   "name": "conda-env-rotnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
